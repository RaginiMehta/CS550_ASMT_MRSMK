{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optims\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as dist\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from transformers import DistilBertModel, DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_path = '/kaggle/input/iu-xray-reports-preprocessed-sorted-df/iu_xray_reports_preprocessed_sorted_df.csv'\n",
    "# output_dir = '/kaggle/working/'\n",
    "\n",
    "input_test_path = '/home/raginivi/CS550_ASMT_MRSMK/filtered_test_data.csv'\n",
    "input_train_path = '/home/raginivi/CS550_ASMT_MRSMK/filtered_train_data.csv'\n",
    "output_path = '/home/raginivi/CS550_ASMT_MRSMK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/raginivi/anaconda3/lib/python3.12/site-packages (2.4.1)\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch)\n",
      "  Downloading triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: setuptools in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (75.2.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cusolver-cu12, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.0.0\n",
      "    Uninstalling triton-3.0.0:\n",
      "      Successfully uninstalled triton-3.0.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
      "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.6.77\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
      "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
      "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
      "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.1\n",
      "    Uninstalling torch-2.4.1:\n",
      "      Successfully uninstalled torch-2.4.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.4.1 requires torch==2.4.1, but you have torch 2.5.1 which is incompatible.\n",
      "torchvision 0.19.1 requires torch==2.4.1, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1 triton-3.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2705, 5) (763, 5)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# os.getcwd()\n",
    "\n",
    "train_path = pd.read_csv(input_train_path)\n",
    "test_path = pd.read_csv(input_test_path)\n",
    "\n",
    "print(train_path.shape, test_path.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: ipywidgets 8.1.5\n",
      "Uninstalling ipywidgets-8.1.5:\n",
      "  Successfully uninstalled ipywidgets-8.1.5\n",
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from ipywidgets) (8.25.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /home/raginivi/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/raginivi/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /home/raginivi/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/raginivi/anaconda3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in /home/raginivi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /home/raginivi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /home/raginivi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /home/raginivi/anaconda3/lib/python3.12/site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Using cached ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Installing collected packages: ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 uninstall ipywidgets --yes\n",
    "!pip3 install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/raginivi/anaconda3/lib/python3.12/site-packages (4.45.2)\n",
      "Requirement already satisfied: torch in /home/raginivi/anaconda3/lib/python3.12/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /home/raginivi/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/raginivi/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.77)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: sentence-transformers in /home/raginivi/anaconda3/lib/python3.12/site-packages (3.2.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.45.2)\n",
      "Requirement already satisfied: tqdm in /home/raginivi/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in /home/raginivi/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in /home/raginivi/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (0.25.2)\n",
      "Requirement already satisfied: Pillow in /home/raginivi/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /home/raginivi/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/raginivi/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/raginivi/anaconda3/lib/python3.12/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch  # For Hugging Face\n",
    "# !pip install sentence-transformers  # For Sentence Transformers\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=768, hidden_dim=512, output_dim=512):\n",
    "        super(SentenceEncoder, self).__init__()\n",
    "        # Encoder network\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Networks to generate mean and variance as mentioned in paper\n",
    "        self.mean_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        self.logvar_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        mean = self.mean_layer(encoded)\n",
    "        logvar = self.logvar_layer(encoded)\n",
    "        return mean, logvar\n",
    "        \n",
    "    def encode(self, x):\n",
    "        \"\"\"Get only the mean for inference\"\"\"\n",
    "        mean, _ = self.forward(x)\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceBERT:\n",
    "    def __init__(self):\n",
    "        # Initialize the BERT tokenizer and model\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def encode_reports(self, reports):\n",
    "        embeddings = []\n",
    "        for report in reports:\n",
    "            # Tokenize and encode the report\n",
    "            inputs = self.tokenizer(report, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "            # Get BERT outputs\n",
    "            with torch.no_grad():  # Disable gradient calculation for inference\n",
    "                outputs = self.bert_model(**inputs)\n",
    "                \n",
    "            # Use the pooled output as the embedding\n",
    "            embeddings.append(outputs.pooler_output)\n",
    "\n",
    "        # Stack all embeddings into a single tensor\n",
    "        return torch.stack(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|████████████████████| 43/43 [03:01<00:00,  4.22s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT Matrix Shape: torch.Size([2705, 768])\n",
      "Sentence Encoder Matrix Shape: torch.Size([2705, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "# Initialize models\n",
    "sentence_bert = SentenceBERT()\n",
    "sentence_encoder = SentenceEncoder()\n",
    "\n",
    "# Parameters for batching\n",
    "batch_size = 64\n",
    "num_batches = (len(df) + batch_size - 1) // batch_size  # Calculate number of batches\n",
    "\n",
    "# Initialize matrices to store embeddings\n",
    "sbert_matrix = []\n",
    "sentence_encoder_matrix = []\n",
    "\n",
    "# Loop through batches with progress bar\n",
    "for i in tqdm(range(num_batches), desc=\"Processing Batches\", unit=\"batch\"):\n",
    "    batch_reports = df['findings'].iloc[i * batch_size:(i + 1) * batch_size].tolist()\n",
    "    \n",
    "    # Compute SBERT embeddings\n",
    "    sbert_embeddings = sentence_bert.encode_reports(batch_reports)\n",
    "    \n",
    "    # Compute Sentence Encoder embeddings\n",
    "    sentence_embeddings = sentence_encoder.encode(sbert_embeddings)\n",
    "    \n",
    "    # Store embeddings in the matrices\n",
    "    sbert_matrix.append(sbert_embeddings)\n",
    "    sentence_encoder_matrix.append(sentence_embeddings)\n",
    "\n",
    "# Stack the matrices to create final output tensors\n",
    "sbert_matrix = torch.cat(sbert_matrix, dim=0).squeeze(1)\n",
    "sentence_encoder_matrix = torch.cat(sentence_encoder_matrix, dim=0).squeeze(1)\n",
    "\n",
    "# Print shapes of the final matrices\n",
    "print(f\"SBERT Matrix Shape: {sbert_matrix.shape}\")\n",
    "print(f\"Sentence Encoder Matrix Shape: {sentence_encoder_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence_loss(mean1: torch.Tensor, logvar1: torch.Tensor, mean2: torch.Tensor, logvar2: torch.Tensor) -> torch.Tensor:\n",
    "    normal1 = dist.Normal(mean1, torch.exp(0.5 * logvar1))  # Standard deviation is sqrt of variance\n",
    "    normal2 = dist.Normal(mean2, torch.exp(0.5 * logvar2))\n",
    "    kl_loss = dist.kl.kl_divergence(normal1, normal2).mean()\n",
    "    return kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 43batch [00:00, 122.05batch/s, loss=0.0630]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20, Average Loss: 0.1346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 43batch [00:00, 162.24batch/s, loss=0.0574]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/20, Average Loss: 0.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 43batch [00:00, 126.77batch/s, loss=0.0562]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/20, Average Loss: 0.0611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 43batch [00:00, 117.44batch/s, loss=0.0561]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/20, Average Loss: 0.0608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 43batch [00:00, 134.42batch/s, loss=0.0557]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/20, Average Loss: 0.0606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 43batch [00:00, 121.36batch/s, loss=0.0554]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/20, Average Loss: 0.0604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 43batch [00:00, 102.47batch/s, loss=0.0551]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/20, Average Loss: 0.0603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 43batch [00:00, 124.51batch/s, loss=0.0548]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/20, Average Loss: 0.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 43batch [00:00, 116.41batch/s, loss=0.0546]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/20, Average Loss: 0.0600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 43batch [00:00, 177.79batch/s, loss=0.0543]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/20, Average Loss: 0.0599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 43batch [00:00, 155.88batch/s, loss=0.0540]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/20, Average Loss: 0.0598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 43batch [00:00, 108.77batch/s, loss=0.0538]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/20, Average Loss: 0.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 43batch [00:00, 156.68batch/s, loss=0.0536]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/20, Average Loss: 0.0597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 43batch [00:00, 168.17batch/s, loss=0.0535]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/20, Average Loss: 0.0596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 43batch [00:00, 175.44batch/s, loss=0.0533]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/20, Average Loss: 0.0595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 43batch [00:00, 116.86batch/s, loss=0.0531]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/20, Average Loss: 0.0594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 43batch [00:00, 113.80batch/s, loss=0.0529]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/20, Average Loss: 0.0593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 43batch [00:00, 105.83batch/s, loss=0.0527]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/20, Average Loss: 0.0593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 43batch [00:00, 117.16batch/s, loss=0.0525]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/20, Average Loss: 0.0592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 43batch [00:00, 201.05batch/s, loss=0.0524]                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/20, Average Loss: 0.0591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_embeddings(sentence_encoder, projection_layer, sentence_encoder_matrix, sbert_matrix, \n",
    "                    optimizer, batch_size, num_epochs):\n",
    "    \"\"\"\n",
    "    Training loop with explicit memory management and graph cleanup\n",
    "    \"\"\"\n",
    "    device = next(sentence_encoder.parameters()).device\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        sentence_encoder.train()\n",
    "        projection_layer.train()\n",
    "        \n",
    "        n_batches = sentence_encoder_matrix.size(0) // batch_size\n",
    "        \n",
    "        with tqdm(total=n_batches, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\") as pbar:\n",
    "            for i in range(0, sentence_encoder_matrix.size(0), batch_size):\n",
    "                try:\n",
    "                    # Clear gradients\n",
    "                    optimizer.zero_grad(set_to_none=True)  # More efficient than zero_grad()\n",
    "                    \n",
    "                    # Get batch data with detached copies\n",
    "                    batch_embedding1 = sentence_encoder_matrix[i:i+batch_size].to(device).detach().clone()\n",
    "                    batch_embedding2 = sbert_matrix[i:i+batch_size].to(device).detach().clone()\n",
    "                    \n",
    "                    # Project SBERT embeddings\n",
    "                    with torch.set_grad_enabled(True):\n",
    "                        batch_embedding2_projected = projection_layer(batch_embedding2)\n",
    "                        \n",
    "                        # Compute means and variances\n",
    "                        mean1 = batch_embedding1.mean(dim=0, keepdim=True)\n",
    "                        var1 = batch_embedding1.var(dim=0, keepdim=True, unbiased=False)\n",
    "                        mean2 = batch_embedding2_projected.mean(dim=0, keepdim=True)\n",
    "                        var2 = batch_embedding2_projected.var(dim=0, keepdim=True, unbiased=False)\n",
    "                        \n",
    "                        # KL divergence loss\n",
    "                        kl_loss = kl_divergence_loss(mean1, var1, mean2, var2)\n",
    "                        \n",
    "                        # Similarity loss\n",
    "                        similarities = F.cosine_similarity(batch_embedding1, batch_embedding2_projected, dim=1)\n",
    "                        sim_loss = 1 - similarities.mean()\n",
    "                        \n",
    "                        # Combined loss\n",
    "                        loss = kl_loss + sim_loss\n",
    "                    \n",
    "                    # Backward pass with no graph retention\n",
    "                    loss.backward(retain_graph=False)\n",
    "                    \n",
    "                    # Clip gradients\n",
    "                    torch.nn.utils.clip_grad_norm_(sentence_encoder.parameters(), max_norm=1.0)\n",
    "                    torch.nn.utils.clip_grad_norm_(projection_layer.parameters(), max_norm=1.0)\n",
    "                    \n",
    "                    # Optimizer step\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    # Update metrics\n",
    "                    current_loss = loss.item()\n",
    "                    total_loss += current_loss\n",
    "                    \n",
    "                    # Clean up tensors explicitly\n",
    "                    del batch_embedding1, batch_embedding2, batch_embedding2_projected\n",
    "                    del mean1, var1, mean2, var2\n",
    "                    del kl_loss, similarities, sim_loss, loss\n",
    "                    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "                    \n",
    "                    # Update progress bar\n",
    "                    pbar.update(1)\n",
    "                    pbar.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "                    \n",
    "                except RuntimeError as e:\n",
    "                    print(f\"\\nError in batch {i//batch_size}:\")\n",
    "                    print(str(e))\n",
    "                    # Try to recover\n",
    "                    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "                    continue\n",
    "        \n",
    "        # Compute average loss for the epoch\n",
    "        avg_loss = total_loss / n_batches\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Set up training\n",
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "\n",
    "# Initialize optimizer with parameters from both models\n",
    "optimizer = optim.Adam([\n",
    "    {'params': sentence_encoder.parameters()},\n",
    "    {'params': projection_layer.parameters()}\n",
    "], lr=1e-3)\n",
    "\n",
    "# Move models to the same device if using GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    sentence_encoder = sentence_encoder.to(device)\n",
    "    projection_layer = projection_layer.to(device)\n",
    "    sentence_encoder_matrix = sentence_encoder_matrix.to(device)\n",
    "    sbert_matrix = sbert_matrix.to(device)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Run training\n",
    "train_embeddings(\n",
    "    sentence_encoder=sentence_encoder,\n",
    "    projection_layer=projection_layer,\n",
    "    sentence_encoder_matrix=sentence_encoder_matrix,\n",
    "    sbert_matrix=sbert_matrix,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarities(batch_embeddings: torch.Tensor, all_embeddings: torch.Tensor) -> torch.Tensor:\n",
    "    # Normalize embeddings\n",
    "    batch_norm = F.normalize(batch_embeddings, p=2, dim=1)\n",
    "    all_norm = F.normalize(all_embeddings, p=2, dim=1)\n",
    "    \n",
    "    # Compute similarities\n",
    "    similarities = torch.mm(batch_norm, all_norm.t())\n",
    "    return similarities\n",
    "\n",
    "# Compute similarity matrices\n",
    "sbert_similarities = compute_cosine_similarities(sbert_matrix, sbert_matrix)\n",
    "sentence_encoder_similarities = compute_cosine_similarities(sentence_encoder_matrix, sentence_encoder_matrix)\n",
    "\n",
    "# Print similarity matrix shapes\n",
    "print(f\"SBERT Similarity Matrix Shape: {sbert_similarities.shape}\")  # Should be [2705, 2705]\n",
    "print(f\"Sentence Encoder Similarity Matrix Shape: {sentence_encoder_similarities.shape}\")  # Should be [2705, 2705]"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5998895,
     "sourceId": 9790116,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
