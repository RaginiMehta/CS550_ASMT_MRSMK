{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bnpd7Zh0NPl2"
   },
   "source": [
    "## **Medical Report Summarisation using Medical Knowledge**\n",
    "\n",
    "### **References**\n",
    "\n",
    "**Main Reference**\n",
    "- Radiology report generation with medical knowledge and multilevel image-report alignment: A new method and its verification\n",
    "https://www.sciencedirect.com/science/article/pii/S0933365723002282\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKdcyk1sMEtD"
   },
   "source": [
    "## **Data Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p81rfgckMR9a"
   },
   "source": [
    "### **Collect Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYR_B6u1ojJt",
    "outputId": "faaac1ed-b54b-4cfd-b3e4-cca51372318e"
   },
   "outputs": [],
   "source": [
    "'''Libraries Installation and Import'''\n",
    "\n",
    "# installling necessary libraries\n",
    "!pip -q install --user requests numpy pandas matplotlib tqdm Pillow opencv-python nltk pyspellchecker torch torchvision torchaudio transformers scikit-learn sentence-transformers\n",
    "\n",
    "# importing required libraries\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import requests\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from spellchecker import SpellChecker\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as dist\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optims\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as dist\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Setting Paths'''\n",
    "\n",
    "# project directory\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# project_directory = '/content/drive/Othercomputers/My Laptop/CS550_ASMT_MRSMK/datasets'\n",
    "# project_directory = '/content/drive/MyDrive/Academics/CS550 Machine Learning/CS550 ASMT MRSMK/datasets'\n",
    "\n",
    "project_directory = \"./datasets\"\n",
    "dataset = 'iu_xray/'\n",
    "iu_xray_dataset = os.path.join(project_directory, dataset)\n",
    "\n",
    "\n",
    "# input directory\n",
    "input_directory = os.path.join(iu_xray_dataset, \"input\")\n",
    "\n",
    "images_dir = os.path.join(input_directory, \"images\")\n",
    "reports_dir = os.path.join(input_directory, \"reports\")\n",
    "iu_xray_images = images_dir\n",
    "iu_xray_reports = os.path.join(reports_dir, 'ecgen-radiology')\n",
    "\n",
    "\n",
    "# output directory \n",
    "output_directory = os.path.join(iu_xray_dataset, \"output\")\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49-0xiXplwH8",
    "outputId": "ea63eda3-908a-4f5f-eeec-a4019130e57f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://openi.nlm.nih.gov/imgs/collections/NLMCXR_png.tgz already exists at: ./datasets/iu_xray/input/images\n",
      "https://openi.nlm.nih.gov/imgs/collections/NLMCXR_reports.tgz already exists at: ./datasets/iu_xray/input/reports\n"
     ]
    }
   ],
   "source": [
    "'''Setup - Generalized'''\n",
    "\n",
    "# setup to download the IU X-Ray Dataset\n",
    "images_url = \"https://openi.nlm.nih.gov/imgs/collections/NLMCXR_png.tgz\"\n",
    "reports_url = \"https://openi.nlm.nih.gov/imgs/collections/NLMCXR_reports.tgz\"\n",
    "\n",
    "\n",
    "# function to check the file size of a given URL\n",
    "def get_file_size(url):\n",
    "    response = requests.head(url)\n",
    "    size_in_bytes = int(response.headers.get('Content-Length', 0))\n",
    "    size_in_mb = size_in_bytes / (1024 * 1024)\n",
    "    return size_in_mb\n",
    "\n",
    "\n",
    "# function to download and extract from a given url to a given directory\n",
    "def download_and_extract(url, save_dir):\n",
    "    file_name = url.split('/')[-1]\n",
    "    file_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('Content-Length', 0))\n",
    "    downloaded_size = 0\n",
    "\n",
    "    with open(file_path, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                file.write(chunk)\n",
    "                downloaded_size += len(chunk)\n",
    "                percent_complete = (downloaded_size / total_size) * 100\n",
    "                print(f\"Downloaded {downloaded_size / (1024*1024):.2f} MB out of {total_size / (1024*1024):.2f} MB: {percent_complete:.2f}% complete\", end=\"\\r\")\n",
    "\n",
    "    print(\"\\nDownload complete!\")\n",
    "\n",
    "    with tarfile.open(file_path, 'r:gz') as tar:\n",
    "        members = tar.getmembers()\n",
    "        total_files = len(members)\n",
    "\n",
    "        for idx, member in enumerate(members, start=1):\n",
    "            tar.extract(member, path=save_dir)\n",
    "            print(f\"Extracting File {idx} out of {total_files}: {member.name}\", end=\"\\r\")\n",
    "\n",
    "    os.remove(file_path)\n",
    "\n",
    "\n",
    "# downloading  IU X-Ray dataset\n",
    "if not os.path.exists(images_dir):\n",
    "    images_size = get_file_size(images_url)\n",
    "    print(f\"Downloading {images_url} to: {images_dir} ({images_size:.2f} MB)\")\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    download_and_extract(images_url, images_dir)\n",
    "    print(f\"Downloaded {images_url} to: {images_dir}\")\n",
    "else:\n",
    "    print(f\"{images_url} already exists at: {images_dir}\")\n",
    "\n",
    "if not os.path.exists(reports_dir):\n",
    "    reports_size = get_file_size(reports_url)\n",
    "    print(f\"Downloading {reports_url} to: {reports_dir} ({reports_size:.2f} MB)\")\n",
    "    os.makedirs(reports_dir, exist_ok=True)\n",
    "    download_and_extract(reports_url, reports_dir)\n",
    "    print(f\"Downloaded {reports_url} to: {reports_dir}\")\n",
    "else:\n",
    "    print(f\"{reports_url} already exists at: {reports_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ZSA8Jyowaoh",
    "outputId": "dffa4899-00a7-4d49-a118-8dd85400ba06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Path:  ./datasets/iu_xray/input/images\n",
      "Directory Contents: 7471 Images\n",
      "\n",
      "Path:  ./datasets/iu_xray/input/reports/ecgen-radiology\n",
      "Directory Contents: 3955 Reports\n"
     ]
    }
   ],
   "source": [
    "'''Exploring the IU X-Ray Dataset Contents'''\n",
    "\n",
    "# displaying directory and subdirectory contents\n",
    "print(\"\\nPath: \", iu_xray_images)\n",
    "print(f\"Directory Contents: {len(os.listdir(iu_xray_images))} Images\")\n",
    "\n",
    "print(\"\\nPath: \", iu_xray_reports)\n",
    "print(f\"Directory Contents: {len(os.listdir(iu_xray_reports))} Reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 822
    },
    "id": "qGczexPLUaN5",
    "outputId": "8c7528a1-7064-4802-c276-edef004f0d5b"
   },
   "outputs": [],
   "source": [
    "'''Processing Textual Data from each .xml Report File and Storing it in a .csv File'''\n",
    "\n",
    "# function to iterate through all .xml report files and storing them in a dataframe\n",
    "def save_images_df():\n",
    "    data = []\n",
    "    cnt = 0\n",
    "    for file in os.listdir(iu_xray_reports):\n",
    "        if file.endswith(\".xml\"):\n",
    "            cnt += 1\n",
    "            print(f\"Processing .xml File {cnt} out of {len(os.listdir(iu_xray_reports))}: {file}\", end=\"\\r\")\n",
    "\n",
    "            file_path = os.path.join(iu_xray_reports, file)\n",
    "            try:\n",
    "                tree = ET.parse(file_path)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                pmc_id = root.find('.//pmcId').attrib.get('id')\n",
    "\n",
    "                comparison = indication = findings = impression = None\n",
    "\n",
    "                for abstract in root.findall('.//AbstractText'):\n",
    "                    if abstract.attrib.get('Label') == 'COMPARISON':\n",
    "                        comparison = abstract.text\n",
    "                    elif abstract.attrib.get('Label') == 'INDICATION':\n",
    "                        indication = abstract.text\n",
    "                    elif abstract.attrib.get('Label') == 'FINDINGS':\n",
    "                        findings = abstract.text\n",
    "                    elif abstract.attrib.get('Label') == 'IMPRESSION':\n",
    "                        impression = abstract.text\n",
    "\n",
    "                for parent_image in root.findall('parentImage'):\n",
    "                    image_file = parent_image.attrib['id'] + \".png\"\n",
    "                    image_path = os.path.join(iu_xray_images, image_file)\n",
    "                    image = cv2.imread(image_path)\n",
    "\n",
    "                    if image is not None:\n",
    "                        height, width, channels = image.shape\n",
    "                        caption = parent_image.find('caption').text if parent_image.find('caption') is not None else None\n",
    "                        data.append([pmc_id, image_file, caption, comparison, indication, findings, impression, height, width])\n",
    "                    else:\n",
    "                        print(f\"Warning: Unable to read image {image_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# creating a dataframe and saving it as .csv\n",
    "iu_xray_images_df_path = os.path.join(output_directory, 'iu_xray_images_df.csv')\n",
    "if os.path.exists(iu_xray_images_df_path):\n",
    "    data = save_images_df()\n",
    "    columns = ['pmc_id', 'image_filename', 'caption', 'comparison', 'indication', 'findings', 'impression', 'height', 'width']\n",
    "    iu_xray_images_df = pd.DataFrame(data, columns=columns)\n",
    "    iu_xray_images_df.to_csv(iu_xray_images_df_path, index=False)\n",
    "    print(f\"Dataframe saved to {iu_xray_images_df_path}\")\n",
    "else:\n",
    "    print(f\"Dataframe already exists at {iu_xray_images_df_path}\")\n",
    "    iu_xray_images_df = pd.read_csv(iu_xray_images_df_path)\n",
    "\n",
    "\n",
    "# displaying the stored dataframe\n",
    "print(\"\\n\\nDataframe Shape:\", iu_xray_images_df.shape)\n",
    "\n",
    "print(\"\\n\\nDataframe Information:\\n\")\n",
    "display(iu_xray_images_df.info())\n",
    "\n",
    "print(\"\\n\\nDisplaying Dataframe:\\n\")\n",
    "display(iu_xray_images_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893
    },
    "id": "vYnfzXXT0O6w",
    "outputId": "d2692046-ebe0-45ac-8291-37641f6d5958"
   },
   "outputs": [],
   "source": [
    "'''Processing Textual Data from each .xml Report File and Storing it in a .csv File'''\n",
    "\n",
    "# function to iterate through all .xml report files and storing them in a dataframe\n",
    "def save_reports_df():\n",
    "    data = []\n",
    "    cnt = 0\n",
    "    for file in os.listdir(iu_xray_reports):\n",
    "        if file.endswith(\".xml\"):\n",
    "            cnt += 1\n",
    "            print(f\"Processing .xml File {cnt} out of {len(os.listdir(iu_xray_reports))}: {file}\", end=\"\\r\")\n",
    "\n",
    "            file_path = os.path.join(iu_xray_reports, file)\n",
    "            try:\n",
    "                tree = ET.parse(file_path)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                pmc_id = root.find('.//pmcId').attrib.get('id')\n",
    "\n",
    "                comparison = indication = findings = impression = None\n",
    "\n",
    "                for abstract in root.findall('.//AbstractText'):\n",
    "                    if abstract.attrib.get('Label') == 'COMPARISON':\n",
    "                        comparison = abstract.text\n",
    "                    elif abstract.attrib.get('Label') == 'INDICATION':\n",
    "                        indication = abstract.text\n",
    "                    elif abstract.attrib.get('Label') == 'FINDINGS':\n",
    "                        findings = abstract.text\n",
    "                    elif abstract.attrib.get('Label') == 'IMPRESSION':\n",
    "                        impression = abstract.text\n",
    "\n",
    "                report_data = {\n",
    "                    'pmc_id': pmc_id,\n",
    "                    'findings': findings,\n",
    "                    'impression': impression,\n",
    "                    'comparison': comparison,\n",
    "                    'indication': indication,\n",
    "                }\n",
    "\n",
    "                parent_images = root.findall('parentImage')\n",
    "                report_data['image_count'] = len(parent_images)\n",
    "\n",
    "                for i, parent_image in enumerate(parent_images, start=1):\n",
    "                    image_file = parent_image.attrib['id'] + \".jpg\"\n",
    "                    caption = parent_image.find('caption').text if parent_image.find('caption') is not None else None\n",
    "                    report_data[f'image_{i}'] = f\"{image_file}: {caption}\" if caption else image_file\n",
    "\n",
    "                data.append(report_data)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# creating a dataframe and saving it as .csv\n",
    "iu_xray_reports_df_path = os.path.join(output_directory, 'iu_xray_reports_df.csv')\n",
    "if not os.path.exists(iu_xray_reports_df_path):\n",
    "    data = save_reports_df()\n",
    "    iu_xray_reports_df = pd.DataFrame(data)\n",
    "    iu_xray_reports_df.to_csv(iu_xray_reports_df_path, index=False)\n",
    "    print(f\"Dataframe saved to {iu_xray_reports_df_path}\")\n",
    "else:\n",
    "    print(f\"Dataframe already exists at {iu_xray_reports_df_path}\")\n",
    "    iu_xray_reports_df = pd.read_csv(iu_xray_reports_df_path)\n",
    "\n",
    "\n",
    "# displaying the stored dataframe\n",
    "print(\"\\n\\nDataframe Shape:\", iu_xray_reports_df.shape)\n",
    "\n",
    "print(\"\\n\\nDataframe Information:\\n\")\n",
    "display(iu_xray_reports_df.info())\n",
    "\n",
    "print(\"\\n\\nDisplaying Dataframe:\\n\")\n",
    "display(iu_xray_reports_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "bw4Ylfa94M1o",
    "outputId": "5ef503a0-265c-423b-8cae-1d36b136134d"
   },
   "outputs": [],
   "source": [
    "'''Displaying the Number of Images per Report'''\n",
    "\n",
    "# displaying the distribution of number of images per report\n",
    "reports_count = iu_xray_reports_df['image_count'].value_counts().rename_axis('images_qty').reset_index(name='reports_count')\n",
    "print(\"\\n\\nNumber of Images per Report:\\n\")\n",
    "display(reports_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Checking for Duplicates'''\n",
    "\n",
    "# Check for duplicate values in the 'pmc_id' column\n",
    "duplicates_in_pmc_id = iu_xray_reports_df['pmc_id'].duplicated()\n",
    "num_duplicates = duplicates_in_pmc_id.sum()\n",
    "\n",
    "# Display the duplicated rows\n",
    "duplicated_rows = iu_xray_reports_df[duplicates_in_pmc_id]\n",
    "print(f\"Number of duplicates in 'pmc_id' column: {num_duplicates}\")\n",
    "print(\"Duplicated rows in 'pmc_id' column:\")\n",
    "print(duplicated_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UouFxQwMNeo"
   },
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cGf99_CMV47"
   },
   "source": [
    "### **Preprocess Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JTClOSxeSCOM",
    "outputId": "811cbc93-70e7-4d60-f213-26238488c44d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Images already exist at: ./datasets/iu_xray/output/images_preprocessed\n"
     ]
    }
   ],
   "source": [
    "'''Preprocessing Images - Resizing, Tensor Conversion and Normalization'''\n",
    "\n",
    "# function to preprocess and save images\n",
    "def preprocess_images(input_dir, output_dir):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    cnt = 0\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.png'):\n",
    "            cnt += 1\n",
    "            print(f\"Preprocessing File {cnt} out of {len(os.listdir(input_dir))}: {filename}\", end=\"\\r\")\n",
    "\n",
    "            image_path = os.path.join(input_dir, filename)\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            processed_image = preprocess(image)\n",
    "\n",
    "            processed_image_path = os.path.join(output_dir, filename)\n",
    "\n",
    "            processed_image_pil = transforms.ToPILImage()(processed_image)\n",
    "            processed_image_pil.save(processed_image_path)\n",
    "\n",
    "\n",
    "# preprocessing images\n",
    "iu_xray_images_preprocessed = os.path.join(output_directory, 'images_preprocessed')\n",
    "if not os.path.exists(iu_xray_images_preprocessed):\n",
    "    print(f\"Preprocessing Images to: {iu_xray_images_preprocessed}\")\n",
    "    preprocess_images(iu_xray_images, iu_xray_images_preprocessed)\n",
    "    print(f\"Preprocessed Images saved to: {iu_xray_images_preprocessed}\")\n",
    "else:\n",
    "    print(f\"Preprocessed Images already exist at: {iu_xray_images_preprocessed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvdRoNqXMZlN"
   },
   "source": [
    "### **Preprocess Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8sW8uz8-plE"
   },
   "outputs": [],
   "source": [
    "'''Preprocessing Text - Lowercasing, Decontracting, Punctuation Removal, Number Removal, Two-Letter Word Removal, Stop Word Removal, Spell Checking, Extra Space Removal'''\n",
    "\n",
    "# download nltk resources and initialize spell checker\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "spell = SpellChecker()\n",
    "\n",
    "\n",
    "# function to convert text to lowercase\n",
    "def lowercase(text):\n",
    "    return text.lower() if isinstance(text, str) else text\n",
    "\n",
    "\n",
    "# function to decontract words\n",
    "def decontracted(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    contractions = {\n",
    "        \"won't\": \"will not\", \"can't\": \"can not\", \"couldn't\": \"could not\",\n",
    "        \"shouldn't\": \"should not\", \"wouldn't\": \"would not\", \"n't\": \" not\",\n",
    "        \"'re\": \" are\", \"'s\": \" is\", \"'d\": \" would\", \"'ll\": \" will\",\n",
    "        \"'t\": \" not\", \"'ve\": \" have\", \"'m\": \" am\"\n",
    "    }\n",
    "    for contraction, full_form in contractions.items():\n",
    "        text = text.replace(contraction, full_form)\n",
    "    return text\n",
    "\n",
    "\n",
    "# function to remove punctuations\n",
    "def rem_punctuations(text):\n",
    "    return re.sub(r'[^\\w\\s]', ' ', text) if isinstance(text, str) else text\n",
    "\n",
    "\n",
    "# function to remove numbers\n",
    "def rem_numbers(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    text = re.sub(r'[xX]{2,}', '', text)\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "\n",
    "# function to remove two-letter words except \"no\" and \"ct\"\n",
    "def rem_two_letter_words(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    return ' '.join(word for word in text.split() if len(word) > 2 or word in [\"no\", \"ct\"])\n",
    "\n",
    "\n",
    "# function to remove stop words\n",
    "def rem_stop_words(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return ' '.join(word for word in text.split() if word not in stop_words)\n",
    "\n",
    "\n",
    "# function to correct spelling\n",
    "def correct_spelling(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    corrected = []\n",
    "    for word in text.split():\n",
    "        corrected_word = list(spell.candidates(word))[0] if spell.candidates(word) else word\n",
    "        corrected.append(corrected_word)\n",
    "    return ' '.join(corrected)\n",
    "\n",
    "\n",
    "# function to remove extra spaces\n",
    "def rem_extra_spaces(text):\n",
    "    return ' '.join(text.split()) if isinstance(text, str) else text\n",
    "\n",
    "\n",
    "# function to handle full stops\n",
    "def handle_fullstops(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    text = re.sub(r'\\.\\.+', '.', text) \n",
    "    return re.sub(r'\\.', ' . ', text) \n",
    "\n",
    "\n",
    "# function to remove apostrophes\n",
    "def rem_apostrophes(text):\n",
    "    return re.sub(\"'\", '', text) if isinstance(text, str) else text\n",
    "\n",
    "\n",
    "# function to preprocess text\n",
    "def preprocess_text(data):\n",
    "    preprocessed = []\n",
    "    for sentence in tqdm(data.values):\n",
    "        sentence = str(sentence)\n",
    "        sentence = lowercase(sentence)\n",
    "        sentence = decontracted(sentence)\n",
    "        sentence = rem_punctuations(sentence)\n",
    "        sentence = rem_numbers(sentence)\n",
    "        sentence = rem_two_letter_words(sentence)\n",
    "        sentence = rem_stop_words(sentence)\n",
    "        sentence = correct_spelling(sentence)\n",
    "        sentence = rem_extra_spaces(sentence)\n",
    "        sentence = handle_fullstops(sentence)\n",
    "        sentence = rem_apostrophes(sentence)\n",
    "        \n",
    "        preprocessed.append(sentence)\n",
    "\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Preprocessing Text - Lowercasing, Decontracting, Punctuation Removal, Number Removal, Two-Letter Word Removal, Stop Word Removal, Spell Checking, Extra Space Removal'''\n",
    "\n",
    "# load your DataFrame (replace with actual path)\n",
    "iu_xray_reports_df = os.path.join(output_directory, 'iu_xray_reports_df.csv')\n",
    "df = pd.read_csv(iu_xray_reports_df)\n",
    "\n",
    "\n",
    "# apply preprocessing on specific columns if they exist\n",
    "preprocess_columns = ['findings']\n",
    "for column in preprocess_columns:\n",
    "    if column in df.columns:\n",
    "        print(f\"Preprocessing Column: {column}\")\n",
    "        df[column] = df[column].fillna('none').astype(str)\n",
    "        df[column] = preprocess_text(df[column])\n",
    "        output_path = os.path.join(output_directory, f'preprocessed_{column}.csv')\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Saved preprocessed '{column}' column to: {output_path}\")\n",
    "        \n",
    "        \n",
    "# split into Train/Validation/Test (70%/10%/20%)\n",
    "output_path = os.path.join(output_directory, f'preprocessed_findings.csv')\n",
    "df = pd.read_csv(output_path)        \n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=(2/3), random_state=42)\n",
    "\n",
    "\n",
    "# save the splits\n",
    "train_path = os.path.join(output_directory, 'train_data.csv')\n",
    "train_df.to_csv(train_path, index=False)\n",
    "display(train_df.head())\n",
    "print(f\"Train data saved to: {train_path}\")\n",
    "\n",
    "val_path = os.path.join(output_directory, 'val_data.csv')\n",
    "val_df.to_csv(val_path, index=False)\n",
    "display(val_df.head())\n",
    "print(f\"Validation data saved to: {val_path}\")\n",
    "\n",
    "test_path = os.path.join(output_directory, 'test_data.csv')\n",
    "test_df.to_csv(test_path, index=False)\n",
    "display(test_df.head())\n",
    "print(f\"Test data saved to: {test_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Indexing the Training Data'''\n",
    "\n",
    "# indexing the train data\n",
    "df = pd.read_csv(train_path)     \n",
    "df = df[['pmc_id', 'findings', 'image_1', 'image_2']]\n",
    "df['index'] = range(1, len(df) + 1)\n",
    "\n",
    "\n",
    "# display the modified DataFrame to check the output\n",
    "print(\"Shape of the DataFrame:\", df.shape)\n",
    "display(df.head(20))\n",
    "df.to_csv(train_path, index=False)\n",
    "print(f\"Train data saved to: {train_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Creating Filtered Dataframes'''\n",
    "\n",
    "# filtering the data\n",
    "filtered_train_path = os.path.join(output_directory, 'filtered_train_data.csv')\n",
    "df = pd.read_csv(train_path)  \n",
    "print(\"Shape of the DataFrame Before:\", df.shape)\n",
    "\n",
    "filtered_df = df.dropna(subset=['image_1', 'image_2'], how='all')\n",
    "print(\"Shape of the DataFrame After:\", filtered_df.shape)\n",
    "\n",
    "filtered_df.to_csv(filtered_train_path, index=False)\n",
    "print(f\"Dataframe saved to: {filtered_train_path}\")\n",
    "\n",
    "\n",
    "# filtering the data\n",
    "filtered_val_path = os.path.join(output_directory, 'filtered_val_data.csv')\n",
    "df = pd.read_csv(val_path)  \n",
    "print(\"Shape of the DataFrame Before:\", df.shape)\n",
    "\n",
    "filtered_df = df.dropna(subset=['image_1', 'image_2'], how='all')\n",
    "print(\"Shape of the DataFrame After:\", filtered_df.shape)\n",
    "\n",
    "filtered_df.to_csv(filtered_val_path, index=False)\n",
    "print(f\"Dataframe saved to: {filtered_val_path}\")\n",
    "\n",
    "\n",
    "# filtering the data\n",
    "filtered_test_path = os.path.join(output_directory, 'filtered_test_data.csv')\n",
    "df = pd.read_csv(test_path)  \n",
    "print(\"Shape of the DataFrame Before:\", df.shape)\n",
    "\n",
    "filtered_df = df.dropna(subset=['image_1', 'image_2'], how='all')\n",
    "print(\"Shape of the DataFrame After:\", filtered_df.shape)\n",
    "\n",
    "filtered_df.to_csv(filtered_test_path, index=False)\n",
    "print(f\"Dataframe saved to: {filtered_test_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8sW8uz8-plE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Preprocessing Text - Lowercasing, Decontracting, Punctuation Removal, Number Removal, Two-Letter Word Removal, Stop Word Removal, Spell Checking, Extra Space Removal'''\n",
    "\n",
    "# download nltk resources and initialize spell checker\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "spell = SpellChecker()\n",
    "\n",
    "\n",
    "# function to convert text to lowercase\n",
    "def lowercase(text):\n",
    "    return text.lower() if isinstance(text, str) else text\n",
    "\n",
    "\n",
    "# function to decontract words\n",
    "def decontracted(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    contractions = {\n",
    "        \"won't\": \"will not\", \"can't\": \"can not\", \"couldn't\": \"could not\",\n",
    "        \"shouldn't\": \"should not\", \"wouldn't\": \"would not\", \"n't\": \" not\",\n",
    "        \"'re\": \" are\", \"'s\": \" is\", \"'d\": \" would\", \"'ll\": \" will\",\n",
    "        \"'t\": \" not\", \"'ve\": \" have\", \"'m\": \" am\"\n",
    "    }\n",
    "    for contraction, full_form in contractions.items():\n",
    "        text = text.replace(contraction, full_form)\n",
    "    return text\n",
    "\n",
    "\n",
    "# function to remove punctuations\n",
    "def rem_punctuations(text):\n",
    "    return re.sub(r'[^\\w\\s]', ' ', text) if isinstance(text, str) else text\n",
    "\n",
    "\n",
    "# function to remove numbers\n",
    "def rem_numbers(text):\n",
    "    return re.sub(r'\\d+', ' ', text) if isinstance(text, str) else text\n",
    "\n",
    "\n",
    "# function to remove two-letter words except \"no\" and \"ct\"\n",
    "def rem_two_letter_words(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    return ' '.join(word for word in text.split() if len(word) > 2 or word in [\"no\", \"ct\"])\n",
    "\n",
    "\n",
    "# function to remove stop words\n",
    "def rem_stop_words(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return ' '.join(word for word in text.split() if word not in stop_words)\n",
    "\n",
    "\n",
    "# function to correct spelling\n",
    "def correct_spelling(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    corrected = []\n",
    "    for word in text.split():\n",
    "        corrected_word = list(spell.candidates(word))[0] if spell.candidates(word) else word\n",
    "        corrected.append(corrected_word)\n",
    "    return ' '.join(corrected)\n",
    "\n",
    "\n",
    "# function to remove extra spaces\n",
    "def rem_extra_spaces(text):\n",
    "    return ' '.join(text.split()) if isinstance(text, str) else text\n",
    "\n",
    "\n",
    "# function to preprocess text\n",
    "def preprocess_text(data):\n",
    "    preprocessed = []\n",
    "    for sentence in tqdm(data.values):\n",
    "        sentence = str(sentence)\n",
    "        sentence = lowercase(sentence)\n",
    "        sentence = decontracted(sentence)\n",
    "        sentence = rem_punctuations(sentence)\n",
    "        sentence = rem_numbers(sentence)\n",
    "        sentence = rem_two_letter_words(sentence)\n",
    "        sentence = rem_stop_words(sentence)\n",
    "        sentence = correct_spelling(sentence)\n",
    "        sentence = rem_extra_spaces(sentence)\n",
    "        \n",
    "        preprocessed.append(sentence)\n",
    "\n",
    "    return preprocessed\n",
    "\n",
    "\n",
    "# path to the preprocessed dataframe\n",
    "iu_xray_reports_preprocessed_df_path = os.path.join(output_directory, 'iu_xray_reports_preprocessed_sorted_df.csv')\n",
    "# report_data_path = os.path.join(output_directory,'iu_xray_reports_preprocessed_sorted_df.csv')\n",
    "iu_xray_reports_preprocessed_df = iu_xray_reports_df.copy()\n",
    "\n",
    "\n",
    "# preprocessing text columns in the dataframe\n",
    "if os.path.exists(iu_xray_reports_preprocessed_df_path):\n",
    "    print(f\"Preprocessing Text of DataFrame {iu_xray_reports_df_path} to: {iu_xray_reports_preprocessed_df_path}\")\n",
    "    \n",
    "    preprocess_caption = True\n",
    "    preprocess_comparison = True\n",
    "    preprocess_indication = True\n",
    "    preprocess_findings = True\n",
    "    preprocess_impression = True\n",
    "    \n",
    "    if preprocess_caption and 'caption' in iu_xray_reports_preprocessed_df.columns:\n",
    "        print(\"Preprocessing Column: caption\")\n",
    "        iu_xray_reports_preprocessed_df['caption'] = iu_xray_reports_preprocessed_df['caption'].fillna('unknown').astype(str)\n",
    "        iu_xray_reports_preprocessed_df['caption'] = preprocess_text(iu_xray_reports_preprocessed_df['caption'])\n",
    "        iu_xray_reports_preprocessed_df.to_csv(iu_xray_reports_preprocessed_df_path, index=False)\n",
    "        print(f\"Saved preprocessed 'caption' column to: {iu_xray_reports_preprocessed_df_path}\")\n",
    "    \n",
    "    if preprocess_comparison and 'comparison' in iu_xray_reports_preprocessed_df.columns:\n",
    "        print(\"Preprocessing Column: comparison\")\n",
    "        iu_xray_reports_preprocessed_df['comparison'] = iu_xray_reports_preprocessed_df['comparison'].fillna('none').astype(str)\n",
    "        iu_xray_reports_preprocessed_df['comparison'] = preprocess_text(iu_xray_reports_preprocessed_df['comparison'])\n",
    "        iu_xray_reports_preprocessed_df.to_csv(iu_xray_reports_preprocessed_df_path, index=False)\n",
    "        print(f\"Saved preprocessed 'comparison' column to: {iu_xray_reports_preprocessed_df_path}\")\n",
    "    \n",
    "    if preprocess_indication and 'indication' in iu_xray_reports_preprocessed_df.columns:\n",
    "        print(\"Preprocessing Column: indication\")\n",
    "        iu_xray_reports_preprocessed_df['indication'] = iu_xray_reports_preprocessed_df['indication'].fillna('none').astype(str)\n",
    "        iu_xray_reports_preprocessed_df['indication'] = preprocess_text(iu_xray_reports_preprocessed_df['indication'])\n",
    "        iu_xray_reports_preprocessed_df.to_csv(iu_xray_reports_preprocessed_df_path, index=False)\n",
    "        print(f\"Saved preprocessed 'indication' column to: {iu_xray_reports_preprocessed_df_path}\")\n",
    "    \n",
    "    if preprocess_findings and 'findings' in iu_xray_reports_preprocessed_df.columns:\n",
    "        print(\"Preprocessing Column: findings\")\n",
    "        iu_xray_reports_preprocessed_df['findings'] = iu_xray_reports_preprocessed_df['findings'].fillna('none').astype(str)\n",
    "        iu_xray_reports_preprocessed_df['findings'] = preprocess_text(iu_xray_reports_preprocessed_df['findings'])\n",
    "        iu_xray_reports_preprocessed_df.to_csv(iu_xray_reports_preprocessed_df_path, index=False)\n",
    "        print(f\"Saved preprocessed 'findings' column to: {iu_xray_reports_preprocessed_df_path}\")\n",
    "    \n",
    "    if preprocess_impression and 'impression' in iu_xray_reports_preprocessed_df.columns:\n",
    "        print(\"Preprocessing Column: impression\")\n",
    "        iu_xray_reports_preprocessed_df['impression'] = iu_xray_reports_preprocessed_df['impression'].fillna('none').astype(str)\n",
    "        iu_xray_reports_preprocessed_df['impression'] = preprocess_text(iu_xray_reports_preprocessed_df['impression'])\n",
    "        iu_xray_reports_preprocessed_df.to_csv(iu_xray_reports_preprocessed_df_path, index=False)\n",
    "        print(f\"Saved preprocessed 'impression' column to: {iu_xray_reports_preprocessed_df_path}\")\n",
    "else:\n",
    "    print(f\"Preprocessed Text of DataFrame {iu_xray_reports_df_path} already exists at: {iu_xray_reports_preprocessed_df_path}\")\n",
    "    \n",
    "\n",
    "# displaying the preprocessed dataframe\n",
    "iu_xray_reports_preprocessed_df = pd.read_csv(iu_xray_reports_preprocessed_df_path)\n",
    "display(iu_xray_reports_preprocessed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize spell checker\n",
    "spell = SpellChecker()\n",
    "\n",
    "# Combined preprocessing functions\n",
    "def lowercase(text):\n",
    "    \"\"\"Convert text to lowercase.\"\"\"\n",
    "    return text.lower() if isinstance(text, str) else text\n",
    "\n",
    "def decontracted(text):\n",
    "    \"\"\"Decontract phrases in the text.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    contractions = {\n",
    "        \"won't\": \"will not\", \"can't\": \"can not\", \"couldn't\": \"could not\",\n",
    "        \"shouldn't\": \"should not\", \"wouldn't\": \"would not\", \"n't\": \" not\",\n",
    "        \"'re\": \" are\", \"'s\": \" is\", \"'d\": \" would\", \"'ll\": \" will\",\n",
    "        \"'t\": \" not\", \"'ve\": \" have\", \"'m\": \" am\"\n",
    "    }\n",
    "    for contraction, full_form in contractions.items():\n",
    "        text = text.replace(contraction, full_form)\n",
    "    return text\n",
    "\n",
    "def rem_punctuations(text):\n",
    "    \"\"\"Remove punctuations except for full stops.\"\"\"\n",
    "    return re.sub(r'[^\\w\\s.]', '', text) if isinstance(text, str) else text\n",
    "\n",
    "def rem_numbers(text):\n",
    "    \"\"\"Remove numbers and irrelevant text like 'XXXX'.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    text = re.sub(r'[xX]{2,}', '', text)  # Removes sequences like 'XXXX'\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "def rem_two_letter_words(text):\n",
    "    \"\"\"Remove words with fewer than 2 characters except 'no' and 'ct'.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    return ' '.join(word for word in text.split() if len(word) > 2 or word in [\"no\", \"ct\"])\n",
    "\n",
    "def rem_stop_words(text):\n",
    "    \"\"\"Remove stop words.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return ' '.join(word for word in text.split() if word not in stop_words)\n",
    "\n",
    "def correct_spelling(text):\n",
    "    \"\"\"Correct spelling using a spell checker.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    corrected = []\n",
    "    for word in text.split():\n",
    "        corrected_word = list(spell.candidates(word))[0] if spell.candidates(word) else word\n",
    "        corrected.append(corrected_word)\n",
    "    return ' '.join(corrected)\n",
    "\n",
    "def rem_extra_spaces(text):\n",
    "    \"\"\"Remove extra spaces.\"\"\"\n",
    "    return ' '.join(text.split()) if isinstance(text, str) else text\n",
    "\n",
    "def handle_fullstops(text):\n",
    "    \"\"\"Handle full stops, spacing around them, and remove multiple consecutive stops.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    text = re.sub(r'\\.\\.+', '.', text)  # Convert multiple full stops to single\n",
    "    return re.sub(r'\\.', ' . ', text)  # Add space around full stops\n",
    "\n",
    "def rem_apostrophes(text):\n",
    "    \"\"\"Remove apostrophes.\"\"\"\n",
    "    return re.sub(\"'\", '', text) if isinstance(text, str) else text\n",
    "\n",
    "# Combined text preprocessing function\n",
    "def preprocess_text(data):\n",
    "    \"\"\"Apply combined preprocessing steps.\"\"\"\n",
    "    preprocessed = []\n",
    "    for sentence in tqdm(data.values):\n",
    "        sentence = str(sentence)\n",
    "        sentence = lowercase(sentence)\n",
    "        sentence = decontracted(sentence)\n",
    "        sentence = rem_punctuations(sentence)\n",
    "        sentence = rem_numbers(sentence)\n",
    "        sentence = rem_two_letter_words(sentence)\n",
    "        sentence = rem_stop_words(sentence)\n",
    "        sentence = correct_spelling(sentence)\n",
    "        sentence = rem_apostrophes(sentence)\n",
    "        sentence = handle_fullstops(sentence)\n",
    "        sentence = rem_extra_spaces(sentence)\n",
    "        \n",
    "        preprocessed.append(sentence)\n",
    "\n",
    "    return preprocessed\n",
    "\n",
    "# Load your DataFrame (replace with actual path)\n",
    "input_path = os.path.join(output_directory, 'iu_xray_reports_sorted_df.csv')\n",
    "# output_directory = os.path.join(output_directory, 'iu_xray_reports_sorted_preprocessed_df.csv')\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Select only the columns 'pmc_id', 'findings', 'image_1', and 'image_2'\n",
    "\n",
    "# Apply preprocessing on specific columns if they exist\n",
    "preprocess_columns = ['findings']\n",
    "for column in preprocess_columns:\n",
    "    if column in df.columns:\n",
    "        print(f\"Preprocessing Column: {column}\")\n",
    "        df[column] = df[column].fillna('none').astype(str)\n",
    "        df[column] = preprocess_text(df[column])\n",
    "        output_path = os.path.join(output_directory, f'preprocessed_{column}.csv')\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Saved preprocessed '{column}' column to: {output_path}\")\n",
    "\n",
    "# Split into Train/Validation/Test (70%/10%/20%)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=(2/3), random_state=42)\n",
    "\n",
    "# Save the splits\n",
    "train_path = os.path.join(output_directory, 'train_data.csv')\n",
    "val_path = os.path.join(output_directory, 'val_data.csv')\n",
    "test_path = os.path.join(output_directory, 'test_data.csv')\n",
    "\n",
    "train_df.to_csv(train_path, index=False)\n",
    "val_df.to_csv(val_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "\n",
    "print(f\"Train data saved to: {train_path}\")\n",
    "print(f\"Validation data saved to: {val_path}\")\n",
    "print(f\"Test data saved to: {test_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasets/iu_xray/output/test_data.csv\")     \n",
    "df = df[['pmc_id', 'findings', 'image_1', 'image_2']]\n",
    "\n",
    "# Display the modified DataFrame to check the output\n",
    "\n",
    "df['index'] = range(1, len(df) + 1)\n",
    "print(\"Shape of the DataFrame:\", df.shape)\n",
    "print(df.head())\n",
    "df.to_csv(test_path, index=False)\n",
    "\n",
    "print(f\"Train data saved to: {test_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train_path = os.path.join(output_directory, 'filtered_train_data.csv')\n",
    "filtered_val_path = os.path.join(output_directory, 'filtered_val_data.csv')\n",
    "filtered_test_path = os.path.join(output_directory, 'filtered_test_data.csv')\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./datasets/iu_xray/output/val_data.csv\")  \n",
    "print(\"Shape of the DataFrame:\", df.shape)\n",
    "filtered_df = df.dropna(subset=['image_1', 'image_2'], how='all')\n",
    "print(\"Shape of the DataFrame:\", filtered_df.shape)\n",
    "filtered_df.to_csv(filtered_val_path, index=False)\n",
    "\n",
    "print(f\"Train data saved to: {filtered_val_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlOl6I0rMa68"
   },
   "source": [
    "### **Create Data Loaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Image Data Loaders to Supply Dataset to Model in Batches'''\n",
    "\n",
    "# classes in dataset\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "# function to load image data with transformation and batching\n",
    "def load_preprocessed_images(image_dir, batch_size=32):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    dataset = CustomImageDataset(image_dir, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Text Data Loaders to Supply Dataset to Model in Batches'''\n",
    "\n",
    "# classes in dataset\n",
    "class CustomTextDataset(Dataset):\n",
    "    def __init__(self, text_list, tokenizer, max_length=512):\n",
    "        self.text_list = text_list\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text_list[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {key: tensor.squeeze(0) for key, tensor in encoding.items()}\n",
    "\n",
    "\n",
    "# function to load text data with batching\n",
    "def load_preprocessed_texts(text_list, tokenizer, batch_size=32, max_length=512):\n",
    "    dataset = CustomTextDataset(text_list, tokenizer, max_length)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQ0H-X3HMgS1"
   },
   "source": [
    "## **Model Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsELnlXpMjGX"
   },
   "source": [
    "### **Visual Extractor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmc_id</th>\n",
       "      <th>findings</th>\n",
       "      <th>image_1</th>\n",
       "      <th>image_2</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3790</td>\n",
       "      <td>low lung volumes .  elevation the right hemidi...</td>\n",
       "      <td>CXR3790_IM-1904-0001-0001.jpg: Xray Chest PA a...</td>\n",
       "      <td>CXR3790_IM-1904-0001-0002.jpg: Xray Chest PA a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2282</td>\n",
       "      <td>the lungs are clear bilaterally .  specificall...</td>\n",
       "      <td>CXR2282_IM-0869-1001.jpg: PA and lateral chest...</td>\n",
       "      <td>CXR2282_IM-0869-2001.jpg: PA and lateral chest...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2841</td>\n",
       "      <td>the heart normal size and contour .  the lungs...</td>\n",
       "      <td>CXR2841_IM-1253-2001.jpg: Xray Chest PA and La...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2192</td>\n",
       "      <td>no focal lung consolidation .  no pneumothora ...</td>\n",
       "      <td>CXR2192_IM-0802-2002.jpg: Xray Chest PA and La...</td>\n",
       "      <td>CXR2192_IM-0802-3003.jpg: Xray Chest PA and La...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3149</td>\n",
       "      <td>the lungs are hyperepanded .  cardiomediastina...</td>\n",
       "      <td>CXR3149_IM-1480-1001.jpg: PA and Lateral views...</td>\n",
       "      <td>CXR3149_IM-1480-2001.jpg: PA and Lateral views...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3673</td>\n",
       "      <td>the heart normal size .  the mediastinal conto...</td>\n",
       "      <td>CXR3673_IM-1828-1001.jpg: CHEST 2V FRONTAL/LAT...</td>\n",
       "      <td>CXR3673_IM-1828-1002.jpg: CHEST 2V FRONTAL/LAT...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>471</td>\n",
       "      <td>the heart normal size .  the mediastinum unrem...</td>\n",
       "      <td>CXR471_IM-2099-2002.jpg: Xray Chest PA and Lat...</td>\n",
       "      <td>CXR471_IM-2099-3003.jpg: Xray Chest PA and Lat...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1226</td>\n",
       "      <td>the heart size within normal limits .  trachea...</td>\n",
       "      <td>CXR1226_IM-0150-1001.jpg: The chest 2 views PA...</td>\n",
       "      <td>CXR1226_IM-0150-1002.jpg: The chest 2 views PA...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1697</td>\n",
       "      <td>lungs are clear bilaterally .  cardiac and med...</td>\n",
       "      <td>CXR1697_IM-0458-1001.jpg: PA and lateral chest...</td>\n",
       "      <td>CXR1697_IM-0458-2001.jpg: PA and lateral chest...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>845</td>\n",
       "      <td>minimal subsegmental atelectasis posteriorly ....</td>\n",
       "      <td>CXR845_IM-2367-1001.jpg: PA and lateral views ...</td>\n",
       "      <td>CXR845_IM-2367-1002.jpg: PA and lateral views ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pmc_id                                           findings   \n",
       "0    3790  low lung volumes .  elevation the right hemidi...  \\\n",
       "1    2282  the lungs are clear bilaterally .  specificall...   \n",
       "2    2841  the heart normal size and contour .  the lungs...   \n",
       "3    2192  no focal lung consolidation .  no pneumothora ...   \n",
       "4    3149  the lungs are hyperepanded .  cardiomediastina...   \n",
       "5    3673  the heart normal size .  the mediastinal conto...   \n",
       "6     471  the heart normal size .  the mediastinum unrem...   \n",
       "7    1226  the heart size within normal limits .  trachea...   \n",
       "8    1697  lungs are clear bilaterally .  cardiac and med...   \n",
       "9     845  minimal subsegmental atelectasis posteriorly ....   \n",
       "\n",
       "                                             image_1   \n",
       "0  CXR3790_IM-1904-0001-0001.jpg: Xray Chest PA a...  \\\n",
       "1  CXR2282_IM-0869-1001.jpg: PA and lateral chest...   \n",
       "2  CXR2841_IM-1253-2001.jpg: Xray Chest PA and La...   \n",
       "3  CXR2192_IM-0802-2002.jpg: Xray Chest PA and La...   \n",
       "4  CXR3149_IM-1480-1001.jpg: PA and Lateral views...   \n",
       "5  CXR3673_IM-1828-1001.jpg: CHEST 2V FRONTAL/LAT...   \n",
       "6  CXR471_IM-2099-2002.jpg: Xray Chest PA and Lat...   \n",
       "7  CXR1226_IM-0150-1001.jpg: The chest 2 views PA...   \n",
       "8  CXR1697_IM-0458-1001.jpg: PA and lateral chest...   \n",
       "9  CXR845_IM-2367-1001.jpg: PA and lateral views ...   \n",
       "\n",
       "                                             image_2  index  \n",
       "0  CXR3790_IM-1904-0001-0002.jpg: Xray Chest PA a...      1  \n",
       "1  CXR2282_IM-0869-2001.jpg: PA and lateral chest...      2  \n",
       "2                                                NaN      3  \n",
       "3  CXR2192_IM-0802-3003.jpg: Xray Chest PA and La...      4  \n",
       "4  CXR3149_IM-1480-2001.jpg: PA and Lateral views...      5  \n",
       "5  CXR3673_IM-1828-1002.jpg: CHEST 2V FRONTAL/LAT...      6  \n",
       "6  CXR471_IM-2099-3003.jpg: Xray Chest PA and Lat...      7  \n",
       "7  CXR1226_IM-0150-1002.jpg: The chest 2 views PA...      8  \n",
       "8  CXR1697_IM-0458-2001.jpg: PA and lateral chest...      9  \n",
       "9  CXR845_IM-2367-1002.jpg: PA and lateral views ...     10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features since they are not precomputed...\n",
      "1, 3790 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "1, 3790 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "2, 2282 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "2, 2282 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "3, 2841 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "3, 2841 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "4, 2192 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "4, 2192 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "5, 3149 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "5, 3149 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "6, 3673 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "6, 3673 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "7, 471 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "7, 471 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "8, 1226 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "8, 1226 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "9, 1697 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "9, 1697 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "10, 845 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "10, 845 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "11, 1121 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "11, 1121 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "12, 3722 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "12, 3722 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "13, 3728 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "13, 3728 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "14, 3208 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "14, 3208 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "15, 430 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "15, 430 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "16, 329 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "16, 329 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "17, 2078 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "17, 2078 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "18, 2444 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "18, 2444 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "19, 1605 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "19, 1605 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "20, 689 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "20, 689 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "21, 1505 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "21, 1505 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "23, 3109 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "23, 3109 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "24, 2559 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "24, 2559 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "25, 2211 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "25, 2211 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "26, 2838 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "26, 2838 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "27, 3745 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "27, 3745 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "29, 543 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "29, 543 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "30, 168 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "30, 168 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "31, 1649 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "31, 1649 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "32, 1975 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "32, 1975 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "33, 3904 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "33, 3904 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "34, 3803 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "34, 3803 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "35, 3721 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "35, 3721 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "36, 2911 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "36, 2911 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "37, 1654 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "37, 1654 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "38, 2798 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "38, 2798 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "39, 186 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "39, 186 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "40, 1743 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "40, 1743 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "41, 954 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "41, 954 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "42, 441 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "42, 441 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "43, 1811 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "43, 1811 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "44, 58 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "44, 58 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "45, 112 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "45, 112 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "46, 1969 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "46, 1969 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "47, 3654 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "47, 3654 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "48, 91 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "48, 91 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "49, 1351 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "49, 1351 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "50, 3442 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "50, 3442 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "51, 3929 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "51, 3929 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "52, 1926 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "52, 1926 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "53, 2765 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "53, 2765 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "54, 1005 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "54, 1005 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "55, 2949 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "55, 2949 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "56, 2183 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "56, 2183 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "57, 59 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "57, 59 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "59, 2047 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "59, 2047 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "60, 2175 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "60, 2175 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "61, 1352 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "61, 1352 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "62, 1187 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "62, 1187 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "63, 1883 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "63, 1883 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "64, 492 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "64, 492 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "65, 2264 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "65, 2264 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "66, 1246 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "66, 1246 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "67, 3179 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "67, 3179 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "68, 2959 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "68, 2959 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "69, 3857 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "69, 3857 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "70, 3358 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "70, 3358 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "71, 3656 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "71, 3656 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "72, 3858 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "72, 3858 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "73, 3100 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "73, 3100 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "74, 2668 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "74, 2668 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "75, 2327 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "75, 2327 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "76, 733 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "76, 733 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "77, 3863 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "77, 3863 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "78, 744 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "78, 744 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "79, 1501 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "79, 1501 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "80, 1196 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "80, 1196 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "81, 3796 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "81, 3796 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "82, 2575 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "82, 2575 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "83, 2519 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "83, 2519 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "84, 1666 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "84, 1666 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "85, 3712 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "85, 3712 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "86, 3372 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "86, 3372 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "87, 1288 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "87, 1288 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "88, 2802 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "88, 2802 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "90, 390 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "90, 390 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "91, 1122 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "91, 1122 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "92, 2024 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "92, 2024 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "93, 1766 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "93, 1766 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "94, 1657 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "94, 1657 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "95, 2947 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "95, 2947 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "96, 405 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "96, 405 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "97, 2455 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "97, 2455 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "98, 1962 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "98, 1962 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "99, 3820 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "99, 3820 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "100, 3217 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "100, 3217 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "101, 48 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "101, 48 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "102, 2495 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "102, 2495 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "103, 3086 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "103, 3086 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "104, 2344 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "104, 2344 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "105, 829 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "105, 829 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "106, 1830 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "106, 1830 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "107, 3589 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "107, 3589 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "108, 241 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "108, 241 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "109, 1107 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "109, 1107 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "110, 905 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "110, 905 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "111, 2276 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "111, 2276 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "112, 3486 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "112, 3486 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "113, 2539 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "113, 2539 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "114, 1119 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "114, 1119 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "115, 1674 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "115, 1674 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "116, 1860 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "116, 1860 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "117, 177 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "117, 177 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "118, 3579 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "118, 3579 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "119, 2377 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "119, 2377 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "120, 2791 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "120, 2791 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "122, 2815 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "122, 2815 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "123, 3465 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "123, 3465 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "124, 1684 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "124, 1684 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "125, 1320 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "125, 1320 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "126, 1760 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "126, 1760 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "127, 720 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "127, 720 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "128, 664 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "128, 664 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "129, 2331 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "129, 2331 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "130, 3781 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "130, 3781 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "131, 3455 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "131, 3455 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "132, 1545 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "132, 1545 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "133, 1200 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "133, 1200 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "134, 1690 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "134, 1690 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "135, 882 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "135, 882 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "136, 2728 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "136, 2728 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "137, 205 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "137, 205 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "138, 1355 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "138, 1355 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "139, 3451 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "139, 3451 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "140, 1506 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "140, 1506 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "141, 3548 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "141, 3548 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "142, 700 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "142, 700 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "143, 2406 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "143, 2406 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "144, 1212 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "144, 1212 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "145, 2770 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "145, 2770 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "146, 3922 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "146, 3922 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "147, 3154 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "147, 3154 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "148, 3837 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "148, 3837 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "149, 3706 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "149, 3706 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "150, 3124 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "150, 3124 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "151, 2723 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "151, 2723 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "152, 3376 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "152, 3376 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "153, 3715 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "153, 3715 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "154, 2355 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "154, 2355 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "155, 3160 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "155, 3160 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "156, 2319 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "156, 2319 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "157, 3862 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "157, 3862 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "158, 2553 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "158, 2553 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "159, 1851 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "159, 1851 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "161, 2681 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "161, 2681 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "162, 2096 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "162, 2096 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "163, 1092 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "163, 1092 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "164, 2397 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "164, 2397 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "165, 892 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "165, 892 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "167, 1035 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "167, 1035 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "168, 3979 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "168, 3979 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "169, 582 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "169, 582 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "170, 3581 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "170, 3581 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "171, 799 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "171, 799 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "172, 1562 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "172, 1562 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "173, 2479 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "173, 2479 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "174, 1401 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "174, 1401 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "175, 2760 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "175, 2760 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "176, 222 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "176, 222 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "177, 2119 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "177, 2119 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "178, 3741 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "178, 3741 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "179, 3506 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "179, 3506 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "181, 3617 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "181, 3617 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "182, 3845 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "182, 3845 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "183, 2697 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "183, 2697 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "184, 3895 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "184, 3895 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "185, 3011 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "185, 3011 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "186, 1189 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "186, 1189 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "187, 2389 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "187, 2389 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "188, 3694 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "188, 3694 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "189, 3206 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "189, 3206 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "190, 770 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "190, 770 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "191, 3695 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "191, 3695 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "192, 964 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "192, 964 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "193, 776 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "193, 776 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "194, 119 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "194, 119 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "195, 1361 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "195, 1361 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "196, 1683 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "196, 1683 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "197, 3676 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "197, 3676 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "198, 1573 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "198, 1573 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "199, 155 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "199, 155 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "200, 3958 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "200, 3958 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "201, 774 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "201, 774 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "202, 642 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "202, 642 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "203, 3335 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "203, 3335 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "204, 2625 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "204, 2625 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "205, 2806 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "205, 2806 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "206, 3178 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "206, 3178 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "207, 2336 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "207, 2336 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "208, 3434 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "208, 3434 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "209, 3840 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "209, 3840 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "210, 1669 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "210, 1669 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "211, 2892 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "211, 2892 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "212, 2349 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "212, 2349 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "213, 1060 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "213, 1060 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "214, 1042 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "214, 1042 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "215, 2269 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "215, 2269 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "216, 2343 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "216, 2343 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "217, 818 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "217, 818 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "219, 411 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "219, 411 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "220, 3075 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "220, 3075 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "221, 883 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "221, 883 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "222, 3111 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "222, 3111 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "223, 2759 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "223, 2759 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "224, 1901 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "224, 1901 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "225, 3653 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "225, 3653 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "226, 354 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "226, 354 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "227, 89 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "227, 89 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "228, 3948 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "228, 3948 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "229, 3330 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "229, 3330 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "230, 3407 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "230, 3407 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "232, 3688 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "232, 3688 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "233, 811 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "233, 811 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "234, 293 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "234, 293 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "235, 165 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "235, 165 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "236, 3212 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "236, 3212 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "237, 3433 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "237, 3433 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "238, 3501 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "238, 3501 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "239, 2576 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "239, 2576 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "240, 3239 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "240, 3239 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "241, 1 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "241, 1 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "242, 318 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "242, 318 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "243, 1220 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "243, 1220 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "244, 2830 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "244, 2830 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "245, 2408 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "245, 2408 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "246, 172 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "246, 172 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "247, 281 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "247, 281 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "248, 39 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "248, 39 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "249, 772 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "249, 772 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "250, 253 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "250, 253 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "251, 2970 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "251, 2970 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "252, 240 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "252, 240 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "253, 2213 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "253, 2213 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "254, 1470 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "254, 1470 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "255, 3655 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "255, 3655 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "256, 2735 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "256, 2735 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "257, 2562 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "257, 2562 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "258, 1002 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "258, 1002 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "259, 337 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "259, 337 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "260, 3648 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "260, 3648 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "261, 2167 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "261, 2167 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "262, 3129 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "262, 3129 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "263, 3689 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "263, 3689 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "264, 1882 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "264, 1882 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "265, 565 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "265, 565 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "266, 644 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "266, 644 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "267, 1152 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "267, 1152 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "268, 3117 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "268, 3117 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "269, 3652 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "269, 3652 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "270, 3637 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "270, 3637 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "271, 2273 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "271, 2273 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "272, 2139 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "272, 2139 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "273, 3996 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "273, 3996 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "275, 3566 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "275, 3566 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "276, 617 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "276, 617 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "277, 1125 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "277, 1125 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "278, 1914 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "278, 1914 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "279, 2458 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "279, 2458 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "280, 1663 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "280, 1663 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "281, 2561 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "281, 2561 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "282, 398 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "282, 398 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "283, 3340 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "283, 3340 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "284, 3430 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "284, 3430 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "285, 1333 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "285, 1333 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "286, 1391 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "286, 1391 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "287, 2721 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "287, 2721 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "288, 504 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "288, 504 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "289, 3531 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "289, 3531 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "290, 3355 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "290, 3355 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "291, 3946 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "291, 3946 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "292, 723 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "292, 723 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "293, 1460 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "293, 1460 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "294, 1123 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "294, 1123 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "295, 921 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "295, 921 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "296, 1027 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "296, 1027 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "297, 1061 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "297, 1061 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "298, 3789 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "298, 3789 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "299, 2507 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "299, 2507 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "300, 2799 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "300, 2799 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "301, 529 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "301, 529 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "302, 215 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "302, 215 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "303, 2633 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "303, 2633 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "304, 2509 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "304, 2509 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "305, 3504 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "305, 3504 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "306, 3584 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "306, 3584 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "307, 2306 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "307, 2306 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "308, 941 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "308, 941 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "309, 1747 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "309, 1747 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "310, 1234 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "310, 1234 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "311, 2439 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "311, 2439 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "312, 1388 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "312, 1388 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "313, 482 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "313, 482 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "314, 1347 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "314, 1347 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "315, 3879 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "315, 3879 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "316, 1731 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "316, 1731 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "317, 874 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "317, 874 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "318, 695 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "318, 695 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "319, 2428 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "319, 2428 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "320, 1815 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "320, 1815 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "321, 2281 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "321, 2281 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "322, 1444 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "322, 1444 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "323, 3959 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "323, 3959 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "324, 3312 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "324, 3312 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "325, 46 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "325, 46 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "326, 3457 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "326, 3457 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "327, 513 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "327, 513 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "328, 2785 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "328, 2785 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "329, 2290 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "329, 2290 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "330, 1001 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "330, 1001 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "331, 930 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "331, 930 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "332, 1161 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "332, 1161 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "333, 2672 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "333, 2672 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "334, 2470 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "334, 2470 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "335, 3456 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "335, 3456 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "336, 3685 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "336, 3685 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "337, 615 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "337, 615 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "338, 959 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "338, 959 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "339, 3847 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "339, 3847 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "340, 1209 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "340, 1209 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "341, 3851 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "341, 3851 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "342, 32 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "342, 32 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "343, 3093 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "343, 3093 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "344, 3261 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "344, 3261 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "345, 2824 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "345, 2824 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "346, 3553 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "346, 3553 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "347, 1243 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "347, 1243 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "348, 2950 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "348, 2950 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "349, 3309 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "349, 3309 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "350, 2018 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "350, 2018 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "351, 2826 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "351, 2826 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "352, 3338 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "352, 3338 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "353, 2904 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "353, 2904 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "354, 2105 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "354, 2105 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "355, 1249 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "355, 1249 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "356, 1143 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "356, 1143 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "357, 3143 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "357, 3143 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "358, 1360 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "358, 1360 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "359, 3705 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "359, 3705 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "360, 3209 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "360, 3209 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "361, 480 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "361, 480 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "362, 2648 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "362, 2648 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "363, 1339 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "363, 1339 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "364, 912 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "364, 912 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "365, 2082 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "365, 2082 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "366, 399 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "366, 399 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "367, 1564 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "367, 1564 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "368, 3804 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "368, 3804 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "369, 208 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "369, 208 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "370, 1553 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "370, 1553 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "371, 2945 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "371, 2945 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "372, 1373 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "372, 1373 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "373, 2831 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "373, 2831 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "374, 22 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "374, 22 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "375, 2194 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "375, 2194 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "376, 1617 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "376, 1617 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "377, 132 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "377, 132 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "378, 2921 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "378, 2921 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "380, 1777 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "380, 1777 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "381, 254 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "381, 254 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "382, 64 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "382, 64 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "383, 2081 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "383, 2081 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "384, 2088 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "384, 2088 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "385, 3063 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "385, 3063 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "386, 1070 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "386, 1070 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "387, 1018 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "387, 1018 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "388, 2233 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "388, 2233 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "389, 2454 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "389, 2454 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "390, 3353 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "390, 3353 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "391, 3576 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "391, 3576 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "392, 3167 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "392, 3167 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "393, 1650 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "393, 1650 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "394, 2158 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "394, 2158 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "395, 3549 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "395, 3549 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "396, 289 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "396, 289 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "397, 3603 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "397, 3603 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "399, 99 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "399, 99 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "400, 1768 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "400, 1768 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "401, 1515 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "401, 1515 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "402, 2232 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "402, 2232 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "403, 24 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "403, 24 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "404, 1289 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "404, 1289 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "405, 1198 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "405, 1198 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "406, 2617 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "406, 2617 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "407, 3382 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "407, 3382 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "408, 831 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "408, 831 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "409, 3033 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "409, 3033 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "410, 2450 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "410, 2450 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "411, 2486 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "411, 2486 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "412, 3122 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "412, 3122 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "413, 1129 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "413, 1129 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "414, 1936 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "414, 1936 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "415, 1265 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "415, 1265 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "416, 3180 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "416, 3180 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "417, 984 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "417, 984 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "418, 1342 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "418, 1342 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "419, 136 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "419, 136 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "420, 2477 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "420, 2477 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "421, 618 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "421, 618 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "422, 3898 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "422, 3898 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "423, 1948 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "423, 1948 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "424, 3271 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "424, 3271 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "425, 2067 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "425, 2067 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "426, 602 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "426, 602 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "427, 591 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "427, 591 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "428, 2036 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "428, 2036 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "429, 3534 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "429, 3534 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "430, 404 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "430, 404 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "431, 537 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "431, 537 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "432, 3880 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "432, 3880 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "434, 3362 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "434, 3362 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "436, 2540 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "436, 2540 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "437, 2493 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "437, 2493 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "438, 2077 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "438, 2077 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "439, 3012 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "439, 3012 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "440, 1223 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "440, 1223 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "441, 438 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "441, 438 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "442, 3419 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "442, 3419 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "443, 1095 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "443, 1095 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "444, 3490 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "444, 3490 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "445, 1703 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "445, 1703 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "446, 2565 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "446, 2565 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "447, 2045 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "447, 2045 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "448, 2724 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "448, 2724 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "449, 3701 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "449, 3701 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "450, 826 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "450, 826 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "451, 2544 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "451, 2544 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "452, 1323 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "452, 1323 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "453, 2792 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "453, 2792 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "454, 2146 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "454, 2146 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "455, 1820 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "455, 1820 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "456, 3000 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "456, 3000 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "457, 3539 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "457, 3539 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "458, 1491 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "458, 1491 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "459, 3557 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "459, 3557 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "460, 128 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "460, 128 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "461, 3769 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "461, 3769 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "462, 1985 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "462, 1985 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "463, 3303 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "463, 3303 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "464, 2886 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "464, 2886 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "465, 3377 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "465, 3377 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "466, 2991 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "466, 2991 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "467, 3339 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "467, 3339 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "468, 2969 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "468, 2969 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "469, 978 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "469, 978 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "470, 43 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "470, 43 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "471, 1093 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "471, 1093 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "472, 3702 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "472, 3702 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "473, 781 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "473, 781 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "474, 309 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "474, 309 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "475, 95 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "475, 95 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "476, 412 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "476, 412 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "477, 1814 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "477, 1814 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "478, 2063 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "478, 2063 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "479, 1296 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "479, 1296 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "480, 357 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "480, 357 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "481, 3768 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "481, 3768 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "482, 2170 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "482, 2170 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "483, 1472 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "483, 1472 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "484, 1474 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "484, 1474 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "485, 169 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "485, 169 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "487, 2172 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "487, 2172 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "488, 2885 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "488, 2885 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "489, 1668 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "489, 1668 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "490, 1832 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "490, 1832 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "491, 1795 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "491, 1795 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "492, 3281 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "492, 3281 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "493, 3842 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "493, 3842 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "494, 791 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "494, 791 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "495, 3198 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "495, 3198 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "496, 609 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "496, 609 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "497, 1487 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "497, 1487 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "498, 3473 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "498, 3473 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "499, 3556 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "499, 3556 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "500, 849 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "500, 849 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "501, 3186 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "501, 3186 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "502, 2108 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "502, 2108 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "503, 2842 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "503, 2842 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "504, 3175 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "504, 3175 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "505, 3511 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "505, 3511 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "506, 3234 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "506, 3234 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "507, 2075 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "507, 2075 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "508, 836 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "508, 836 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "509, 2058 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "509, 2058 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "510, 2122 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "510, 2122 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "511, 2446 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "511, 2446 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "512, 2742 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "512, 2742 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "513, 66 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "513, 66 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "514, 3824 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "514, 3824 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "515, 1698 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "515, 1698 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "516, 154 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "516, 154 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "517, 2627 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "517, 2627 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "518, 82 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "518, 82 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "519, 1621 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "519, 1621 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "520, 1857 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "520, 1857 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "521, 3616 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "521, 3616 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "522, 2708 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "522, 2708 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "523, 387 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "523, 387 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "524, 1593 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "524, 1593 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "525, 2919 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "525, 2919 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "526, 1465 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "526, 1465 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "527, 2311 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "527, 2311 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "528, 2968 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "528, 2968 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "529, 2085 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "529, 2085 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "530, 3909 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "530, 3909 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "531, 3510 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "531, 3510 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "532, 259 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "532, 259 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "533, 2164 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "533, 2164 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "534, 858 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "534, 858 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "535, 716 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "535, 716 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "536, 923 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "536, 923 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "537, 65 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "537, 65 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "538, 3813 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "538, 3813 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "539, 2541 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "539, 2541 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "540, 863 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "540, 863 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "541, 713 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "541, 713 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "542, 557 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "542, 557 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "543, 3516 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "543, 3516 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "544, 3319 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "544, 3319 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "545, 3437 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "545, 3437 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "546, 322 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "546, 322 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "547, 2253 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "547, 2253 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "548, 3245 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "548, 3245 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "549, 773 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "549, 773 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "550, 3502 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "550, 3502 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "551, 3268 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "551, 3268 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "552, 1428 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "552, 1428 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "553, 649 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "553, 649 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "554, 2110 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "554, 2110 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "555, 461 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "555, 461 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "556, 610 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "556, 610 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "557, 1104 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "557, 1104 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "558, 1415 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "558, 1415 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "559, 567 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "559, 567 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "561, 2818 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "561, 2818 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "562, 2360 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "562, 2360 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "563, 270 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "563, 270 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "564, 552 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "564, 552 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "565, 3121 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "565, 3121 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "566, 919 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "566, 919 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "567, 703 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "567, 703 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "568, 17 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "568, 17 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "569, 1722 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "569, 1722 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "571, 2868 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "571, 2868 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "572, 524 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "572, 524 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "573, 1587 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "573, 1587 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "574, 3875 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "574, 3875 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "575, 1988 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "575, 1988 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "576, 3965 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "576, 3965 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "577, 1912 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "577, 1912 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "578, 1686 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "578, 1686 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "579, 2240 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "579, 2240 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "580, 3373 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "580, 3373 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "582, 1252 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "582, 1252 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "583, 1856 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "583, 1856 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "584, 3061 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "584, 3061 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "585, 604 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "585, 604 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "586, 2365 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "586, 2365 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "587, 429 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "587, 429 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "588, 676 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "588, 676 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "589, 2001 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "589, 2001 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "590, 1283 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "590, 1283 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "591, 865 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "591, 865 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "592, 3365 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "592, 3365 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "593, 2580 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "593, 2580 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "594, 652 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "594, 652 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "595, 111 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "595, 111 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "596, 3930 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "596, 3930 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "597, 1168 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "597, 1168 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "598, 960 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "598, 960 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "599, 3624 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "599, 3624 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "600, 3971 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "600, 3971 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "601, 989 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "601, 989 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "602, 3698 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "602, 3698 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "603, 2200 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "603, 2200 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "604, 1055 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "604, 1055 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "605, 2563 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "605, 2563 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "606, 176 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "606, 176 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "607, 1277 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "607, 1277 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "608, 1676 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "608, 1676 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "609, 2169 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "609, 2169 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "610, 3337 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "610, 3337 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "611, 3321 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "611, 3321 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "612, 3827 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "612, 3827 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "613, 962 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "613, 962 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "614, 484 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "614, 484 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "615, 769 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "615, 769 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "616, 2566 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "616, 2566 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "617, 1427 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "617, 1427 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "618, 2382 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "618, 2382 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "619, 62 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "619, 62 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "620, 2289 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "620, 2289 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "621, 778 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "621, 778 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "622, 1368 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "622, 1368 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "623, 996 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "623, 996 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "624, 3598 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "624, 3598 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "625, 1592 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "625, 1592 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "626, 2924 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "626, 2924 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "627, 1528 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "627, 1528 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "628, 834 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "628, 834 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "629, 3744 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "629, 3744 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "630, 243 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "630, 243 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "631, 2661 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "631, 2661 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "632, 2750 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "632, 2750 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "633, 526 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "633, 526 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "634, 3048 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "634, 3048 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "635, 1217 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "635, 1217 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "636, 3306 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "636, 3306 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "637, 1366 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "637, 1366 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "638, 3560 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "638, 3560 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "639, 1544 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "639, 1544 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "640, 3681 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "640, 3681 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "641, 734 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "641, 734 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "642, 1728 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "642, 1728 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "643, 1539 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "643, 1539 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "644, 3125 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "644, 3125 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "645, 3467 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "645, 3467 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "646, 3674 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "646, 3674 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "647, 2905 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "647, 2905 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "648, 2237 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "648, 2237 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "649, 1530 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "649, 1530 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "650, 1286 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "650, 1286 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "651, 1241 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "651, 1241 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "652, 1566 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "652, 1566 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "653, 1130 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "653, 1130 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "654, 1025 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "654, 1025 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "655, 283 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "655, 283 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "656, 3078 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "656, 3078 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "657, 2578 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "657, 2578 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "658, 2695 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "658, 2695 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "659, 2332 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "659, 2332 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "660, 28 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "660, 28 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "661, 1594 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "661, 1594 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "663, 286 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "663, 286 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "664, 830 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "664, 830 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "665, 3882 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "665, 3882 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "666, 2099 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "666, 2099 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "667, 665 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "667, 665 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "668, 416 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "668, 416 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "669, 498 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "669, 498 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "670, 3508 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "670, 3508 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "673, 249 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "673, 249 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "674, 2272 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "674, 2272 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "675, 2350 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "675, 2350 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "676, 3899 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "676, 3899 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "677, 2280 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "677, 2280 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "678, 2100 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "678, 2100 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "679, 2719 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "679, 2719 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "680, 3545 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "680, 3545 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "681, 266 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "681, 266 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "682, 3174 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "682, 3174 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "683, 779 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "683, 779 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "684, 1321 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "684, 1321 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "685, 886 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "685, 886 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "686, 942 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "686, 942 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "687, 245 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "687, 245 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "689, 3894 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "689, 3894 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "690, 1560 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "690, 1560 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "691, 3794 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "691, 3794 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "692, 3843 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "692, 3843 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "693, 1496 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "693, 1496 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "694, 2198 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "694, 2198 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "695, 1960 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "695, 1960 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "696, 2423 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "696, 2423 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "697, 879 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "697, 879 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "698, 2866 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "698, 2866 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "700, 435 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "700, 435 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "701, 1992 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "701, 1992 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "702, 2999 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "702, 2999 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "703, 3932 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "703, 3932 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "704, 627 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "704, 627 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "705, 229 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "705, 229 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "706, 514 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "706, 514 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "707, 93 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "707, 93 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "708, 1443 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "708, 1443 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "709, 1977 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "709, 1977 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "710, 1779 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "710, 1779 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "711, 483 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "711, 483 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "712, 1780 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "712, 1780 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "713, 3225 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "713, 3225 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "714, 3253 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "714, 3253 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "715, 2342 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "715, 2342 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "716, 444 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "716, 444 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "717, 1483 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "717, 1483 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "718, 594 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "718, 594 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "719, 765 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "719, 765 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "720, 3527 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "720, 3527 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "721, 1529 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "721, 1529 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "722, 1072 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "722, 1072 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "723, 2393 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "723, 2393 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "724, 3066 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "724, 3066 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "725, 1230 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "725, 1230 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "726, 2106 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "726, 2106 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "727, 2373 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "727, 2373 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "728, 1928 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "728, 1928 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "729, 2694 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "729, 2694 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "730, 2864 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "730, 2864 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "731, 666 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "731, 666 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "732, 2372 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "732, 2372 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "733, 1522 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "733, 1522 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "734, 2941 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "734, 2941 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "735, 715 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "735, 715 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "736, 124 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "736, 124 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "737, 1665 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "737, 1665 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "738, 1203 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "738, 1203 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "739, 2870 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "739, 2870 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "740, 348 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "740, 348 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "741, 1946 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "741, 1946 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "742, 351 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "742, 351 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "743, 1023 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "743, 1023 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "744, 2711 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "744, 2711 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "745, 3777 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "745, 3777 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "746, 1598 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "746, 1598 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "748, 3181 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "748, 3181 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "749, 1597 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "749, 1597 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "750, 3575 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "750, 3575 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "751, 3045 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "751, 3045 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "752, 106 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "752, 106 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "753, 2940 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "753, 2940 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "754, 3322 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "754, 3322 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "755, 3498 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "755, 3498 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "756, 1142 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "756, 1142 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "757, 3918 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "757, 3918 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "758, 1175 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "758, 1175 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "759, 2095 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "759, 2095 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "760, 2117 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "760, 2117 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "761, 3018 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "761, 3018 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "762, 1213 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "762, 1213 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "763, 1176 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "763, 1176 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "764, 894 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "764, 894 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "765, 576 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "765, 576 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "766, 114 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "766, 114 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "767, 1232 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "767, 1232 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "768, 2395 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "768, 2395 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "769, 137 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "769, 137 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "770, 3190 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "770, 3190 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "771, 782 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "771, 782 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "772, 2903 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "772, 2903 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "773, 1997 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "773, 1997 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "774, 1177 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "774, 1177 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "775, 474 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "775, 474 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "776, 538 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "776, 538 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Warning: Missing or invalid image reference in image_2 column.\n",
      "777, 469 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "777, 469 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "778, 2727 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "778, 2727 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "780, 1278 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "780, 1278 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "781, 420 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "781, 420 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "782, 2411 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "782, 2411 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "783, 2993 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "783, 2993 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "784, 2975 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "784, 2975 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "785, 635 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "785, 635 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "786, 669 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "786, 669 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "787, 1416 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "787, 1416 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "788, 533 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "788, 533 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "789, 1094 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "789, 1094 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "790, 1019 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "790, 1019 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "791, 236 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "791, 236 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "792, 2364 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "792, 2364 Patch Features Shape: torch.Size([1, 512]), Avg Features Shape: torch.Size([1, 2048])\n",
      "Patch Features Shape: torch.Size([766, 1024])\n",
      "Average Features Shape: torch.Size([766, 2048])\n",
      "Final Embedding Shape: torch.Size([766, 3072])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "output_directory=\"./datasets/iu_xray/output/\"\n",
    "# Define paths for saving features\n",
    "patch_feats_file = os.path.join(output_directory, 'final_test_patch_feats.pt')\n",
    "avg_feats_file = os.path.join(output_directory, 'final_test_avg_feats.pt')\n",
    "final_embeddings_file = os.path.join(output_directory, 'final_test_final_embeddings.pt')\n",
    "# iu_xray_images_preprocessed=\"/kaggle/working/extracted_images/images_preprocessed\"\n",
    "# # Define paths for saving features\n",
    "# patch_feats_file = os.path.join(output_directory, 'patch_feats.pt')\n",
    "# avg_feats_file = os.path.join(output_directory, 'avg_feats.pt')\n",
    "# final_embeddings_file = os.path.join(output_directory, 'final_embeddings.pt')\n",
    "\n",
    "# Define the transform for image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Adjust size based on model input requirement\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization for ResNet\n",
    "])\n",
    "\n",
    "# Define VisualExtractor class\n",
    "class VisualExtractor(nn.Module):\n",
    "    def __init__(self, visual_extractor='resnet101', pretrained=True):\n",
    "        super(VisualExtractor, self).__init__()\n",
    "\n",
    "        model = getattr(models, visual_extractor)(pretrained=pretrained)\n",
    "        \n",
    "        # Remove the last fully connected layer\n",
    "        modules = list(model.children())[:-2]  \n",
    "        self.model = nn.Sequential(*modules)\n",
    "        \n",
    "        # Average pooling and a fully connected layer to transform the features\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc_layer = nn.Linear(model.fc.in_features, 512)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        avg_feats = self.avg_pool(x).view(x.size(0), -1)\n",
    "        patch_feats = self.fc_layer(avg_feats)\n",
    "        return patch_feats, avg_feats\n",
    "\n",
    "# Load images function that handles the new DataFrame structure\n",
    "def load_images(report_row, img_folder):\n",
    "    images = []\n",
    "    for i in range(1, 3):  # For image_1 and image_2\n",
    "        img_value = report_row[f'image_{i}']\n",
    "        \n",
    "        # Check if img_value is a string before splitting\n",
    "        if isinstance(img_value, str):\n",
    "            img_filename = img_value.split('.')[0] + '.png'  # Replace with .png\n",
    "            img_path = os.path.join(img_folder, img_filename)\n",
    "            \n",
    "            # Check if the image file exists before attempting to open it\n",
    "            if os.path.exists(img_path):\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                images.append(transform(img))\n",
    "            else:\n",
    "                print(f\"Warning: Image file not found: {img_path}\")  # Warning if file not found\n",
    "        else:\n",
    "            print(f\"Warning: Missing or invalid image reference in {f'image_{i}'} column.\")\n",
    "    \n",
    "    # If only one image was loaded, duplicate it\n",
    "    if len(images) == 1:\n",
    "        images.append(images[0].clone())  # Duplicate the single available image\n",
    "    \n",
    "    return torch.stack(images) if images else torch.tensor([])  # Return empty tensor if no images loaded\n",
    "\n",
    "# Initialize visual extractor\n",
    "visual_extractor = VisualExtractor()\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "visual_extractor.to(device)\n",
    "\n",
    "# Set learning rates and other parameters\n",
    "learning_rate = 5e-5  # 5 × 10^−5\n",
    "other_parameter = 1e-4  # Example of another parameter (like weight decay)\n",
    "\n",
    "# Create an optimizer\n",
    "optimizer = optim.Adam(visual_extractor.parameters(), lr=learning_rate, weight_decay=other_parameter)\n",
    "\n",
    "def extract_features(data_loader):\n",
    "    patch_feats, avg_feats, final_embeddings = [], [], []\n",
    "    \n",
    "    for idx, row in data_loader.iterrows():\n",
    "        images = load_images(row, iu_xray_images_preprocessed).to(device)  # Load up to 2 images\n",
    "        \n",
    "        if images.numel() == 0:  # Skip if no images were loaded\n",
    "            continue\n",
    "        \n",
    "        report_patch_feats, report_avg_feats = [], []\n",
    "        \n",
    "        # Iterate directly over the images tensor\n",
    "        for image in images:  # Process each image in the loaded images tensor\n",
    "            image = image.unsqueeze(0).to(device)  # Move single image to device\n",
    "            pf, af = visual_extractor(image)  # Extract patch_feats, avg_feats\n",
    "            print(f\"{row['index']}, {row['pmc_id']} Patch Features Shape: {pf.shape}, Avg Features Shape: {af.shape}\")\n",
    "            \n",
    "            # Store the output temporarily, releasing earlier references\n",
    "            report_patch_feats.append(pf.detach())\n",
    "            report_avg_feats.append(af.detach())\n",
    "\n",
    "        # Concatenate patch features and average the avg_feats\n",
    "        concatenated_patch_feats = torch.cat(report_patch_feats, dim=1)  # Concatenate along feature dimension\n",
    "        averaged_avg_feats = torch.mean(torch.stack(report_avg_feats), dim=0)  # Average the avg_feats\n",
    "\n",
    "        # Combine avg_feats with patch_feats to create final embedding\n",
    "        final_embedding = torch.cat((averaged_avg_feats, concatenated_patch_feats), dim=1)\n",
    "        patch_feats.append(concatenated_patch_feats)\n",
    "        avg_feats.append(averaged_avg_feats)\n",
    "        final_embeddings.append(final_embedding)\n",
    "        \n",
    "    return torch.stack(patch_feats), torch.stack(avg_feats), torch.stack(final_embeddings)\n",
    "\n",
    "# Functions to load and save features\n",
    "def load_features(file_path):\n",
    "    return torch.load(file_path)\n",
    "\n",
    "def save_features(file_path, features):\n",
    "    torch.save(features, file_path)\n",
    "\n",
    "# # Load data\n",
    "# report_data_path = os.path.join(output_directory, 'filtered_train_data.csv')\n",
    "# iu_xray_reports_df = pd.read_csv(report_data_path)\n",
    "# display(iu_xray_reports_df.head(10))\n",
    "# # Load data\n",
    "report_data_path =  os.path.join(output_directory, \"final_filtered_test_data.csv\")\n",
    "iu_xray_reports_df = pd.read_csv(report_data_path)\n",
    "display(iu_xray_reports_df.head(10))\n",
    "\n",
    "# Check if features are already saved; if not, extract and save them\n",
    "if not os.path.exists(patch_feats_file) and os.path.exists(avg_feats_file) and os.path.exists(final_embeddings_file):\n",
    "    print(\"All features are already precomputed and will be loaded.\")\n",
    "    patch_feats = load_features(patch_feats_file)\n",
    "    avg_feats = load_features(avg_feats_file)\n",
    "    final_embeddings = load_features(final_embeddings_file)\n",
    "else:\n",
    "    print(\"Extracting features since they are not precomputed...\")\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    visual_extractor.train()  \n",
    "    \n",
    "    patch_feats, avg_feats, final_embeddings = extract_features(iu_xray_reports_df)\n",
    "    patch_feats = patch_feats.squeeze(1)  \n",
    "    avg_feats = avg_feats.squeeze(1)      \n",
    "    final_embeddings = final_embeddings.squeeze(1) \n",
    "\n",
    "    save_features(patch_feats_file, patch_feats)\n",
    "    save_features(avg_feats_file, avg_feats)\n",
    "    save_features(final_embeddings_file, final_embeddings)\n",
    "\n",
    "# Displaying the shapes of the feature dataframes\n",
    "print(\"Patch Features Shape:\", patch_feats.shape)\n",
    "print(\"Average Features Shape:\", avg_feats.shape)\n",
    "print(\"Final Embedding Shape:\", final_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_feats = patch_feats.squeeze(1)  # Shape: (3851, 4096)\n",
    "avg_feats = avg_feats.squeeze(1)      # Shape: (3851, 2048)\n",
    "final_embeddings = final_embeddings.squeeze(1)  # Shape: (3851, 6144)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Define paths for the saved features\n",
    "patch_feats_file = os.path.join(output_directory, 'patch_feats.pt')\n",
    "avg_feats_file = os.path.join(output_directory, 'avg_feats.pt')\n",
    "final_embeddings_file = os.path.join(output_directory, 'final_embeddings.pt')\n",
    "\n",
    "# Function to load features and print their shapes\n",
    "def print_tensor_shapes():\n",
    "    # Load patch features\n",
    "    if os.path.exists(patch_feats_file):\n",
    "        patch_feats = torch.load(patch_feats_file, map_location=torch.device('cpu'))\n",
    "        print(\"Patch Features Shape:\", patch_feats.shape)\n",
    "    else:\n",
    "        print(f\"Patch features file not found: {patch_feats_file}\")\n",
    "\n",
    "    # Load average features\n",
    "    if os.path.exists(avg_feats_file):\n",
    "        avg_feats = torch.load(avg_feats_file, map_location=torch.device('cpu'))\n",
    "        print(\"Average Features Shape:\", avg_feats.shape)\n",
    "    else:\n",
    "        print(f\"Average features file not found: {avg_feats_file}\")\n",
    "\n",
    "    # Load final embeddings\n",
    "    if os.path.exists(final_embeddings_file):\n",
    "        final_embeddings = torch.load(final_embeddings_file, map_location=torch.device('cpu'))\n",
    "        print(\"Final Embedding Shape:\", final_embeddings.shape)\n",
    "    else:\n",
    "        print(f\"Final embeddings file not found: {final_embeddings_file}\")\n",
    "\n",
    "# Call the function to print shapes\n",
    "print_tensor_shapes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Displaying Tensor Shapes for All Embeddings'''\n",
    "\n",
    "# Define paths for the saved features\n",
    "patch_feats_file = os.path.join(output_directory, 'patch_feats.pt')\n",
    "avg_feats_file = os.path.join(output_directory, 'avg_feats.pt')\n",
    "final_embeddings_file = os.path.join(output_directory, 'final_embeddings.pt')\n",
    "\n",
    "\n",
    "# Function to load features and print their shapes\n",
    "def print_tensor_shapes():\n",
    "    # Load patch features\n",
    "    if os.path.exists(patch_feats_file):\n",
    "        patch_feats = torch.load(patch_feats_file, map_location=torch.device('cpu'))\n",
    "        print(\"Patch Features Shape:\", patch_feats.shape)\n",
    "    else:\n",
    "        print(f\"Patch features file not found: {patch_feats_file}\")\n",
    "\n",
    "    # Load average features\n",
    "    if os.path.exists(avg_feats_file):\n",
    "        avg_feats = torch.load(avg_feats_file, map_location=torch.device('cpu'))\n",
    "        print(\"Average Features Shape:\", avg_feats.shape)\n",
    "    else:\n",
    "        print(f\"Average features file not found: {avg_feats_file}\")\n",
    "\n",
    "    # Load final embeddings\n",
    "    if os.path.exists(final_embeddings_file):\n",
    "        final_embeddings = torch.load(final_embeddings_file, map_location=torch.device('cpu'))\n",
    "        print(\"Final Embedding Shape:\", final_embeddings.shape)\n",
    "    else:\n",
    "        print(f\"Final embeddings file not found: {final_embeddings_file}\")\n",
    "\n",
    "        \n",
    "# Call the function to print shapes\n",
    "print_tensor_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2kBZTiCMmsE"
   },
   "source": [
    "### **Text Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as dist\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, bert_model=\"bert-base-uncased\", output_dim=384):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
    "        self.projection = nn.Linear(self.bert.config.hidden_size, output_dim)\n",
    "        \n",
    "    def encode_dictionary(self, dictionary):\n",
    "        \"\"\"\n",
    "        Encodes dictionary entries using BERT and combines key-value pairs\n",
    "        dictionary: Dict with medical terms as keys and list of related terms as values\n",
    "        Returns: Tensor of shape [num_entries, output_dim]\n",
    "        \"\"\"\n",
    "        encoded_entries = []\n",
    "        \n",
    "        for key, values in dictionary.items():\n",
    "            # Combine key with its values into a single text\n",
    "            if values:  # If values list is not empty\n",
    "                text = key + \": \" + \", \".join(values)\n",
    "            else:\n",
    "                text = key\n",
    "                \n",
    "            # Tokenize and encode\n",
    "            inputs = self.tokenizer(text, \n",
    "                                  padding=True, \n",
    "                                  truncation=True, \n",
    "                                  return_tensors=\"pt\")\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.bert(**inputs)\n",
    "                # Use [CLS] token embedding\n",
    "                embedding = outputs.last_hidden_state[:, 0, :]\n",
    "                \n",
    "            # Project to desired dimension\n",
    "            projected = self.projection(embedding)\n",
    "            encoded_entries.append(projected)\n",
    "            \n",
    "        return torch.cat(encoded_entries, dim=0)\n",
    "        \n",
    "    def encode_reports(self, reports):\n",
    "            \"\"\"\n",
    "            Encodes medical reports using BERT\n",
    "            reports: List of report texts\n",
    "            Returns: Tensor of shape [batch_size, output_dim]\n",
    "            \"\"\"\n",
    "            # Tokenize all reports in batch\n",
    "            inputs = self.tokenizer(reports,\n",
    "                                  padding=True,\n",
    "                                  truncation=True,\n",
    "                                  return_tensors=\"pt\")\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.bert(**inputs)\n",
    "                # Use [CLS] token embeddings\n",
    "                embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "                \n",
    "            # Project to desired dimension\n",
    "            projected = self.projection(embeddings)\n",
    "            \n",
    "            return projected\n",
    "\n",
    "medical_dict = {\n",
    "    \"pleural\": [\"hemithorax\", \"effusion\", \"pneumothorax\", \"parenchymal\"],\n",
    "    \"lung\": [\"lungs\", \"pulmonary\", \"hilar\", \"lobe\", \"consolidation\", \n",
    "             \"atelectasis\", \"edema\", \"opacity\", \"pneumonia\"],\n",
    "    \"mediastinal\": [\"mediastinum\", \"diaphragm\", \"hemidiaphragm\"],\n",
    "    \"cardiac\": [\"heart\", \"cardiomegaly\", \"cardiomediastinal\", \"atrium\",\n",
    "                \"ventricle\", \"retrocardiac\"],\n",
    "    \"vascular\": [\"aorta\", \"venous\", \"jugular\", \"aortic\", \"vasculature\", \"cabg\"],\n",
    "    \"osseous\": [\"rib\", \"sternal\", \"subclavian\", \"thoracic\"],\n",
    "    \"trachea\": [\"endotrachea\"],\n",
    "    \"stomach\": [],\n",
    "    \"abdomen\": [],\n",
    "    \"tube\": [\"clips\"],\n",
    "    \"spine\": [\"vertebral\", \"degenerative\"],\n",
    "    \"nodule\": [\"mass\"],\n",
    "    \"chest\": [\"small\", \"enlarged\", \"unchanged\", \"stable\", \"silhouette\",\n",
    "              \"contours\", \"size\", \"focal\", \"mild\", \"acute\"]\n",
    "}\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        # weight matrices for query, key, value\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V):\n",
    "        # Compute QK^T / sqrt(d_k)\n",
    "        d_k = Q.size(-1)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k).float())\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        output = torch.matmul(attn_weights, V)\n",
    "        return output, attn_weights\n",
    "\n",
    "    def forward(self, V, I_prime):\n",
    "        I_prime = I_prime.unsqueeze(1)\n",
    "        Q = self.W_q(V)  # Dictionary embeddings\n",
    "        K = self.W_k(I_prime)  # Image embeddings \n",
    "        V = self.W_v(I_prime)\n",
    "        batch_size, seq_len, d_model = K.size()\n",
    "        Q = Q.view(Q.size(0), -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = K.view(K.size(0), -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = V.view(V.size(0), -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        Q = Q.repeat(64 // 13 + 1, 1, 1, 1)  # Repeat enough times\n",
    "        Q = Q[:64]\n",
    "        \n",
    "        attn_output, attn_weights = self.scaled_dot_product_attention(Q, K, V)\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(V.size(0), -1, self.d_model)\n",
    "        output = self.W_o(attn_output)\n",
    "        \n",
    "        return output, attn_weights\n",
    "\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "\n",
    "def kl_divergence(mu1, logvar1, mu2, logvar2):\n",
    "    normal1 = dist.Normal(mu1, torch.exp(0.5 * logvar1))\n",
    "    normal2 = dist.Normal(mu2, torch.exp(0.5 * logvar2))\n",
    "    kl_loss = dist.kl.kl_divergence(normal1, normal2).mean()\n",
    "    return kl_loss\n",
    "\n",
    "class Piror(nn.Module):\n",
    "    \"\"\"Fully connected layer to convert encodings to mean and variance\"\"\"\n",
    "    def __init__(self, input_dim=3072, hidden_dim=512):\n",
    "        super(Piror, self).__init__()\n",
    "        self.fc_mu = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc_var = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Generate mean and log variance\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_var(x)\n",
    "        return mu, logvar\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sentence Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=768, hidden_dim=512, output_dim=512):\n",
    "        super(SentenceEncoder, self).__init__()\n",
    "        # Encoder network\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Networks to generate mean and variance as mentioned in paper\n",
    "        self.mean_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        self.logvar_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        mean = self.mean_layer(encoded)\n",
    "        logvar = self.logvar_layer(encoded)\n",
    "        return mean, logvar\n",
    "        \n",
    "    def encode(self, x):\n",
    "        \"\"\"Get only the mean for inference\"\"\"\n",
    "        mean, _ = self.forward(x)\n",
    "        return mean\n",
    "\n",
    "class SentenceBERT:\n",
    "    def __init__(self):\n",
    "        # Initialize the BERT tokenizer and model\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def encode_reports(self, reports):\n",
    "        embeddings = []\n",
    "        for report in reports:\n",
    "            # Tokenize and encode the report\n",
    "            inputs = self.tokenizer(report, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "            # Get BERT outputs\n",
    "            with torch.no_grad():  # Disable gradient calculation for inference\n",
    "                outputs = self.bert_model(**inputs)\n",
    "                \n",
    "            # Use the pooled output as the embedding\n",
    "            embeddings.append(outputs.pooler_output)\n",
    "\n",
    "        # Stack all embeddings into a single tensor\n",
    "        return torch.stack(embeddings)\n",
    "def kl_divergence_loss(mean1: torch.Tensor, logvar1: torch.Tensor, mean2: torch.Tensor, logvar2: torch.Tensor) -> torch.Tensor:\n",
    "    normal1 = dist.Normal(mean1, torch.exp(0.5 * logvar1))  # Standard deviation is sqrt of variance\n",
    "    normal2 = dist.Normal(mean2, torch.exp(0.5 * logvar2))\n",
    "    kl_loss = dist.kl.kl_divergence(normal1, normal2).mean()\n",
    "    return kl_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarities(batch_embeddings: torch.Tensor, all_embeddings: torch.Tensor) -> torch.Tensor:\n",
    "    # Normalize embeddings\n",
    "    batch_norm = F.normalize(batch_embeddings, p=2, dim=1)\n",
    "    all_norm = F.normalize(all_embeddings, p=2, dim=1)\n",
    "    \n",
    "    # Compute similarities\n",
    "    similarities = torch.mm(batch_norm, all_norm.t())\n",
    "    return similarities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def screen_historical_knowledge(current_embedding, historical_embeddings, top_k=5):\n",
    "    \"\"\"\n",
    "    Screen historical knowledge by selecting the top-K most similar historical embeddings.\n",
    "    \n",
    "    Parameters:\n",
    "    - current_embedding: Tensor, the current report embedding (1, d_model).\n",
    "    - historical_embeddings: deque, containing historical embeddings of shape (num_historical, d_model).\n",
    "    - top_k: int, number of most similar historical embeddings to select.\n",
    "\n",
    "    Returns:\n",
    "    - screened_knowledge: Tensor, containing the top-K most similar historical embeddings.\n",
    "    \"\"\"\n",
    "    # Calculate cosine similarities between the current embedding and each historical embedding\n",
    "    similarities = [\n",
    "        F.cosine_similarity(current_embedding, hist_embedding.unsqueeze(0), dim=1)\n",
    "        for hist_embedding in historical_embeddings\n",
    "    ]\n",
    "    similarities = torch.stack(similarities).squeeze()  # Shape: (num_historical,)\n",
    "\n",
    "    # Get indices of top-K most similar historical embeddings\n",
    "    top_k_indices = torch.topk(similarities, top_k, largest=True).indices\n",
    "    # print(top_k_indices)\n",
    "    # Select the top-K most similar historical embeddings\n",
    "    screened_knowledge = torch.stack([historical_embeddings[idx] for idx in top_k_indices])\n",
    "\n",
    "    return screened_knowledge\n",
    "\n",
    "# Contrastive loss function\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=0.2):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, pos_sim, neg_sim):\n",
    "        return F.relu(self.margin - pos_sim + neg_sim).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define projection layers\n",
    "avg_projection = nn.Linear(2048, 512).to(device)\n",
    "hist_projection = nn.Identity().to(device)\n",
    "\n",
    "# Initialize contrastive loss and classifier\n",
    "itc_loss_fn = ContrastiveLoss().to(device)\n",
    "itm_classifier = nn.Linear(512 * 2, 1).to(device)\n",
    "\n",
    "# Coarse alignment loop\n",
    "itc_loss_total = 0\n",
    "itm_loss_total = 0\n",
    "\n",
    "# Project embeddings\n",
    "# proj_avg_embeddings = avg_projection(average_embeddings)      # (2700, 512)\n",
    "# proj_hist_embeddings = hist_projection(historical_embeddings)  # (2700, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIYzXGtsMqmQ"
   },
   "source": [
    "### **Multilevel Alignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReportDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, vocab_size, num_layers, num_heads, d_ff, dropout=0.1):\n",
    "        super(ReportDecoder, self).__init__()\n",
    "        \n",
    "        # Add a linear projection to convert concatenated features to model dimension\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model, num_heads, d_ff, dropout)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "    \n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None):\n",
    "        # Project input memory to model dimension\n",
    "        # memory shape: [batch_size, total_features]\n",
    "        memory = self.input_projection(memory)  # [batch_size, d_model]\n",
    "        \n",
    "        # Add sequence dimension and transpose for transformer\n",
    "        memory = memory.unsqueeze(0)  # [1, batch_size, d_model]\n",
    "        \n",
    "        # Handle target sequence\n",
    "        if len(tgt.shape) == 2:\n",
    "            tgt = tgt.transpose(0, 1)  # [seq_len, batch_size]\n",
    "            \n",
    "        # Embed target\n",
    "        tgt_embed = self.embedding(tgt)  # [seq_len, batch_size, d_model]\n",
    "        \n",
    "        # Apply transformer decoder\n",
    "        output = self.transformer_decoder(tgt_embed, memory, tgt_mask=tgt_mask, memory_mask=memory_mask)\n",
    "        \n",
    "        # Project to vocabulary size\n",
    "        return self.fc_out(output)  # [seq_len, batch_size, vocab_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Uk_G0K8M2H9"
   },
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2700, 3072])\n",
      "Number of rows: 2700\n",
      "Number of columns: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|                                      | 0/42 [00:00<?, ?batch/s]/tmp/ipykernel_105086/3024036132.py:235: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(itm_classifier.parameters(), max_norm=1.0)\n",
      "Epoch 1/1:  31%|████▉           | 13/42 [07:13<19:42, 40.79s/batch, loss=0.0914]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load final_embeddings as per your code setup\n",
    "output_aligned_features_dir = \"./datasets/iu_xray/output/final_train_final_embeddings.pt\"\n",
    "final_embeddings = torch.load(output_aligned_features_dir, map_location=device)\n",
    "print(final_embeddings.size())\n",
    "# Parameters and model setup\n",
    "vocab_size = 30522  # Example vocab size (based on BERT)\n",
    "d_model = 3072\n",
    "num_layers = 3\n",
    "num_heads = 8\n",
    "d_ff = 4096\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# decoder = ReportDecoder(d_model, vocab_size, num_layers, num_heads, d_ff).to(device)\n",
    "sentence_encoder = SentenceEncoder().to(device)\n",
    "text_encoder = TextEncoder()\n",
    "\n",
    "# projection_layer = ProjectionLayer(input_dim=768, output_dim=d_model).to(device)  # Example dimensions\n",
    "projection_layer = nn.Linear(768, 512).to(device)\n",
    "avg_projection = nn.Linear(2048, 512).to(device)\n",
    "vprime_layer = nn.Linear(13 * 3072, 3072).to(device)\n",
    "text_projection_layer = nn.Linear(384, 3072)\n",
    "hist_projection = nn.Identity().to(device)\n",
    "itm_classifier = nn.Sequential(\n",
    "    nn.Linear(512 * 2, 1),  # Example dimensions for a concatenated input\n",
    "    # nn.ReLU(),\n",
    "    # nn.Linear(512, 1)\n",
    ").to(device)\n",
    "MHA = nn.MultiheadAttention(512, num_heads=8).to(device)\n",
    "mha = MultiHeadAttention(d_model, num_heads).to(device)\n",
    "sentence_bert = SentenceBERT()\n",
    "sentence_encoder = SentenceEncoder()\n",
    "ffn = FeedForwardNetwork(d_model, d_ff).to(device)\n",
    "piror_1 = Piror(d_model).to(device)\n",
    "piror_2 = Piror(384).to(device)\n",
    "# alignment_model = ImageTextAlignment().to(device)\n",
    "# Initialize the decoder\n",
    "# decoder = ReportDecoder(d_model, vocab_size, num_layers, num_heads, d_ff).to(device)\n",
    "total_feature_dim = 3072 + 3072 + 25600  # 8704\n",
    "# d_model = 512  # or whatever dimension you want to use\n",
    "\n",
    "decoder = ReportDecoder(\n",
    "    input_dim=total_feature_dim,  # 8704\n",
    "    d_model=512,\n",
    "    vocab_size=vocab_size,\n",
    "    num_layers=3,\n",
    "    num_heads=8,\n",
    "    d_ff=2048,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "# Define a negative log-likelihood loss for the report generation\n",
    "criterion_nll = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Combine the optimizer for both encoder and decoder\n",
    "params = (\n",
    "    list(sentence_encoder.parameters()) + \n",
    "    list(text_encoder.parameters()) +\n",
    "    list(projection_layer.parameters()) + \n",
    "    list(avg_projection.parameters()) + \n",
    "    list(itm_classifier.parameters()) +\n",
    "    list(mha.parameters()) + \n",
    "    list(ffn.parameters()) + \n",
    "    # list(piror.parameters()) +\n",
    "    list(decoder.parameters())+\n",
    "    list(vprime_layer.parameters())\n",
    ")\n",
    "optimizer = Adam(params, lr=1e-4)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_epochs = 1\n",
    "output_dir = './model_checkpoints'\n",
    "\n",
    "average_embeddings = final_embeddings[:, :2048]\n",
    "patch_embeddings = final_embeddings[:, 2048:2560]\n",
    "\n",
    "# Updated Training Loop with Report Generation\n",
    "def train_with_decoder(final_embeddings, batch_size, num_epochs, output_dir, target_reports_df):\n",
    "    dataset_size = final_embeddings.size(0)\n",
    "    training_log = []\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        n_batches = dataset_size // batch_size + (0 if dataset_size % batch_size != 0 else -1)\n",
    "        screened_historical_embedding= None\n",
    "        historical_embeddings=[]\n",
    "\n",
    "        with tqdm(total=n_batches, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\") as pbar:\n",
    "            for i in range(0, dataset_size, batch_size):\n",
    "                if final_embeddings[i:i + batch_size].size(0) != batch_size:\n",
    "                    print(f\"Skipping batch {i} due to size mismatch (expected {batch_size}, got {final_embeddings[i:i + batch_size].size(0)})\")\n",
    "                    continue\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                \n",
    "                #TARGET REPORTS\n",
    "                batch = df.iloc[i:i+batch_size]  # Adjust slicing to include valid rows\n",
    "                batch_reports_text = batch['findings'].tolist()\n",
    "                # print(f\"Batch {i} to {i+batch_size}: {batch_reports_text}\")\n",
    "                # Tokenize the target reports using the BERT tokenizer\n",
    "                tokenized_reports = tokenizer(batch_reports_text, padding='longest', return_tensors='pt', truncation=True)\n",
    "                \n",
    "                # Extract input IDs and attention mask for the decoder\n",
    "                batch_report_input_ids = tokenized_reports['input_ids'].to(device)\n",
    "                batch_report_attention_mask = tokenized_reports['attention_mask'].to(device)\n",
    "\n",
    "                # Shift the input IDs for the decoder\n",
    "                report_seq = batch_report_input_ids[:, :-1]  # Input sequence for decoder\n",
    "                tgt_seq = batch_report_input_ids[:, 1:]      # Target sequence for NLL loss\n",
    "\n",
    "                \n",
    "                #SENTENCE ENCODER\n",
    "                # Get batch data\n",
    "                batch_final_embeddings = final_embeddings[i:i + batch_size].to(device)\n",
    "                current_batch_size = batch_final_embeddings.size(0)\n",
    "                batch_reports = tokenized_reports[i:i + batch_size] #.to(device)\n",
    "                \n",
    "                # # Fine alignment (cosine similarity and KL divergence)\n",
    "                # batch_embedding1 = sentence_encoder_matrix[i:i + current_batch_size].to(device)\n",
    "                # batch_embedding2 = sbert_matrix[i:i + current_batch_size].to(device)\n",
    "                \n",
    "\n",
    "                batch_embedding2 = sentence_bert.encode_reports(batch_reports_text)\n",
    "                batch_embedding1 = sentence_encoder.encode(batch_embedding2)\n",
    "                batch_embedding1 = batch_embedding1.squeeze(1)\n",
    "\n",
    "                batch_embedding2_projected = projection_layer(batch_embedding2)\n",
    "                \n",
    "                mean1 = batch_embedding1.mean(dim=0, keepdim=True)\n",
    "                var1 = batch_embedding1.var(dim=0, keepdim=True, unbiased=False)\n",
    "                mean2 = batch_embedding2_projected.mean(dim=0, keepdim=True)\n",
    "                var2 = batch_embedding2_projected.var(dim=0, keepdim=True, unbiased=False)\n",
    "\n",
    "                kl_loss_fine = kl_divergence_loss(mean1, var1, mean2, var2)\n",
    "                sim_loss = 1 - F.cosine_similarity(batch_embedding1, batch_embedding2_projected, dim=1).mean()\n",
    "                fine_alignment_loss = kl_loss_fine + sim_loss\n",
    "\n",
    "                # Fprint(f\"batch_embedding1: {batch_embedding1.size()}\")\n",
    "                for embedding in batch_embedding1:\n",
    "                    historical_embeddings.append(embedding.detach())\n",
    "                    # historical_embeddings_2.append(embedding.detach()) # Add embeddings without gradient tracking\n",
    "                historical_embeddings_2 = batch_embedding1\n",
    "\n",
    "\n",
    "                #SCREENED HISTORICAL KNOWLEDGE\n",
    "                screened_knowledge_batch = []\n",
    "                for embedding in batch_embedding1[:current_batch_size]:\n",
    "                    screened_knowledge = screen_historical_knowledge(embedding, historical_embeddings_2, top_k=50)\n",
    "                    screened_knowledge_batch.append(screened_knowledge)\n",
    "                screened_knowledge_batch = torch.stack(screened_knowledge_batch).to(device)  # Shape: (batch_size, top_k, d_model)\n",
    "                \n",
    "                \n",
    "                #BLIP ARCHITECTURE\n",
    "                \n",
    "                # Coarse alignment (ITC and ITM loss)\n",
    "                proj_avg_embeddings = avg_projection(average_embeddings[i:i + current_batch_size].to(device))\n",
    "                proj_hist_embeddings = hist_projection(batch_embedding1)\n",
    "                itc_loss_total = 0\n",
    "                itm_loss_total = 0\n",
    "                for j in range(proj_avg_embeddings.size(0)):\n",
    "                    img_embed = proj_avg_embeddings[j]\n",
    "                    txt_embed = batch_embedding1[j]\n",
    "                    txt_embed = txt_embed.squeeze(0)\n",
    "                    pos_sim = F.cosine_similarity(img_embed, txt_embed, dim=0)\n",
    "                    neg_index = torch.randint(0, historical_embeddings_2.size(0), (1,), device=device)\n",
    "                    neg_txt_embed = proj_hist_embeddings[neg_index]\n",
    "                    neg_sim = F.cosine_similarity(img_embed, neg_txt_embed, dim=0)\n",
    "\n",
    "                    itc_loss = itc_loss_fn(pos_sim, neg_sim)\n",
    "                    itc_loss_total += itc_loss\n",
    "                    # print(f\"Shape of combined tensor: {img_embed.shape}  {txt_embed.shape}\")\n",
    "                    combined = torch.cat((img_embed, txt_embed), dim=-1)\n",
    "                    # print(f\"Shape of combined tensor: {combined.shape}\")\n",
    "                    itm_pred = itm_classifier(combined)\n",
    "                    itm_label = torch.tensor([1.0], dtype=torch.float, device=device)\n",
    "                    itm_loss = F.binary_cross_entropy_with_logits(itm_pred, itm_label)\n",
    "                    itm_loss_total += itm_loss\n",
    "\n",
    "                itc_loss_avg = itc_loss_total / proj_avg_embeddings.size(0)\n",
    "                itm_loss_avg = itm_loss_total / proj_avg_embeddings.size(0)\n",
    "                coarse_alignment_loss = itc_loss_avg + itm_loss_avg\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                #TEXT ENCODER WITH ALIGNMENT\n",
    "\n",
    "                # dictionary_embeddings, label_embeddings = alignment_model.encode_dictionary_and_labels(medical_dict, batch_reports_text)\n",
    "                # kl_loss_mha, attention_maps, V_prime = alignment_model(medical_dict, batch_reports_text, batch_final_embeddings, batch_size)\n",
    "                # Multi-Head Attention and Feed-Forward Network\n",
    "                dictionary_embeddings = text_encoder.encode_dictionary(medical_dict)\n",
    "\n",
    "                # Load final embeddings and project dictionary embeddings\n",
    "                dictionary_embeddings = dictionary_embeddings.to(torch.float32)  \n",
    "                \n",
    "                V_projected = text_projection_layer(dictionary_embeddings).to(device)\n",
    "                # batch_patch_embeddings = average_embeddings[i:i + current_batch_size].to(device)\n",
    "                # batch_V_projected = V_projected.unsqueeze(0).repeat(batch_final_embeddings.size(0), 1, 1).to(device)\n",
    "                aligned_output, _ = mha(V_projected, batch_final_embeddings)\n",
    "                aligned_output_ffn = ffn(aligned_output)\n",
    "                V_prime = aligned_output_ffn\n",
    "                V_label = text_encoder.encode_reports(batch_reports_text)\n",
    "                \n",
    "                # print(f\"V_prime shape: {V_prime.shape}\")\n",
    "                # print(f\"V_label shape: {V_prime.shape}\")\n",
    "                # print(f\"V_prime reduced shape: {V_prime_reduced.shape}\")\n",
    "                # V_prime_reduced = V_prime.max(dim=1).values\n",
    "                # attention_weights = F.softmax(vprime_layer(V_prime), dim=1)  \n",
    "                # v_prime_reduced = (attention_weights * V_prime).sum(dim=1)  \n",
    "\n",
    "                mu1, logvar1 = piror_1(V_prime)\n",
    "                mu2, logvar2 = piror_2(V_label)\n",
    "                kl_loss_mha = kl_divergence_loss(mu1, logvar1.exp(), mu2, logvar2.exp())\n",
    "        \n",
    "                # Total Loss\n",
    "                total_encoder_loss = fine_alignment_loss + coarse_alignment_loss + kl_loss_mha\n",
    "                # total_batch_loss.backward()\n",
    "                \n",
    "                # Gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(sentence_encoder.parameters(), max_norm=1.0)\n",
    "                torch.nn.utils.clip_grad_norm_(text_encoder.parameters(), max_norm=1.0)\n",
    "                torch.nn.utils.clip_grad_norm_(projection_layer.parameters(), max_norm=1.0)\n",
    "                torch.nn.utils.clip_grad_norm_(avg_projection.parameters(), max_norm=1.0) \n",
    "                torch.nn.utils.clip_grad_norm(itm_classifier.parameters(), max_norm=1.0) \n",
    "                torch.nn.utils.clip_grad_norm_(mha.parameters(), max_norm=1.0) \n",
    "                torch.nn.utils.clip_grad_norm_(ffn.parameters(), max_norm=1.0) \n",
    "                # torch.nn.utils.clip_grad_norm_(piror.parameters(), max_norm=1.0)\n",
    "               \n",
    "                \n",
    "                #DECODER\n",
    "                screened_knowledge_batch_flat = screened_knowledge_batch.view(current_batch_size, -1)  # Flatten along the second dimension\n",
    "                # memory = torch.cat([batch_final_embeddings, V_prime], dim=1)\n",
    "                \n",
    "                # print(f\"batch_final_embeddings shape: {batch_final_embeddings.shape}\")\n",
    "                # print(f\"V_prime shape: {V_prime.shape}\")\n",
    "                # print(f\"V_prime reduced shape: {V_prime_reduced.shape}\")\n",
    "                # print(f\"screened_knowledge_batch shape: {screened_knowledge_batch_flat.shape}\")\n",
    "                # print(f\"report_seq shape: {report_seq.shape}\")\n",
    "                # print(f\"tgt_seq shape: {tgt_seq.shape}\")\n",
    "                V_prime_reduced = V_prime.squeeze(1)\n",
    "                memory = torch.cat([batch_final_embeddings, V_prime_reduced, screened_knowledge_batch_flat], dim=1).to(device)\n",
    "                report_seq = report_seq.to(device)\n",
    "                tgt_seq = tgt_seq.to(device)\n",
    "                \n",
    "                output_seq = decoder(report_seq, memory)\n",
    "                output_seq = output_seq.transpose(0, 1)\n",
    "\n",
    "                output_flat = output_seq.reshape(-1, vocab_size)  # (batch_size * seq_len, vocab_size)\n",
    "                target_flat = tgt_seq.reshape(-1)  # (batch_size * seq_len)\n",
    "                # Compute report generation (NLL) loss\n",
    "                nll_loss = criterion_nll(output_flat.reshape(-1, vocab_size), target_flat.reshape(-1))\n",
    "\n",
    "                # Compute other losses (KL, similarity, etc.)\n",
    "                # kl_loss = kl_divergence_loss(mu1, logvar1, mu2, logvar2)\n",
    "                # sim_loss = 1 - F.cosine_similarity(batch_final_embeddings, V_prime, dim=-1).mean()\n",
    "\n",
    "                # Combine all losses\n",
    "                total_batch_loss = nll_loss + total_encoder_loss\n",
    "                \n",
    "                # Backward pass and optimization step\n",
    "                total_batch_loss.backward(retain_graph=True)\n",
    "                torch.nn.utils.clip_grad_norm_(params, max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                total_loss += total_batch_loss.item()\n",
    "\n",
    "                # Update progress\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(loss=f\"{total_loss / (i + batch_size):.4f}\")\n",
    "\n",
    "            if len(historical_embeddings) > 0:\n",
    "                historical_embeddings_tensor = torch.stack(historical_embeddings)\n",
    "                \n",
    "                # Compute similarity for all historical embeddings\n",
    "                similarity_scores = F.cosine_similarity(\n",
    "                    historical_embeddings_tensor.unsqueeze(1),  # All embeddings (H x 1 x D)\n",
    "                    historical_embeddings_tensor.unsqueeze(0),  # All embeddings (1 x H x D)\n",
    "                    dim=2\n",
    "                )  # Resulting tensor size: (H x H)\n",
    "                \n",
    "                # Mask self-similarity\n",
    "                similarity_scores.fill_diagonal_(-float('inf'))\n",
    "                \n",
    "                # Flatten the similarity scores to find global top 50\n",
    "                flat_scores = similarity_scores.view(-1)  # Flatten to 1D tensor\n",
    "                top_50_values, top_50_indices = torch.topk(flat_scores, k=50, largest=True)\n",
    "                \n",
    "                # Convert flat indices back to 2D indices\n",
    "                num_reports = similarity_scores.size(0)\n",
    "                row_indices = top_50_indices // num_reports  # Source report indices\n",
    "                col_indices = top_50_indices % num_reports   # Target report indices\n",
    "                \n",
    "                # Get the embeddings for the top 50 most similar reports\n",
    "                top_n_embeddings = []\n",
    "                top_n_similar_reports = []\n",
    "                \n",
    "                for score, col_idx in zip(top_50_values, col_indices):\n",
    "                    top_n_embeddings.append(historical_embeddings_tensor[col_idx])\n",
    "                    top_n_similar_reports.append((score.item(), col_idx.item()))\n",
    "                \n",
    "                # Stack the embeddings into a tensor\n",
    "                top_n_embeddings_tensor = torch.stack(top_n_embeddings)  # Shape: [50, 512]\n",
    "\n",
    "                # with open('top_n_similar_reports.pkl', 'wb') as pickle_file:\n",
    "                #     pickle.dump(top_n_similar_reports, pickle_file)\n",
    "\n",
    "            # Save model parameters and results per epoch\n",
    "            torch.save({\n",
    "                'sentence_encoder': sentence_encoder.state_dict(),\n",
    "                'text_encoder': text_encoder.state_dict(),\n",
    "                'projection_layer': projection_layer.state_dict(),\n",
    "                'avg_projection': avg_projection.state_dict(),\n",
    "                'itm_classifier': itm_classifier.state_dict(),\n",
    "                'mha': mha.state_dict(),\n",
    "                'ffn': ffn.state_dict(),\n",
    "                # 'piror': piror.state_dict(),\n",
    "                'decoder': decoder.state_dict(),\n",
    "            }, os.path.join(output_dir, f\"final_model_pafinal_filtered_train_datarameters_epoch_{epoch + 1}.pth\"))\n",
    "            torch.save(top_n_embeddings_tensor , \"screened_historical_embedding.pt\")\n",
    "            print(f\"\\nEpoch {epoch + 1}/{num_epochs} completed. Average Loss: {total_loss / n_batches:.4f}\")\n",
    "            print(f\"size of saved screened_historical_embedding: {top_n_embeddings_tensor .shape}\")\n",
    "\n",
    "    print(\"Training complete. Model parameters saved for each epoch.\")\n",
    "\n",
    "output_dir = \"./datasets/iu_xray/output/\"\n",
    "filter_report_path = \"./datasets/iu_xray/output/final_filtered_train_data.csv\"\n",
    "df = pd.read_csv(filter_report_path)\n",
    "# Number of rows\n",
    "num_rows = len(df)\n",
    "print(f'Number of rows: {num_rows}')\n",
    "\n",
    "# Number of columns\n",
    "num_columns = len(df.columns)\n",
    "print(f'Number of columns: {num_columns}')\n",
    "\n",
    "df['findings'].isnull().sum()\n",
    "\n",
    "# Training loop\n",
    "train_with_decoder(final_embeddings, batch_size, num_epochs, output_dir, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uz4pEhW2MuBF"
   },
   "source": [
    "### **Report Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer\n",
    "import heapq\n",
    "def load_trained_model(checkpoint_path, device='cuda'):\n",
    "    \"\"\"\n",
    "    Load the trained model components from a checkpoint\n",
    "    \"\"\"\n",
    "    # Initialize model components\n",
    "    sentence_encoder = SentenceEncoder().to(device)\n",
    "    text_encoder = TextEncoder().to(device)\n",
    "    projection_layer = nn.Linear(768, 512).to(device)\n",
    "    avg_projection = nn.Linear(2048, 512).to(device)\n",
    "    itm_classifier = nn.Sequential(\n",
    "        nn.Linear(512 * 2, 1)\n",
    "    ).to(device)\n",
    "    mha = MultiHeadAttention(3072, 8).to(device)\n",
    "    ffn = FeedForwardNetwork(3072, 4096).to(device)\n",
    "    piror = Piror(3072).to(device)\n",
    "    \n",
    "    # Load the saved state dictionaries\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    sentence_encoder.load_state_dict(checkpoint['sentence_encoder'])\n",
    "    text_encoder.load_state_dict(checkpoint['text_encoder'])\n",
    "    projection_layer.load_state_dict(checkpoint['projection_layer'])\n",
    "    avg_projection.load_state_dict(checkpoint['avg_projection'])\n",
    "    itm_classifier.load_state_dict(checkpoint['itm_classifier'])\n",
    "    mha.load_state_dict(checkpoint['mha'])\n",
    "    ffn.load_state_dict(checkpoint['ffn'])\n",
    "    # piror.load_state_dict(checkpoint['piror'])\n",
    "    decoder.load_state_dict(checkpoint['decoder'])\n",
    "    \n",
    "    return {\n",
    "        'sentence_encoder': sentence_encoder,\n",
    "        'text_encoder': text_encoder,\n",
    "        'projection_layer': projection_layer,\n",
    "        'avg_projection': avg_projection,\n",
    "        'itm_classifier': itm_classifier,\n",
    "        'mha': mha,\n",
    "        'ffn': ffn,\n",
    "        # 'piror': piror,\n",
    "        'decoder': decoder\n",
    "    }\n",
    "def beam_search_generate_report(models, image_embedding, historical_embeddings, tokenizer, device='cuda', beam_size=3, max_length=100):\n",
    "    \"\"\"\n",
    "    Generate a medical report using beam search\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Prepare image embedding\n",
    "        image_embedding = image_embedding.unsqueeze(0).to(device)  # Add batch dimension\n",
    "        \n",
    "        # Process through sentence encoder and projections\n",
    "        avg_embeddings = image_embedding[:, :2048]\n",
    "        proj_avg_embeddings = models['avg_projection'](avg_embeddings)\n",
    "        \n",
    "        dictionary_embeddings = models['text_encoder'].encode_dictionary(medical_dict)\n",
    "        dictionary_embeddings = dictionary_embeddings.to(torch.float32)  \n",
    "                \n",
    "        V_projected = text_projection_layer(dictionary_embeddings).to(device)\n",
    "                \n",
    "        # Multi-head attention and feed-forward processing\n",
    "        aligned_output, _ = models['mha'](V_projected, image_embedding)\n",
    "        aligned_output_ffn = models['ffn'](aligned_output)\n",
    "        V_prime = aligned_output_ffn\n",
    "        V_prime_reduced = V_prime.squeeze(1)\n",
    "        V_prime_reduced = V_prime.max(dim=1).values\n",
    "        # print(f\"image embeddings {image_embedding.size()}\")\n",
    "        # print(f\"V_prime_reduced,{V_prime_reduced.size()}\")\n",
    "        # print(f\"historical_embeddings {historical_embeddings.size()}\")\n",
    "        # Prepare memory\n",
    "        memory = torch.cat([image_embedding, V_prime_reduced, historical_embeddings], dim=1)\n",
    "        \n",
    "        # Initialize beam search\n",
    "        start_token = tokenizer.cls_token_id\n",
    "        end_token = tokenizer.sep_token_id\n",
    "        \n",
    "        # Beam search candidates: (score, sequence, last_token)\n",
    "        initial_sequence = torch.tensor([[start_token]]).to(device)\n",
    "        candidates = [(0.0, initial_sequence, start_token)]\n",
    "        completed_sequences = []\n",
    "        \n",
    "        for step in range(max_length):\n",
    "            next_candidates = []\n",
    "            \n",
    "            # Expand each candidate\n",
    "            for score, sequence, prev_token in candidates:\n",
    "                # print(prev_token)\n",
    "                # print(end_token)\n",
    "                # if prev_token.eq(end_token).any() or sequence.shape[1] >= max_length:\n",
    "                #     heapq.heappush(completed_sequences, (score, sequence))\n",
    "                #     continue\n",
    "                # If prev_token is a tensor, use .eq() and .any()\n",
    "                if isinstance(prev_token, torch.Tensor):\n",
    "                    if prev_token.eq(end_token).any() or sequence.shape[1] >= max_length:\n",
    "                        heapq.heappush(completed_sequences, (score, sequence))\n",
    "                        continue\n",
    "                # If prev_token is a single token (int), compare directly\n",
    "                elif prev_token == end_token or sequence.shape[1] >= max_length:\n",
    "                    heapq.heappush(completed_sequences, (score, sequence))\n",
    "                    continue\n",
    "                # Decoder step\n",
    "                output = models['decoder'](sequence, memory)\n",
    "                next_token_logits = output[:, -1:]\n",
    "                \n",
    "                # Get top K tokens\n",
    "                topk_probs, topk_indices = torch.topk(\n",
    "                    torch.softmax(next_token_logits, dim=-1), \n",
    "                    k=beam_size, \n",
    "                    dim=-1\n",
    "                )\n",
    "                \n",
    "                for prob, token_id in zip(topk_probs[0], topk_indices[0]):\n",
    "                    \n",
    "                    token_id = token_id.squeeze(0)\n",
    "                    # print(token_id.size())\n",
    "                    # print(sequence.size())\n",
    "                    # print(token_id.unsqueeze(1).size())\n",
    "                    # token_id = token_id.view(1)\n",
    "                    new_sequence = torch.cat([sequence, token_id.unsqueeze(0)], dim=1)\n",
    "                    new_score = score - torch.log(prob) #.item()  # Negative log likelihood\n",
    "                    \n",
    "                    next_candidates.append((new_score, new_sequence, token_id))\n",
    "            \n",
    "            # Sort and select top beam_size candidates\n",
    "            next_candidates.sort(key=lambda x: x[0])\n",
    "            candidates = next_candidates[:beam_size]\n",
    "            \n",
    "            # Check if all candidates are end tokens\n",
    "            # if all(candidate[2].item() == end_token for candidate in candidates):\n",
    "            #     break\n",
    "            if any((candidate[2] == end_token).any() for candidate in candidates):\n",
    "                break\n",
    "            # for candidate in candidates:\n",
    "            #     print(candidate[2])\n",
    "            #     if (candidate[2] == end_token):\n",
    "            #         break\n",
    "        # Select best sequence\n",
    "        if completed_sequences:\n",
    "            _, best_sequence = heapq.heappop(completed_sequences)\n",
    "        else:\n",
    "            _, best_sequence, _ = min(candidates, key=lambda x: x[0])\n",
    "        \n",
    "        # Decode the best sequence\n",
    "        generated_ids = best_sequence[0].cpu().numpy().tolist()\n",
    "        generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "        \n",
    "        return generated_text\n",
    "\n",
    "def test_model(test_image_embeddings, checkpoint_path, historical_embeddings, beam_size=3):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    # Load models\n",
    "    models = load_trained_model(checkpoint_path, device)\n",
    "    \n",
    "    # Generate reports for all test images\n",
    "    reports = []\n",
    "    for embedding in test_image_embeddings:\n",
    "        report = beam_search_generate_report(\n",
    "            models,\n",
    "            embedding,\n",
    "            historical_embeddings,\n",
    "            tokenizer,\n",
    "            device,\n",
    "            beam_size=beam_size\n",
    "        )\n",
    "        print(report)\n",
    "        reports.append(report)\n",
    "    \n",
    "    return reports\n",
    "\n",
    "# Example usage\n",
    "checkpoint_path = \"/kaggle/working/model_checkpoints/new_model_parameters_epoch_1.pth\"\n",
    "test_image_embeddings = torch.load(\"/kaggle/input/test-data/test_final_embeddings.pt\")\n",
    "historical_embeddings = torch.load(\"/kaggle/working/screened_historical_embedding.pt\")\n",
    "historical_flat = historical_embeddings.reshape(1, -1)\n",
    "\n",
    "reports = test_model(\n",
    "    test_image_embeddings,\n",
    "    checkpoint_path,\n",
    "    historical_flat,\n",
    "    beam_size=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluation**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "MlOl6I0rMa68",
    "PsELnlXpMjGX",
    "D2kBZTiCMmsE",
    "gIYzXGtsMqmQ",
    "Uz4pEhW2MuBF",
    "Z_WeRBlDMwX2",
    "7Uk_G0K8M2H9",
    "OXhkaJVvM3Uu"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
