{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bnpd7Zh0NPl2"
   },
   "source": [
    "## **Medical Report Summarisation using Medical Knowledge**\n",
    "\n",
    "### **References**\n",
    "\n",
    "**Main Reference**\n",
    "- Radiology report generation with medical knowledge and multilevel image-report alignment: A new method and its verification\n",
    "https://www.sciencedirect.com/science/article/pii/S0933365723002282\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKdcyk1sMEtD"
   },
   "source": [
    "## **Data Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p81rfgckMR9a"
   },
   "source": [
    "### **Collect Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYR_B6u1ojJt",
    "outputId": "faaac1ed-b54b-4cfd-b3e4-cca51372318e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "'''Libraries Installation and Import'''\n",
    "\n",
    "# installling necessary libraries\n",
    "!pip -q install --user requests numpy pandas matplotlib tqdm Pillow opencv-python nltk pyspellchecker torch torchvision torchaudio transformers scikit-learn sentence-transformers\n",
    "\n",
    "# importing required libraries\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Setting Paths'''\n",
    "\n",
    "# project directory\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# project_directory = '/content/drive/Othercomputers/My Laptop/CS550_ASMT_MRSMK/datasets'\n",
    "# project_directory = '/content/drive/MyDrive/Academics/CS550 Machine Learning/CS550 ASMT MRSMK/datasets'\n",
    "\n",
    "project_directory = \"./datasets\"\n",
    "dataset = 'iu_xray/'\n",
    "iu_xray_dataset = os.path.join(project_directory, dataset)\n",
    "\n",
    "\n",
    "# input directory\n",
    "input_directory = os.path.join(iu_xray_dataset, \"input\")\n",
    "\n",
    "images_dir = os.path.join(input_directory, \"images\")\n",
    "reports_dir = os.path.join(input_directory, \"reports\")\n",
    "iu_xray_images = images_dir\n",
    "iu_xray_reports = os.path.join(reports_dir, 'ecgen-radiology')\n",
    "\n",
    "\n",
    "# output directory \n",
    "output_directory = os.path.join(iu_xray_dataset, \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-19T18:58:24.886422Z",
     "iopub.status.busy": "2024-10-19T18:58:24.885947Z",
     "iopub.status.idle": "2024-10-19T18:58:24.945116Z",
     "shell.execute_reply": "2024-10-19T18:58:24.944038Z",
     "shell.execute_reply.started": "2024-10-19T18:58:24.886378Z"
    },
    "id": "49-0xiXplwH8",
    "outputId": "ea63eda3-908a-4f5f-eeec-a4019130e57f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://openi.nlm.nih.gov/imgs/collections/NLMCXR_png.tgz already exists at: ./datasets/iu_xray/input/images\n",
      "https://openi.nlm.nih.gov/imgs/collections/NLMCXR_reports.tgz already exists at: ./datasets/iu_xray/input/reports\n"
     ]
    }
   ],
   "source": [
    "'''Setup - Generalized'''\n",
    "\n",
    "# setup to download the IU X-Ray Dataset\n",
    "images_url = \"https://openi.nlm.nih.gov/imgs/collections/NLMCXR_png.tgz\"\n",
    "reports_url = \"https://openi.nlm.nih.gov/imgs/collections/NLMCXR_reports.tgz\"\n",
    "\n",
    "\n",
    "# function to check the file size of a given URL\n",
    "def get_file_size(url):\n",
    "    response = requests.head(url)\n",
    "    size_in_bytes = int(response.headers.get('Content-Length', 0))\n",
    "    size_in_mb = size_in_bytes / (1024 * 1024)\n",
    "    return size_in_mb\n",
    "\n",
    "\n",
    "# function to download and extract from a given url to a given directory\n",
    "def download_and_extract(url, save_dir):\n",
    "    file_name = url.split('/')[-1]\n",
    "    file_path = os.path.join(save_dir, file_name)\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('Content-Length', 0))\n",
    "    downloaded_size = 0\n",
    "\n",
    "    with open(file_path, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                file.write(chunk)\n",
    "                downloaded_size += len(chunk)\n",
    "                percent_complete = (downloaded_size / total_size) * 100\n",
    "                print(f\"Downloaded {downloaded_size / (1024*1024):.2f} MB out of {total_size / (1024*1024):.2f} MB: {percent_complete:.2f}% complete\")\n",
    "\n",
    "    print(\"\\nDownload complete!\")\n",
    "\n",
    "    with tarfile.open(file_path, 'r:gz') as tar:\n",
    "        members = tar.getmembers()\n",
    "        total_files = len(members)\n",
    "\n",
    "        for idx, member in enumerate(members, start=1):\n",
    "            tar.extract(member, path=save_dir)\n",
    "            print(f\"Extracting File {idx} out of {total_files}: {member.name}\")\n",
    "\n",
    "    os.remove(file_path)\n",
    "\n",
    "\n",
    "# downloading  IU X-Ray dataset\n",
    "if not os.path.exists(images_dir):\n",
    "    images_size = get_file_size(images_url)\n",
    "    print(f\"Downloading {images_url} to: {images_dir} ({images_size:.2f} MB)\")\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    download_and_extract(images_url, images_dir)\n",
    "    print(f\"Downloaded {images_url} to: {images_dir}\")\n",
    "else:\n",
    "    print(f\"{images_url} already exists at: {images_dir}\")\n",
    "\n",
    "if not os.path.exists(reports_dir):\n",
    "    reports_size = get_file_size(reports_url)\n",
    "    print(f\"Downloading {reports_url} to: {reports_dir} ({reports_size:.2f} MB)\")\n",
    "    os.makedirs(reports_dir, exist_ok=True)\n",
    "    download_and_extract(reports_url, reports_dir)\n",
    "    print(f\"Downloaded {reports_url} to: {reports_dir}\")\n",
    "else:\n",
    "    print(f\"{reports_url} already exists at: {reports_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-19T18:58:24.948661Z",
     "iopub.status.busy": "2024-10-19T18:58:24.947707Z",
     "iopub.status.idle": "2024-10-19T18:58:24.961726Z",
     "shell.execute_reply": "2024-10-19T18:58:24.960832Z",
     "shell.execute_reply.started": "2024-10-19T18:58:24.948615Z"
    },
    "id": "5ZSA8Jyowaoh",
    "outputId": "dffa4899-00a7-4d49-a118-8dd85400ba06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Path:  ./datasets/iu_xray/input/images\n",
      "Directory Contents: 7471 Images\n",
      "\n",
      "Path:  ./datasets/iu_xray/input/reports/ecgen-radiology\n",
      "Directory Contents: 3955 Reports\n"
     ]
    }
   ],
   "source": [
    "'''Exploring the IU X-Ray Dataset Contents'''\n",
    "\n",
    "# displaying directory and subdirectory contents\n",
    "print(\"\\nPath: \", iu_xray_images)\n",
    "print(f\"Directory Contents: {len(os.listdir(iu_xray_images))} Images\")\n",
    "\n",
    "print(\"\\nPath: \", iu_xray_reports)\n",
    "print(f\"Directory Contents: {len(os.listdir(iu_xray_reports))} Reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 822
    },
    "execution": {
     "iopub.execute_input": "2024-10-19T18:58:24.963724Z",
     "iopub.status.busy": "2024-10-19T18:58:24.963106Z",
     "iopub.status.idle": "2024-10-19T18:58:25.059827Z",
     "shell.execute_reply": "2024-10-19T18:58:25.058789Z",
     "shell.execute_reply.started": "2024-10-19T18:58:24.963685Z"
    },
    "id": "qGczexPLUaN5",
    "outputId": "8c7528a1-7064-4802-c276-edef004f0d5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe already exists at ./datasets/iu_xray/output/iu_xray_images_df.csv\n",
      "\n",
      "\n",
      "Dataframe Shape: (7470, 9)\n",
      "\n",
      "\n",
      "Dataframe Information:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7470 entries, 0 to 7469\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   pmc_id          7470 non-null   int64 \n",
      " 1   image_filename  7470 non-null   object\n",
      " 2   caption         7468 non-null   object\n",
      " 3   comparison      5210 non-null   object\n",
      " 4   indication      7311 non-null   object\n",
      " 5   findings        6473 non-null   object\n",
      " 6   impression      7418 non-null   object\n",
      " 7   height          7470 non-null   int64 \n",
      " 8   width           7470 non-null   int64 \n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 525.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Displaying Dataframe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmc_id</th>\n",
       "      <th>image_filename</th>\n",
       "      <th>caption</th>\n",
       "      <th>comparison</th>\n",
       "      <th>indication</th>\n",
       "      <th>findings</th>\n",
       "      <th>impression</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3967</td>\n",
       "      <td>CXR3967_IM-2028-1001.png</td>\n",
       "      <td>PA and lateral chest x-XXXX XXXX at XXXX hours.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chest pain</td>\n",
       "      <td>The cardiomediastinal silhouette is within nor...</td>\n",
       "      <td>1. No acute radiographic cardiopulmonary process.</td>\n",
       "      <td>420</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3967</td>\n",
       "      <td>CXR3967_IM-2028-2001.png</td>\n",
       "      <td>PA and lateral chest x-XXXX XXXX at XXXX hours.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chest pain</td>\n",
       "      <td>The cardiomediastinal silhouette is within nor...</td>\n",
       "      <td>1. No acute radiographic cardiopulmonary process.</td>\n",
       "      <td>624</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3332</td>\n",
       "      <td>CXR3332_IM-1596-1001.png</td>\n",
       "      <td>Radiograph Chest PA and Lateral XXXX, XXXX.</td>\n",
       "      <td>Radiograph Chest PA and Lateral XXXX, XXXX.</td>\n",
       "      <td>Weakness.</td>\n",
       "      <td>The heart is normal in size and contour. There...</td>\n",
       "      <td>No acute cardiopulmonary abnormalities.</td>\n",
       "      <td>420</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3332</td>\n",
       "      <td>CXR3332_IM-1596-2001.png</td>\n",
       "      <td>Radiograph Chest PA and Lateral XXXX, XXXX.</td>\n",
       "      <td>Radiograph Chest PA and Lateral XXXX, XXXX.</td>\n",
       "      <td>Weakness.</td>\n",
       "      <td>The heart is normal in size and contour. There...</td>\n",
       "      <td>No acute cardiopulmonary abnormalities.</td>\n",
       "      <td>624</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3332</td>\n",
       "      <td>CXR3332_IM-1596-3001.png</td>\n",
       "      <td>Radiograph Chest PA and Lateral XXXX, XXXX.</td>\n",
       "      <td>Radiograph Chest PA and Lateral XXXX, XXXX.</td>\n",
       "      <td>Weakness.</td>\n",
       "      <td>The heart is normal in size and contour. There...</td>\n",
       "      <td>No acute cardiopulmonary abnormalities.</td>\n",
       "      <td>624</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pmc_id            image_filename  \\\n",
       "0    3967  CXR3967_IM-2028-1001.png   \n",
       "1    3967  CXR3967_IM-2028-2001.png   \n",
       "2    3332  CXR3332_IM-1596-1001.png   \n",
       "3    3332  CXR3332_IM-1596-2001.png   \n",
       "4    3332  CXR3332_IM-1596-3001.png   \n",
       "\n",
       "                                            caption  \\\n",
       "0  PA and lateral chest x-XXXX XXXX at XXXX hours.    \n",
       "1  PA and lateral chest x-XXXX XXXX at XXXX hours.    \n",
       "2      Radiograph Chest PA and Lateral XXXX, XXXX.    \n",
       "3      Radiograph Chest PA and Lateral XXXX, XXXX.    \n",
       "4      Radiograph Chest PA and Lateral XXXX, XXXX.    \n",
       "\n",
       "                                    comparison  indication  \\\n",
       "0                                          NaN  Chest pain   \n",
       "1                                          NaN  Chest pain   \n",
       "2  Radiograph Chest PA and Lateral XXXX, XXXX.   Weakness.   \n",
       "3  Radiograph Chest PA and Lateral XXXX, XXXX.   Weakness.   \n",
       "4  Radiograph Chest PA and Lateral XXXX, XXXX.   Weakness.   \n",
       "\n",
       "                                            findings  \\\n",
       "0  The cardiomediastinal silhouette is within nor...   \n",
       "1  The cardiomediastinal silhouette is within nor...   \n",
       "2  The heart is normal in size and contour. There...   \n",
       "3  The heart is normal in size and contour. There...   \n",
       "4  The heart is normal in size and contour. There...   \n",
       "\n",
       "                                          impression  height  width  \n",
       "0  1. No acute radiographic cardiopulmonary process.     420    512  \n",
       "1  1. No acute radiographic cardiopulmonary process.     624    512  \n",
       "2            No acute cardiopulmonary abnormalities.     420    512  \n",
       "3            No acute cardiopulmonary abnormalities.     624    512  \n",
       "4            No acute cardiopulmonary abnormalities.     624    512  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Processing Textual Data from each .xml Report File and Storing it in a .csv File'''\n",
    "\n",
    "# function to iterate through all .xml report files and storing them in a dataframe\n",
    "def save_images_df():\n",
    "    data = []\n",
    "    cnt = 0\n",
    "    for file in os.listdir(iu_xray_reports):\n",
    "        if file.endswith(\".xml\"):\n",
    "            cnt += 1\n",
    "            print(f\"Processing .xml File {cnt} out of {len(os.listdir(iu_xray_reports))}: {file}\")\n",
    "\n",
    "            file_path = os.path.join(iu_xray_reports, file)\n",
    "            try:\n",
    "                tree = ET.parse(file_path)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                pmc_id = root.find('.//pmcId').attrib.get('id')\n",
    "\n",
    "                comparison = indication = findings = impression = None\n",
    "\n",
    "                for abstract in root.findall('.//AbstractText'):\n",
    "                    if abstract.attrib.get('Label') == 'COMPARISON':\n",
    "                        comparison = abstract.text\n",
    "                    elif abstract.attrib.get('Label') == 'INDICATION':\n",
    "                        indication = abstract.text\n",
    "                    elif abstract.attrib.get('Label') == 'FINDINGS':\n",
    "                        findings = abstract.text\n",
    "                    elif abstract.attrib.get('Label') == 'IMPRESSION':\n",
    "                        impression = abstract.text\n",
    "\n",
    "                for parent_image in root.findall('parentImage'):\n",
    "                    image_file = parent_image.attrib['id'] + \".png\"\n",
    "                    image_path = os.path.join(iu_xray_images, image_file)\n",
    "                    image = cv2.imread(image_path)\n",
    "\n",
    "                    if image is not None:\n",
    "                        height, width, channels = image.shape\n",
    "                        caption = parent_image.find('caption').text if parent_image.find('caption') is not None else None\n",
    "                        data.append([pmc_id, image_file, caption, comparison, indication, findings, impression, height, width])\n",
    "                    else:\n",
    "                        print(f\"Warning: Unable to read image {image_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# creating a dataframe and saving it as .csv\n",
    "iu_xray_images_df_path = os.path.join(output_directory, 'iu_xray_images_df.csv')\n",
    "if not os.path.exists(iu_xray_images_df_path):\n",
    "    data = save_images_df()\n",
    "    columns = ['pmc_id', 'image_filename', 'caption', 'comparison', 'indication', 'findings', 'impression', 'height', 'width']\n",
    "    iu_xray_images_df = pd.DataFrame(data, columns=columns)\n",
    "    iu_xray_images_df.to_csv(iu_xray_images_df_path, index=False)\n",
    "    print(f\"Dataframe saved to {iu_xray_images_df_path}\")\n",
    "else:\n",
    "    print(f\"Dataframe already exists at {iu_xray_images_df_path}\")\n",
    "    iu_xray_images_df = pd.read_csv(iu_xray_images_df_path)\n",
    "\n",
    "\n",
    "# displaying the stored dataframe\n",
    "print(\"\\n\\nDataframe Shape:\", iu_xray_images_df.shape)\n",
    "\n",
    "print(\"\\n\\nDataframe Information:\\n\")\n",
    "display(iu_xray_images_df.info())\n",
    "\n",
    "print(\"\\n\\nDisplaying Dataframe:\\n\")\n",
    "display(iu_xray_images_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893
    },
    "execution": {
     "iopub.execute_input": "2024-10-19T18:58:25.061834Z",
     "iopub.status.busy": "2024-10-19T18:58:25.061414Z",
     "iopub.status.idle": "2024-10-19T18:58:25.132065Z",
     "shell.execute_reply": "2024-10-19T18:58:25.131025Z",
     "shell.execute_reply.started": "2024-10-19T18:58:25.061787Z"
    },
    "id": "vYnfzXXT0O6w",
    "outputId": "d2692046-ebe0-45ac-8291-37641f6d5958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe already exists at ./datasets/iu_xray/output/iu_xray_reports_df.csv\n",
      "\n",
      "\n",
      "Dataframe Shape: (3955, 11)\n",
      "\n",
      "\n",
      "Dataframe Information:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3955 entries, 0 to 3954\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   pmc_id       3955 non-null   int64 \n",
      " 1   findings     3425 non-null   object\n",
      " 2   impression   3921 non-null   object\n",
      " 3   comparison   2757 non-null   object\n",
      " 4   indication   3865 non-null   object\n",
      " 5   image_count  3955 non-null   int64 \n",
      " 6   image_1      3851 non-null   object\n",
      " 7   image_2      3405 non-null   object\n",
      " 8   image_3      197 non-null    object\n",
      " 9   image_4      16 non-null     object\n",
      " 10  image_5      1 non-null      object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 340.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Displaying Dataframe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmc_id</th>\n",
       "      <th>findings</th>\n",
       "      <th>impression</th>\n",
       "      <th>comparison</th>\n",
       "      <th>indication</th>\n",
       "      <th>image_count</th>\n",
       "      <th>image_1</th>\n",
       "      <th>image_2</th>\n",
       "      <th>image_3</th>\n",
       "      <th>image_4</th>\n",
       "      <th>image_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3967</td>\n",
       "      <td>The cardiomediastinal silhouette is within nor...</td>\n",
       "      <td>1. No acute radiographic cardiopulmonary process.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chest pain</td>\n",
       "      <td>2</td>\n",
       "      <td>CXR3967_IM-2028-1001.jpg: PA and lateral chest...</td>\n",
       "      <td>CXR3967_IM-2028-2001.jpg: PA and lateral chest...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3332</td>\n",
       "      <td>The heart is normal in size and contour. There...</td>\n",
       "      <td>No acute cardiopulmonary abnormalities.</td>\n",
       "      <td>Radiograph Chest PA and Lateral XXXX, XXXX.</td>\n",
       "      <td>Weakness.</td>\n",
       "      <td>3</td>\n",
       "      <td>CXR3332_IM-1596-1001.jpg: Radiograph Chest PA ...</td>\n",
       "      <td>CXR3332_IM-1596-2001.jpg: Radiograph Chest PA ...</td>\n",
       "      <td>CXR3332_IM-1596-3001.jpg: Radiograph Chest PA ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>Lungs are clear without focal consolidation, e...</td>\n",
       "      <td>Negative acute cardiopulmonary abnormality.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XXXX-year-old male with chest pain.</td>\n",
       "      <td>2</td>\n",
       "      <td>CXR30_IM-1385-1001.jpg: Chest x-XXXX XXXX and ...</td>\n",
       "      <td>CXR30_IM-1385-2001.jpg: Chest x-XXXX XXXX and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2593</td>\n",
       "      <td>Mild cardiomegaly is unchanged. Stable superio...</td>\n",
       "      <td>Mild cardiomegaly with interstitial prominence...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Back pain</td>\n",
       "      <td>2</td>\n",
       "      <td>CXR2593_IM-1084-1001.jpg: Chest, 2 views, XXXX...</td>\n",
       "      <td>CXR2593_IM-1084-2001.jpg: Chest, 2 views, XXXX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1165</td>\n",
       "      <td>Frontal and lateral views of the chest show no...</td>\n",
       "      <td>No acute or active cardiac, pulmonary or pleur...</td>\n",
       "      <td>None.</td>\n",
       "      <td>Chest pain. Shortness of breath. The patient's...</td>\n",
       "      <td>1</td>\n",
       "      <td>CXR1165_IM-0110-1001.jpg: Xray Chest PA and La...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pmc_id                                           findings  \\\n",
       "0    3967  The cardiomediastinal silhouette is within nor...   \n",
       "1    3332  The heart is normal in size and contour. There...   \n",
       "2      30  Lungs are clear without focal consolidation, e...   \n",
       "3    2593  Mild cardiomegaly is unchanged. Stable superio...   \n",
       "4    1165  Frontal and lateral views of the chest show no...   \n",
       "\n",
       "                                          impression  \\\n",
       "0  1. No acute radiographic cardiopulmonary process.   \n",
       "1            No acute cardiopulmonary abnormalities.   \n",
       "2        Negative acute cardiopulmonary abnormality.   \n",
       "3  Mild cardiomegaly with interstitial prominence...   \n",
       "4  No acute or active cardiac, pulmonary or pleur...   \n",
       "\n",
       "                                    comparison  \\\n",
       "0                                          NaN   \n",
       "1  Radiograph Chest PA and Lateral XXXX, XXXX.   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                        None.   \n",
       "\n",
       "                                          indication  image_count  \\\n",
       "0                                         Chest pain            2   \n",
       "1                                          Weakness.            3   \n",
       "2                XXXX-year-old male with chest pain.            2   \n",
       "3                                          Back pain            2   \n",
       "4  Chest pain. Shortness of breath. The patient's...            1   \n",
       "\n",
       "                                             image_1  \\\n",
       "0  CXR3967_IM-2028-1001.jpg: PA and lateral chest...   \n",
       "1  CXR3332_IM-1596-1001.jpg: Radiograph Chest PA ...   \n",
       "2  CXR30_IM-1385-1001.jpg: Chest x-XXXX XXXX and ...   \n",
       "3  CXR2593_IM-1084-1001.jpg: Chest, 2 views, XXXX...   \n",
       "4  CXR1165_IM-0110-1001.jpg: Xray Chest PA and La...   \n",
       "\n",
       "                                             image_2  \\\n",
       "0  CXR3967_IM-2028-2001.jpg: PA and lateral chest...   \n",
       "1  CXR3332_IM-1596-2001.jpg: Radiograph Chest PA ...   \n",
       "2  CXR30_IM-1385-2001.jpg: Chest x-XXXX XXXX and ...   \n",
       "3  CXR2593_IM-1084-2001.jpg: Chest, 2 views, XXXX...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                             image_3 image_4 image_5  \n",
       "0                                                NaN     NaN     NaN  \n",
       "1  CXR3332_IM-1596-3001.jpg: Radiograph Chest PA ...     NaN     NaN  \n",
       "2                                                NaN     NaN     NaN  \n",
       "3                                                NaN     NaN     NaN  \n",
       "4                                                NaN     NaN     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Processing Textual Data from each .xml Report File and Storing it in a .csv File'''\n",
    "\n",
    "# function to iterate through all .xml report files and storing them in a dataframe\n",
    "def save_reports_df():\n",
    "    data = []\n",
    "    cnt = 0\n",
    "    for file in os.listdir(iu_xray_reports):\n",
    "        if file.endswith(\".xml\"):\n",
    "            cnt += 1\n",
    "            print(f\"Processing .xml File {cnt} out of {len(os.listdir(iu_xray_reports))}: {file}\")\n",
    "\n",
    "            file_path = os.path.join(iu_xray_reports, file)\n",
    "            try:\n",
    "                tree = ET.parse(file_path)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                pmc_id = root.find('.//pmcId').attrib.get('id')\n",
    "\n",
    "                comparison = indication = findings = impression = None\n",
    "\n",
    "                for abstract in root.findall('.//AbstractText'):\n",
    "                    if abstract.attrib.get('Label') == 'COMPARISON':\n",
    "                        comparison = abstract.text\n",
    "                    elif abstract.attrib.get('Label') == 'INDICATION':\n",
    "                        indication = abstract.text\n",
    "                    elif abstract.attrib.get('Label') == 'FINDINGS':\n",
    "                        findings = abstract.text\n",
    "                    elif abstract.attrib.get('Label') == 'IMPRESSION':\n",
    "                        impression = abstract.text\n",
    "\n",
    "                report_data = {\n",
    "                    'pmc_id': pmc_id,\n",
    "                    'findings': findings,\n",
    "                    'impression': impression,\n",
    "                    'comparison': comparison,\n",
    "                    'indication': indication,\n",
    "                }\n",
    "\n",
    "                parent_images = root.findall('parentImage')\n",
    "                report_data['image_count'] = len(parent_images)\n",
    "\n",
    "                for i, parent_image in enumerate(parent_images, start=1):\n",
    "                    image_file = parent_image.attrib['id'] + \".jpg\"\n",
    "                    caption = parent_image.find('caption').text if parent_image.find('caption') is not None else None\n",
    "                    report_data[f'image_{i}'] = f\"{image_file}: {caption}\" if caption else image_file\n",
    "\n",
    "                data.append(report_data)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# creating a dataframe and saving it as .csv\n",
    "iu_xray_reports_df_path = os.path.join(output_directory, 'iu_xray_reports_df.csv')\n",
    "if not os.path.exists(iu_xray_reports_df_path):\n",
    "    data = save_reports_df()\n",
    "    iu_xray_reports_df = pd.DataFrame(data)\n",
    "    iu_xray_reports_df.to_csv(iu_xray_reports_df_path, index=False)\n",
    "    print(f\"Dataframe saved to {iu_xray_reports_df_path}\")\n",
    "else:\n",
    "    print(f\"Dataframe already exists at {iu_xray_reports_df_path}\")\n",
    "    iu_xray_reports_df = pd.read_csv(iu_xray_reports_df_path)\n",
    "\n",
    "\n",
    "# displaying the stored dataframe\n",
    "print(\"\\n\\nDataframe Shape:\", iu_xray_reports_df.shape)\n",
    "\n",
    "print(\"\\n\\nDataframe Information:\\n\")\n",
    "display(iu_xray_reports_df.info())\n",
    "\n",
    "print(\"\\n\\nDisplaying Dataframe:\\n\")\n",
    "display(iu_xray_reports_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "execution": {
     "iopub.execute_input": "2024-10-19T18:58:25.133773Z",
     "iopub.status.busy": "2024-10-19T18:58:25.133396Z",
     "iopub.status.idle": "2024-10-19T18:58:25.148639Z",
     "shell.execute_reply": "2024-10-19T18:58:25.147394Z",
     "shell.execute_reply.started": "2024-10-19T18:58:25.133733Z"
    },
    "id": "bw4Ylfa94M1o",
    "outputId": "5ef503a0-265c-423b-8cae-1d36b136134d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of Images per Report:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images_qty</th>\n",
       "      <th>reports_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   images_qty  reports_count\n",
       "0           2           3208\n",
       "1           1            446\n",
       "2           3            181\n",
       "3           0            104\n",
       "4           4             15\n",
       "5           5              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Displaying the Number of Images per Report'''\n",
    "\n",
    "# displaying the distribution of number of images per report\n",
    "reports_count = iu_xray_reports_df['image_count'].value_counts().rename_axis('images_qty').reset_index(name='reports_count')\n",
    "print(\"\\n\\nNumber of Images per Report:\\n\")\n",
    "display(reports_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UouFxQwMNeo"
   },
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cGf99_CMV47"
   },
   "source": [
    "### **Preprocess Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-19T18:58:25.150758Z",
     "iopub.status.busy": "2024-10-19T18:58:25.150245Z",
     "iopub.status.idle": "2024-10-19T18:58:25.163866Z",
     "shell.execute_reply": "2024-10-19T18:58:25.162620Z",
     "shell.execute_reply.started": "2024-10-19T18:58:25.150707Z"
    },
    "id": "JTClOSxeSCOM",
    "outputId": "811cbc93-70e7-4d60-f213-26238488c44d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Images already exist at: ./datasets/iu_xray/output/images_preprocessed\n"
     ]
    }
   ],
   "source": [
    "'''Preprocessing Images - Resizing, Tensor Conversion and Normalization'''\n",
    "\n",
    "# function to preprocess and save images\n",
    "def preprocess_images(input_dir, output_dir):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    cnt = 0\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.png'):\n",
    "            cnt += 1\n",
    "            print(f\"Preprocessing File {cnt} out of {len(os.listdir(input_dir))}: {filename}\")\n",
    "\n",
    "            image_path = os.path.join(input_dir, filename)\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            processed_image = preprocess(image)\n",
    "\n",
    "            processed_image_path = os.path.join(output_dir, filename)\n",
    "\n",
    "            processed_image_pil = transforms.ToPILImage()(processed_image)\n",
    "            processed_image_pil.save(processed_image_path)\n",
    "\n",
    "\n",
    "# preprocessing images\n",
    "iu_xray_images_preprocessed = os.path.join(output_directory, 'images_preprocessed')\n",
    "if not os.path.exists(iu_xray_images_preprocessed):\n",
    "    print(f\"Preprocessing Images to: {iu_xray_images_preprocessed}\")\n",
    "    preprocess_images(iu_xray_images, iu_xray_images_preprocessed)\n",
    "    print(f\"Preprocessed Images saved to: {iu_xray_images_preprocessed}\")\n",
    "else:\n",
    "    print(f\"Preprocessed Images already exist at: {iu_xray_images_preprocessed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvdRoNqXMZlN"
   },
   "source": [
    "### **Preprocess Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T18:58:25.165652Z",
     "iopub.status.busy": "2024-10-19T18:58:25.165357Z",
     "iopub.status.idle": "2024-10-19T18:58:25.751858Z",
     "shell.execute_reply": "2024-10-19T18:58:25.750990Z",
     "shell.execute_reply.started": "2024-10-19T18:58:25.165620Z"
    },
    "id": "M8sW8uz8-plE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Preprocessed Text of DataFrame ./datasets/iu_xray/output/iu_xray_reports_df.csv already exists at: ./datasets/iu_xray/output/iu_xray_reports_preprocessed_df.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmc_id</th>\n",
       "      <th>findings</th>\n",
       "      <th>impression</th>\n",
       "      <th>comparison</th>\n",
       "      <th>indication</th>\n",
       "      <th>image_count</th>\n",
       "      <th>image_1</th>\n",
       "      <th>image_2</th>\n",
       "      <th>image_3</th>\n",
       "      <th>image_4</th>\n",
       "      <th>image_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3967</td>\n",
       "      <td>cardiomediastinal silhouette within normal lim...</td>\n",
       "      <td>acute radiographic cardiopulmonary process</td>\n",
       "      <td>none</td>\n",
       "      <td>chest pain</td>\n",
       "      <td>2</td>\n",
       "      <td>CXR3967_IM-2028-1001.jpg: PA and lateral chest...</td>\n",
       "      <td>CXR3967_IM-2028-2001.jpg: PA and lateral chest...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3332</td>\n",
       "      <td>heart normal size contour mediastinal widening...</td>\n",
       "      <td>acute cardiopulmonary abnormalities</td>\n",
       "      <td>radiograph chest lateral xxxx xxxx</td>\n",
       "      <td>weakness</td>\n",
       "      <td>3</td>\n",
       "      <td>CXR3332_IM-1596-1001.jpg: Radiograph Chest PA ...</td>\n",
       "      <td>CXR3332_IM-1596-2001.jpg: Radiograph Chest PA ...</td>\n",
       "      <td>CXR3332_IM-1596-3001.jpg: Radiograph Chest PA ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>lungs clear without focal consolidation effusi...</td>\n",
       "      <td>negative acute cardiopulmonary abnormality</td>\n",
       "      <td>none</td>\n",
       "      <td>xxxx year old male chest pain</td>\n",
       "      <td>2</td>\n",
       "      <td>CXR30_IM-1385-1001.jpg: Chest x-XXXX XXXX and ...</td>\n",
       "      <td>CXR30_IM-1385-2001.jpg: Chest x-XXXX XXXX and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2593</td>\n",
       "      <td>mild cardiomegaly unchanged stable superior me...</td>\n",
       "      <td>mild cardiomegaly interstitial prominence coul...</td>\n",
       "      <td>none</td>\n",
       "      <td>back pain</td>\n",
       "      <td>2</td>\n",
       "      <td>CXR2593_IM-1084-1001.jpg: Chest, 2 views, XXXX...</td>\n",
       "      <td>CXR2593_IM-1084-2001.jpg: Chest, 2 views, XXXX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1165</td>\n",
       "      <td>frontal lateral views chest show normal size c...</td>\n",
       "      <td>acute active cardiac pulmonary pleural disease</td>\n",
       "      <td>none</td>\n",
       "      <td>chest pain shortness breath patient lower abdo...</td>\n",
       "      <td>1</td>\n",
       "      <td>CXR1165_IM-0110-1001.jpg: Xray Chest PA and La...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pmc_id                                           findings  \\\n",
       "0    3967  cardiomediastinal silhouette within normal lim...   \n",
       "1    3332  heart normal size contour mediastinal widening...   \n",
       "2      30  lungs clear without focal consolidation effusi...   \n",
       "3    2593  mild cardiomegaly unchanged stable superior me...   \n",
       "4    1165  frontal lateral views chest show normal size c...   \n",
       "\n",
       "                                          impression  \\\n",
       "0         acute radiographic cardiopulmonary process   \n",
       "1                acute cardiopulmonary abnormalities   \n",
       "2         negative acute cardiopulmonary abnormality   \n",
       "3  mild cardiomegaly interstitial prominence coul...   \n",
       "4     acute active cardiac pulmonary pleural disease   \n",
       "\n",
       "                           comparison  \\\n",
       "0                                none   \n",
       "1  radiograph chest lateral xxxx xxxx   \n",
       "2                                none   \n",
       "3                                none   \n",
       "4                                none   \n",
       "\n",
       "                                          indication  image_count  \\\n",
       "0                                         chest pain            2   \n",
       "1                                           weakness            3   \n",
       "2                      xxxx year old male chest pain            2   \n",
       "3                                          back pain            2   \n",
       "4  chest pain shortness breath patient lower abdo...            1   \n",
       "\n",
       "                                             image_1  \\\n",
       "0  CXR3967_IM-2028-1001.jpg: PA and lateral chest...   \n",
       "1  CXR3332_IM-1596-1001.jpg: Radiograph Chest PA ...   \n",
       "2  CXR30_IM-1385-1001.jpg: Chest x-XXXX XXXX and ...   \n",
       "3  CXR2593_IM-1084-1001.jpg: Chest, 2 views, XXXX...   \n",
       "4  CXR1165_IM-0110-1001.jpg: Xray Chest PA and La...   \n",
       "\n",
       "                                             image_2  \\\n",
       "0  CXR3967_IM-2028-2001.jpg: PA and lateral chest...   \n",
       "1  CXR3332_IM-1596-2001.jpg: Radiograph Chest PA ...   \n",
       "2  CXR30_IM-1385-2001.jpg: Chest x-XXXX XXXX and ...   \n",
       "3  CXR2593_IM-1084-2001.jpg: Chest, 2 views, XXXX...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                             image_3 image_4 image_5  \n",
       "0                                                NaN     NaN     NaN  \n",
       "1  CXR3332_IM-1596-3001.jpg: Radiograph Chest PA ...     NaN     NaN  \n",
       "2                                                NaN     NaN     NaN  \n",
       "3                                                NaN     NaN     NaN  \n",
       "4                                                NaN     NaN     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Preprocessing Text - Lowercasing, Decontracting, Punctuation Removal, Number Removal, Two-Letter Word Removal, Stop Word Removal, Spell Checking, Extra Space Removal'''\n",
    "\n",
    "# download nltk resources and initialize spell checker\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "spell = SpellChecker()\n",
    "\n",
    "\n",
    "# function to convert text to lowercase\n",
    "def lowercase(text):\n",
    "    return text.lower() if isinstance(text, str) else text\n",
    "\n",
    "\n",
    "# function to decontract words\n",
    "def decontracted(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    contractions = {\n",
    "        \"won't\": \"will not\", \"can't\": \"can not\", \"couldn't\": \"could not\",\n",
    "        \"shouldn't\": \"should not\", \"wouldn't\": \"would not\", \"n't\": \" not\",\n",
    "        \"'re\": \" are\", \"'s\": \" is\", \"'d\": \" would\", \"'ll\": \" will\",\n",
    "        \"'t\": \" not\", \"'ve\": \" have\", \"'m\": \" am\"\n",
    "    }\n",
    "    for contraction, full_form in contractions.items():\n",
    "        text = text.replace(contraction, full_form)\n",
    "    return text\n",
    "\n",
    "\n",
    "# function to remove punctuations\n",
    "def rem_punctuations(text):\n",
    "    return re.sub(r'[^\\w\\s]', ' ', text) if isinstance(text, str) else text\n",
    "\n",
    "\n",
    "# function to remove numbers\n",
    "def rem_numbers(text):\n",
    "    return re.sub(r'\\d+', ' ', text) if isinstance(text, str) else text\n",
    "\n",
    "\n",
    "# function to remove two-letter words except \"no\" and \"ct\"\n",
    "def rem_two_letter_words(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    return ' '.join(word for word in text.split() if len(word) > 2 or word in [\"no\", \"ct\"])\n",
    "\n",
    "\n",
    "# function to remove stop words\n",
    "def rem_stop_words(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return ' '.join(word for word in text.split() if word not in stop_words)\n",
    "\n",
    "\n",
    "# function to correct spelling\n",
    "def correct_spelling(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    corrected = []\n",
    "    for word in text.split():\n",
    "        corrected_word = list(spell.candidates(word))[0] if spell.candidates(word) else word\n",
    "        corrected.append(corrected_word)\n",
    "    return ' '.join(corrected)\n",
    "\n",
    "\n",
    "# function to remove extra spaces\n",
    "def rem_extra_spaces(text):\n",
    "    return ' '.join(text.split()) if isinstance(text, str) else text\n",
    "\n",
    "\n",
    "# function to preprocess text\n",
    "def preprocess_text(data):\n",
    "    preprocessed = []\n",
    "    for sentence in tqdm(data.values):\n",
    "        sentence = str(sentence)\n",
    "        sentence = lowercase(sentence)\n",
    "        sentence = decontracted(sentence)\n",
    "        sentence = rem_punctuations(sentence)\n",
    "        sentence = rem_numbers(sentence)\n",
    "        sentence = rem_two_letter_words(sentence)\n",
    "        sentence = rem_stop_words(sentence)\n",
    "        sentence = correct_spelling(sentence)\n",
    "        sentence = rem_extra_spaces(sentence)\n",
    "        \n",
    "        preprocessed.append(sentence)\n",
    "\n",
    "    return preprocessed\n",
    "\n",
    "\n",
    "# path to the preprocessed dataframe\n",
    "iu_xray_reports_preprocessed_df_path = os.path.join(output_directory, 'iu_xray_reports_preprocessed_df.csv')\n",
    "iu_xray_reports_preprocessed_df = iu_xray_reports_df.copy()\n",
    "\n",
    "\n",
    "# preprocessing text columns in the dataframe\n",
    "if not os.path.exists(iu_xray_reports_preprocessed_df_path):\n",
    "    print(f\"Preprocessing Text of DataFrame {iu_xray_reports_df_path} to: {iu_xray_reports_preprocessed_df_path}\")\n",
    "    \n",
    "    preprocess_caption = True\n",
    "    preprocess_comparison = True\n",
    "    preprocess_indication = True\n",
    "    preprocess_findings = True\n",
    "    preprocess_impression = True\n",
    "    \n",
    "    if preprocess_caption and 'caption' in iu_xray_reports_preprocessed_df.columns:\n",
    "        print(\"Preprocessing Column: caption\")\n",
    "        iu_xray_reports_preprocessed_df['caption'] = iu_xray_reports_preprocessed_df['caption'].fillna('unknown').astype(str)\n",
    "        iu_xray_reports_preprocessed_df['caption'] = preprocess_text(iu_xray_reports_preprocessed_df['caption'])\n",
    "        iu_xray_reports_preprocessed_df.to_csv(iu_xray_reports_preprocessed_df_path, index=False)\n",
    "        print(f\"Saved preprocessed 'caption' column to: {iu_xray_reports_preprocessed_df_path}\")\n",
    "    \n",
    "    if preprocess_comparison and 'comparison' in iu_xray_reports_preprocessed_df.columns:\n",
    "        print(\"Preprocessing Column: comparison\")\n",
    "        iu_xray_reports_preprocessed_df['comparison'] = iu_xray_reports_preprocessed_df['comparison'].fillna('none').astype(str)\n",
    "        iu_xray_reports_preprocessed_df['comparison'] = preprocess_text(iu_xray_reports_preprocessed_df['comparison'])\n",
    "        iu_xray_reports_preprocessed_df.to_csv(iu_xray_reports_preprocessed_df_path, index=False)\n",
    "        print(f\"Saved preprocessed 'comparison' column to: {iu_xray_reports_preprocessed_df_path}\")\n",
    "    \n",
    "    if preprocess_indication and 'indication' in iu_xray_reports_preprocessed_df.columns:\n",
    "        print(\"Preprocessing Column: indication\")\n",
    "        iu_xray_reports_preprocessed_df['indication'] = iu_xray_reports_preprocessed_df['indication'].fillna('none').astype(str)\n",
    "        iu_xray_reports_preprocessed_df['indication'] = preprocess_text(iu_xray_reports_preprocessed_df['indication'])\n",
    "        iu_xray_reports_preprocessed_df.to_csv(iu_xray_reports_preprocessed_df_path, index=False)\n",
    "        print(f\"Saved preprocessed 'indication' column to: {iu_xray_reports_preprocessed_df_path}\")\n",
    "    \n",
    "    if preprocess_findings and 'findings' in iu_xray_reports_preprocessed_df.columns:\n",
    "        print(\"Preprocessing Column: findings\")\n",
    "        iu_xray_reports_preprocessed_df['findings'] = iu_xray_reports_preprocessed_df['findings'].fillna('none').astype(str)\n",
    "        iu_xray_reports_preprocessed_df['findings'] = preprocess_text(iu_xray_reports_preprocessed_df['findings'])\n",
    "        iu_xray_reports_preprocessed_df.to_csv(iu_xray_reports_preprocessed_df_path, index=False)\n",
    "        print(f\"Saved preprocessed 'findings' column to: {iu_xray_reports_preprocessed_df_path}\")\n",
    "    \n",
    "    if preprocess_impression and 'impression' in iu_xray_reports_preprocessed_df.columns:\n",
    "        print(\"Preprocessing Column: impression\")\n",
    "        iu_xray_reports_preprocessed_df['impression'] = iu_xray_reports_preprocessed_df['impression'].fillna('none').astype(str)\n",
    "        iu_xray_reports_preprocessed_df['impression'] = preprocess_text(iu_xray_reports_preprocessed_df['impression'])\n",
    "        iu_xray_reports_preprocessed_df.to_csv(iu_xray_reports_preprocessed_df_path, index=False)\n",
    "        print(f\"Saved preprocessed 'impression' column to: {iu_xray_reports_preprocessed_df_path}\")\n",
    "else:\n",
    "    print(f\"Preprocessed Text of DataFrame {iu_xray_reports_df_path} already exists at: {iu_xray_reports_preprocessed_df_path}\")\n",
    "    \n",
    "\n",
    "# displaying the preprocessed dataframe\n",
    "iu_xray_reports_preprocessed_df = pd.read_csv(iu_xray_reports_preprocessed_df_path)\n",
    "display(iu_xray_reports_preprocessed_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlOl6I0rMa68"
   },
   "source": [
    "### **Create Data Loaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T18:58:25.755509Z",
     "iopub.status.busy": "2024-10-19T18:58:25.755177Z",
     "iopub.status.idle": "2024-10-19T18:58:25.764725Z",
     "shell.execute_reply": "2024-10-19T18:58:25.763573Z",
     "shell.execute_reply.started": "2024-10-19T18:58:25.755470Z"
    }
   },
   "outputs": [],
   "source": [
    "'''Image Data Loaders to Supply Dataset to Model in Batches'''\n",
    "\n",
    "# classes in dataset\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "# function to load image data with transformation and batching\n",
    "def load_preprocessed_images(image_dir, batch_size=32):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    dataset = CustomImageDataset(image_dir, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T18:58:25.766517Z",
     "iopub.status.busy": "2024-10-19T18:58:25.766162Z",
     "iopub.status.idle": "2024-10-19T18:58:25.777607Z",
     "shell.execute_reply": "2024-10-19T18:58:25.776644Z",
     "shell.execute_reply.started": "2024-10-19T18:58:25.766477Z"
    }
   },
   "outputs": [],
   "source": [
    "'''Text Data Loaders to Supply Dataset to Model in Batches'''\n",
    "\n",
    "# classes in dataset\n",
    "class CustomTextDataset(Dataset):\n",
    "    def __init__(self, text_list, tokenizer, max_length=512):\n",
    "        self.text_list = text_list\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text_list[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {key: tensor.squeeze(0) for key, tensor in encoding.items()}\n",
    "\n",
    "\n",
    "# function to load text data with batching\n",
    "def load_preprocessed_texts(text_list, tokenizer, batch_size=32, max_length=512):\n",
    "    dataset = CustomTextDataset(text_list, tokenizer, max_length)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQ0H-X3HMgS1"
   },
   "source": [
    "## **Model Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsELnlXpMjGX"
   },
   "source": [
    "### **Visual Extractor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T18:58:25.779484Z",
     "iopub.status.busy": "2024-10-19T18:58:25.779194Z",
     "iopub.status.idle": "2024-10-19T18:58:32.604387Z",
     "shell.execute_reply": "2024-10-19T18:58:32.603412Z",
     "shell.execute_reply.started": "2024-10-19T18:58:25.779453Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-cd907fc2.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-cd907fc2.pth\n",
      "100%|| 171M/171M [00:01<00:00, 143MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features are already precomputed and will be loaded.\n",
      "Loading features from ./datasets/iu_xray/output/patch_feats.pt\n",
      "Loading features from ./datasets/iu_xray/output/avg_feats.pt\n",
      "Loading features from ./datasets/iu_xray/output/image_embeddings.pt\n",
      "Patch Features Shape: torch.Size([7470, 49, 2048])\n",
      "Average Features Shape: torch.Size([7470, 2048])\n",
      "Final Embedding Shape: torch.Size([7470, 50, 2048])\n"
     ]
    }
   ],
   "source": [
    "'''Visual Extractor to Extract Data from Image and Encode it Accordingly'''\n",
    "\n",
    "# defining device for gpu support\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# defining the visual extractor model using ResNet101 \n",
    "class VisualExtractor(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(VisualExtractor, self).__init__()\n",
    "        self.visual_extractor = args.visual_extractor\n",
    "        weights = models.ResNet101_Weights.DEFAULT if args.visual_extractor_pretrained else None  \n",
    "        model = getattr(models, self.visual_extractor)(weights=weights)\n",
    "        modules = list(model.children())[:-2]  \n",
    "        self.model = nn.Sequential(*modules)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc_layer = nn.Linear(model.fc.in_features, 2048) \n",
    "        \n",
    "    def forward(self, images):\n",
    "        patch_feats = self.model(images)\n",
    "        avg_feats = self.avg_pool(patch_feats).squeeze() \n",
    "        avg_feats = self.fc_layer(avg_feats)\n",
    "\n",
    "        batch_size, feat_size, _, _ = patch_feats.shape\n",
    "        patch_feats = patch_feats.view(batch_size, feat_size, -1).permute(0, 2, 1)\n",
    "        \n",
    "        final_embedding = torch.cat((avg_feats.unsqueeze(1), patch_feats), dim=1) \n",
    "        \n",
    "        return patch_feats, avg_feats, final_embedding\n",
    "\n",
    "\n",
    "# arguments for the visual extractor\n",
    "class Args:\n",
    "    visual_extractor = 'resnet101' \n",
    "    visual_extractor_pretrained = True\n",
    "\n",
    "\n",
    "# initializing the model\n",
    "args = Args()\n",
    "visual_extractor = VisualExtractor(args).to(device)\n",
    "\n",
    "\n",
    "# function to extract features from images\n",
    "def extract_features(images_dataloader):\n",
    "    all_patch_feats = []\n",
    "    all_avg_feats = []\n",
    "    all_final_embeddings = []\n",
    "\n",
    "    visual_extractor.eval() \n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(images_dataloader):\n",
    "            images = images.to(device)\n",
    "            patch_feats, avg_feats, final_embedding = visual_extractor(images)\n",
    "            all_patch_feats.append(patch_feats.cpu()) \n",
    "            all_avg_feats.append(avg_feats.cpu())\n",
    "            all_final_embeddings.append(final_embedding.cpu())\n",
    "\n",
    "    all_patch_feats = torch.cat(all_patch_feats, dim=0)\n",
    "    all_avg_feats = torch.cat(all_avg_feats, dim=0)\n",
    "    all_final_embeddings = torch.cat(all_final_embeddings, dim=0)\n",
    "\n",
    "    return all_patch_feats, all_avg_feats, all_final_embeddings\n",
    "\n",
    "\n",
    "# function to save extracted features\n",
    "def save_features(file_path, features):\n",
    "    print(f\"Saving features to {file_path}\")\n",
    "    torch.save(features, file_path)\n",
    "\n",
    "\n",
    "# function to lead the extracted features\n",
    "def load_features(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Loading features from {file_path}\")\n",
    "        return torch.load(file_path, weights_only=True)\n",
    "    return None\n",
    "\n",
    "\n",
    "# initializing paths\n",
    "feature_dir = output_directory\n",
    "patch_feats_file = os.path.join(output_directory, 'patch_feats.pt')\n",
    "avg_feats_file = os.path.join(output_directory, 'avg_feats.pt')\n",
    "image_embeddings_file = os.path.join(output_directory, 'image_embeddings.pt')\n",
    "images_dataloader = load_preprocessed_images(iu_xray_images_preprocessed)\n",
    "\n",
    "\n",
    "# extracting and saving the extracted features\n",
    "if os.path.exists(patch_feats_file) and os.path.exists(avg_feats_file) and os.path.exists(image_embeddings_file):\n",
    "    print(\"All features are already precomputed and will be loaded.\")\n",
    "    patch_feats = load_features(patch_feats_file)\n",
    "    avg_feats = load_features(avg_feats_file)\n",
    "    image_embeddings = load_features(image_embeddings_file)\n",
    "else:\n",
    "    print(\"Extracting features since they are not precomputed...\")\n",
    "    patch_feats, avg_feats, image_embeddings = extract_features(images_dataloader) \n",
    "        \n",
    "    os.makedirs(feature_dir, exist_ok=True)\n",
    "    save_features(patch_feats_file, patch_feats)\n",
    "    save_features(avg_feats_file, avg_feats)\n",
    "    save_features(image_embeddings_file, image_embeddings)\n",
    "\n",
    "\n",
    "# displaying sizes of the feature dataframes\n",
    "print(\"Patch Features Shape:\", patch_feats.shape)\n",
    "print(\"Average Features Shape:\", avg_feats.shape)\n",
    "print(\"Final Embedding Shape:\", image_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T18:58:32.605842Z",
     "iopub.status.busy": "2024-10-19T18:58:32.605566Z",
     "iopub.status.idle": "2024-10-19T18:58:32.621101Z",
     "shell.execute_reply": "2024-10-19T18:58:32.620165Z",
     "shell.execute_reply.started": "2024-10-19T18:58:32.605812Z"
    }
   },
   "outputs": [],
   "source": [
    "'''Visualizing Extracted Features using Plots'''\n",
    "\n",
    "# function to visualize features using PCA and t-SNE, including K-Means clustering\n",
    "def visualize_features(features, title):\n",
    "    print(f\"Original feature shape: {features.shape}\")\n",
    "    \n",
    "    features = features.reshape(features.shape[0], -1) \n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(features)\n",
    "\n",
    "    tsne = TSNE(n_components=2)\n",
    "    tsne_result = tsne.fit_transform(features)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.5)\n",
    "    plt.title(f\"PCA - {title}\")\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(tsne_result[:, 0], tsne_result[:, 1], alpha=0.5)\n",
    "    plt.title(f\"t-SNE - {title}\")\n",
    "    plt.xlabel(\"t-SNE Component 1\")\n",
    "    plt.ylabel(\"t-SNE Component 2\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    num_clusters = 3\n",
    "    kmeans = KMeans(n_clusters=num_clusters)\n",
    "    labels = kmeans.fit_predict(features)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=labels, cmap='viridis', alpha=0.5)\n",
    "    plt.title('t-SNE Result with K-Means Clusters')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(pca_result[:, 0], pca_result[:, 1], c=labels, cmap='viridis', alpha=0.5)\n",
    "    plt.title('PCA Result with K-Means Clusters')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# function to visualize features using PCA and t-SNE, without clustering\n",
    "def visualize_features_2(features, title):\n",
    "    print(f\"Original feature shape: {features.shape}\")\n",
    "    \n",
    "    flattened_features = features.reshape(features.shape[0], -1) \n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(flattened_features)\n",
    "\n",
    "    tsne = TSNE(n_components=2)\n",
    "    tsne_result = tsne.fit_transform(flattened_features)\n",
    "\n",
    "    plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.7)\n",
    "    plt.title(f'PCA: {title}')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.scatter(tsne_result[:, 0], tsne_result[:, 1], alpha=0.7)\n",
    "    plt.title(f't-SNE: {title}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# visualizing average features\n",
    "# visualize_features(avg_feats.numpy(), \"Average Features\")\n",
    "# visualize_features(patch_feats.numpy(), \"Patch Features\")\n",
    "# visualize_features(image_embeddings.numpy(), \"Image Embeddings\")\n",
    "\n",
    "# visualize_features_2(avg_feats.numpy(), \"Average Features\")\n",
    "# visualize_features_2(patch_feats.numpy(), \"Patch Features\")\n",
    "# visualize_features_2(image_embeddings.numpy(), \"Image Embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2kBZTiCMmsE"
   },
   "source": [
    "### **Text Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Text Encoder'''\n",
    "\n",
    "# function to embed text\n",
    "def embed_text(text_dataloader, model):\n",
    "    all_embeddings = []\n",
    "    \n",
    "    try:\n",
    "        for batch in text_dataloader:\n",
    "            if isinstance(batch, str):\n",
    "                inputs = tokenizer([batch], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "            elif isinstance(batch, list):\n",
    "                inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "            else:\n",
    "                raise ValueError(\"Batch must be of type str or List[str]\")\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "            all_embeddings.append(embeddings)\n",
    "\n",
    "        if all_embeddings: \n",
    "            return torch.cat(all_embeddings, dim=0)\n",
    "        else:\n",
    "            if isinstance(model, SentenceTransformer):\n",
    "                return torch.empty(0, model.get_sentence_embedding_dimension()).to(device)\n",
    "            else:\n",
    "                return torch.empty(0, model.config.hidden_size).to(device)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in embedding: {e}\")\n",
    "        if isinstance(model, SentenceTransformer):\n",
    "            return torch.empty(0, model.get_sentence_embedding_dimension()).to(device)\n",
    "        else:\n",
    "            return torch.empty(0, model.config.hidden_size).to(device)\n",
    "\n",
    "\n",
    "# function to compute cosine similarity\n",
    "def compute_cosine_similarity(embeddings1, embeddings2):\n",
    "    embeddings1 = F.normalize(embeddings1, p=2, dim=1)\n",
    "    embeddings2 = F.normalize(embeddings2, p=2, dim=1)\n",
    "    cosine = torch.mm(embeddings1, embeddings2.t())\n",
    "    return cosine\n",
    "\n",
    "\n",
    "# defining device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# # loading tokenizer, bert model and sentence-bert model\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "# sentence_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved to ./datasets/iu_xray/output/radiology_terms.csv\n",
      "Embeddings Shape: (47, 384)\n",
      "Already saved at path : ./datasets/iu_xray/output/dictionary_embeddings.pt\n"
     ]
    }
   ],
   "source": [
    "'''Text Encoder - Medical Knowledge encoder using TextEncoder -> note shape'''\n",
    "\n",
    "# defining radiology dictionary\n",
    "radiology_dictionary = {\n",
    "    \"pleural\": ['hemithorax', 'effusion', 'pneumothorax', 'parenchymal'],\n",
    "    \"lung\": ['lungs', 'pulmonary', 'hilar', 'lobe', 'consolidation', 'atelectasis', 'edema', 'opacity', 'pneumonia'],\n",
    "    \"mediastinal\": ['mediastinum', 'diaphragm', 'hemidiaphragm'],\n",
    "    \"cardiac\": ['heart', 'cardiomegaly', 'cardiomediastinal', 'atrium', 'ventricle', 'retrocardiac'],\n",
    "    \"vascular\": ['aorta', 'venous', 'jugular', 'aortic', 'vasculature', 'cabg'],\n",
    "    \"osseous\": ['rib', 'sternal', 'subclavian', 'thoracic'],\n",
    "    \"trachea\": ['endotrachea'],\n",
    "    \"stomach\": [],\n",
    "    \"abdomen\": [],\n",
    "    \"tube\": ['clips'],\n",
    "    \"spine\": ['vertebral', 'degenerative'],\n",
    "    \"nodule\": ['mass'],\n",
    "    \"chest\": ['small', 'enlarged', 'unchanged', 'stable', 'silhouette', 'contours', 'size', 'focal', 'mild', 'acute']\n",
    "}\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Define the filename and full path\n",
    "filename = 'radiology_terms.csv'\n",
    "dictionary_csv = os.path.join(output_directory, filename)  # Full path\n",
    "\n",
    "# Open the CSV file in write mode using the full path\n",
    "if not os.path.exists(dictionary_csv):    \n",
    "    with open(dictionary_csv, 'w', newline='') as file:  # Opens the file at dictionary_csv\n",
    "        writer = csv.writer(file)  # Creates a CSV writer object\n",
    "        writer.writerow(['Category', 'Term'])  # Writes the header row\n",
    "    \n",
    "        for category, terms in radiology_dictionary.items():\n",
    "            for term in terms:\n",
    "                if term:  # Ensure the term is not empty\n",
    "                    writer.writerow([category, term])  # Writes each row with category and term\n",
    "    \n",
    "    print(f\"Dictionary saved to {dictionary_csv}\")  # Confirms where the file is saved\n",
    "else:     print(f\"File already exists at {dictionary_csv}. No changes made.\")\n",
    "\n",
    "# Load the SentenceTransformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(text_list)\n",
    "\n",
    "# Display the shape of the embeddings\n",
    "print(f\"Embeddings Shape: {embeddings.shape}\")\n",
    "\n",
    "dictionary_pt = os.path.join(output_directory, 'dictionary_embeddings.pt')\n",
    "if not os.path.exists(dictionary_pt):    \n",
    "    torch.save(embeddings, dictionary_pt)\n",
    "    print(f\"Saved at : {dictionary_pt}\")\n",
    "else : print(f\"Already saved at path : {dictionary_pt}\")\n",
    "\n",
    "# # embedding dictionary and reports using bert, and historical medical reports using sentence transformer\n",
    "# dictionary_dataloader = load_preprocessed_texts(radiology_dictionary, tokenizer)\n",
    "# dictionary_embeddings = embed_text(dictionary_dataloader, bert_model)\n",
    "\n",
    "\n",
    "# # saving embeddings\n",
    "# embeddings_file_path = os.path.join(output_directory, 'dictionary_embeddings.pt')\n",
    "# if not os.path.exists(embeddings_file_path):\n",
    "#     torch.save(dictionary_embeddings.cpu(), embeddings_file_path)\n",
    "#     print(f\"Dictionary embeddings saved to {embeddings_file_path}\")\n",
    "\n",
    "\n",
    "# # displaying shape of embeddings\n",
    "# print(f\"Dictionary Embeddings Shape: {dictionary_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    404\u001b[0m         path_or_repo_id,\n\u001b[1;32m    405\u001b[0m         filename,\n\u001b[1;32m    406\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[1;32m    407\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    408\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    409\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    410\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    411\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    412\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    413\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    414\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    415\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    416\u001b[0m     )\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1232\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[1;32m   1233\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m   1234\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   1235\u001b[0m         \u001b[38;5;66;03m# File info\u001b[39;00m\n\u001b[1;32m   1236\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m   1237\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   1238\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m   1239\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   1240\u001b[0m         \u001b[38;5;66;03m# HTTP info\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[1;32m   1242\u001b[0m         etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[1;32m   1243\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1244\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1245\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   1246\u001b[0m         \u001b[38;5;66;03m# Additional options\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1248\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   1249\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1339\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m-> 1339\u001b[0m     _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1854\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1853\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1854\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1856\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1746\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1746\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m get_hf_file_metadata(\n\u001b[1;32m   1747\u001b[0m         url\u001b[38;5;241m=\u001b[39murl, proxies\u001b[38;5;241m=\u001b[39mproxies, timeout\u001b[38;5;241m=\u001b[39metag_timeout, headers\u001b[38;5;241m=\u001b[39mheaders, token\u001b[38;5;241m=\u001b[39mtoken\n\u001b[1;32m   1748\u001b[0m     )\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1666\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1666\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1667\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1668\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   1669\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1670\u001b[0m     allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1671\u001b[0m     follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1672\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1673\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   1674\u001b[0m )\n\u001b[1;32m   1675\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:364\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 364\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m    365\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    366\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    367\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    369\u001b[0m     )\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:388\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    387\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 388\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:454\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    446\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m     )\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-6714246e-33c72aac4912074a77e010f5;fe53025f-24dc-42bd-b0e0-ffeb58db44ba)\n\nRepository Not Found for url: https://huggingface.co/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m medical_history \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(report) \u001b[38;5;28;01mfor\u001b[39;00m report \u001b[38;5;129;01min\u001b[39;00m medical_history \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(report, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(report)]\n\u001b[1;32m      8\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m  \u001b[38;5;66;03m# Set your desired batch size\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Ensure you have your tokenizer defined\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Load the data into a DataLoader\u001b[39;00m\n\u001b[1;32m     12\u001b[0m medical_reports_dataloader \u001b[38;5;241m=\u001b[39m load_preprocessed_texts(medical_history, tokenizer, batch_size)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:844\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    843\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[0;32m--> 844\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m get_tokenizer_config(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[1;32m    846\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:676\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m     token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[1;32m    675\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 676\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m    677\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m    678\u001b[0m     TOKENIZER_CONFIG_FILE,\n\u001b[1;32m    679\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    680\u001b[0m     force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    681\u001b[0m     resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    682\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    683\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    684\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    685\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    686\u001b[0m     subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m    687\u001b[0m     _raise_exceptions_for_gated_repo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    688\u001b[0m     _raise_exceptions_for_missing_entries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    689\u001b[0m     _raise_exceptions_for_connection_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    690\u001b[0m     _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[1;32m    691\u001b[0m )\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    693\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:426\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    431\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "'''Text Encoder - Medical History encoding using sentence encoder'''\n",
    "\n",
    "# reading and preprocessing medical history reports\n",
    "iu_xray_reports_preprocessed_df_path = os.path.join(output_directory, 'iu_xray_reports_preprocessed_df.csv')\n",
    "medical_history = pd.read_csv(iu_xray_reports_preprocessed_df_path)[\"findings\"].dropna().tolist()\n",
    "medical_history = [str(report) for report in medical_history if isinstance(report, str) or pd.notna(report)]\n",
    "\n",
    "batch_size = 32  # Set your desired batch size\n",
    "tokenizer = AutoTokenizer.from_pretrained('all-MiniLM-L6-v2')  # Ensure you have your tokenizer defined\n",
    "\n",
    "# Load the data into a DataLoader\n",
    "medical_reports_dataloader = load_preprocessed_texts(medical_history, tokenizer, batch_size)\n",
    "\n",
    "# Step 3: Print the shapes of the batches\n",
    "for batch in medical_reports_dataloader:\n",
    "    # Printing shapes of input tensors\n",
    "    print({key: tensor.shape for key, tensor in batch.items()})\n",
    "    break  # Remove this break to see all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No invalid entries found.\n",
      "Error in embedding: Batch must be of type str or List[str]\n",
      "Already at ./datasets/iu_xray/output/historical_embeddings_b.pt\n",
      "Historical Embeddings Shape: torch.Size([0, 768])\n"
     ]
    }
   ],
   "source": [
    "'''Text Encoder -  Sentence-Bert Encoder using Medical History'''\n",
    "\n",
    "# reading and preprocessing medical history reports\n",
    "iu_xray_reports_preprocessed_df_path = os.path.join(output_directory, 'iu_xray_reports_preprocessed_df.csv')\n",
    "medical_history = pd.read_csv(iu_xray_reports_preprocessed_df_path)[\"findings\"].dropna().tolist()\n",
    "medical_history = [str(report) for report in medical_history if isinstance(report, str) or pd.notna(report)]\n",
    "\n",
    "invalid_entries = [report for report in medical_history if not isinstance(report, (str, list))]\n",
    "\n",
    "# Print if there are any invalid entries\n",
    "if invalid_entries:\n",
    "    print(f\"Found {len(invalid_entries)} invalid entries: {invalid_entries}\")\n",
    "else:\n",
    "    print(\"No invalid entries found.\")\n",
    "\n",
    "# encoding medical history using Sentence-BERT\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "historical_dataloader_b = load_preprocessed_texts(medical_history, tokenizer)\n",
    "historical_embeddings_b = embed_text(historical_dataloader, bert_model)\n",
    "\n",
    "# # Check for invalid entries after batching\n",
    "# invalid_entries_after_batches = [\n",
    "#     report for batch in historical_dataloader_b for report in batch.values() if not isinstance(report, (str, list))\n",
    "# ]\n",
    "\n",
    "# for batch in historical_dataloader:\n",
    "#     print(type(batch))  # Check the type\n",
    "#     print(batch)  # Print the batch content\n",
    "#     break\n",
    "\n",
    "\n",
    "\n",
    "# saving embeddings\n",
    "historical_pt_b = os.path.join(output_directory, 'historical_embeddings_b.pt')\n",
    "if not os.path.exists(historical_pt_b):\n",
    "    torch.save(historical_embeddings_b.cpu(), historical_pt_b)\n",
    "    print(f\"Historical embeddings saved to {historical_pt_b}\")\n",
    "else : print(f\"Already at {historical_pt_b}\")\n",
    "\n",
    "\n",
    "# displaying shape of embeddings\n",
    "print(f\"Historical Embeddings Shape: {historical_embeddings_b.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T19:11:16.520892Z",
     "iopub.status.busy": "2024-10-19T19:11:16.520038Z",
     "iopub.status.idle": "2024-10-19T19:11:16.658663Z",
     "shell.execute_reply": "2024-10-19T19:11:16.657206Z",
     "shell.execute_reply.started": "2024-10-19T19:11:16.520840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in embedding: SentenceTransformer.forward() missing 1 required positional argument: 'input'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (0x768 and 384x0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m historical_embeddings_normalized \u001b[38;5;241m=\u001b[39m historical_embeddings \u001b[38;5;241m/\u001b[39m historical_embeddings\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m current_embeddings_normalized \u001b[38;5;241m=\u001b[39m current_embeddings \u001b[38;5;241m/\u001b[39m current_embeddings\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 12\u001b[0m similarity_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_cosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictionary_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistorical_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimilarity Matrix Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimilarity_matrix\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# finding top-k relevant entries\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 40\u001b[0m, in \u001b[0;36mcompute_cosine_similarity\u001b[0;34m(embeddings1, embeddings2)\u001b[0m\n\u001b[1;32m     38\u001b[0m embeddings1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(embeddings1, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     39\u001b[0m embeddings2 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(embeddings2, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m cosine \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cosine\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (0x768 and 384x0)"
     ]
    }
   ],
   "source": [
    "'''Text Encoder - Finding Reports Similar to Current Report'''\n",
    "\n",
    "# current report embedding\n",
    "current_report = 'Heart size pulmonary vascularity appear within normal limits mild tortuosity descending thoracic aorta lungs free focal airspace disease pleural effusion pneumothorax seen discrete nodules adenopathy noted degenerative changes present spine'\n",
    "current_embeddings = embed_text(current_report, sentence_model)\n",
    "\n",
    "\n",
    "# computing cosine similarity\n",
    "historical_embeddings_normalized = historical_embeddings / historical_embeddings.norm(dim=1, keepdim=True)\n",
    "current_embeddings_normalized = current_embeddings / current_embeddings.norm(dim=1, keepdim=True)\n",
    "\n",
    "similarity_matrix = compute_cosine_similarity(dictionary_embeddings, historical_embeddings)\n",
    "print(f\"Similarity Matrix Shape: {similarity_matrix.shape}\")\n",
    "\n",
    "\n",
    "# finding top-k relevant entries\n",
    "k = 5\n",
    "top_k_indices = similarity_matrix.topk(k=k, dim=1).indices\n",
    "\n",
    "\n",
    "# preparing relevant entries based on indices\n",
    "relevant_entries = []\n",
    "for row in top_k_indices:\n",
    "    relevant_entries.append(medical_history[row.item()])\n",
    "\n",
    "\n",
    "# printing relevant entries for each report\n",
    "print(f\"Relevant Entries for the Current Report: {relevant_entries}\")\n",
    "\n",
    "\n",
    "# update the historical embeddingx\n",
    "historical_embeddings.append(current_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIYzXGtsMqmQ"
   },
   "source": [
    "### **Multilevel Alignment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Multilevel Alignment based on BLIP Architecture'''\n",
    "\n",
    "\n",
    "'''\n",
    "Use the reports and their corresponding image embeddings for that particular report, \n",
    "to find alignment for each report present and some sort of relation based off the BLIP architecture.\n",
    "\n",
    "image_features = extract_image_features(df[['image_1', 'image_2', 'image_3']].values.flatten())\n",
    "similarity_matrix = cosine_similarity(findings_embeddings[0].detach().numpy(), image_features)\n",
    "\n",
    "Coarse Alignment (Cosine Similarity)\n",
    "Fine-Grained Alignment (Attention)\n",
    "\n",
    "\n",
    "# Step 1: Encode Findings Text (Text Embeddings)\n",
    "def get_findings_embeddings(findings_list):\n",
    "    encoded_findings = tokenizer(findings_list, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        findings_embeddings = bert_model(**encoded_findings).last_hidden_state.mean(dim=1)  # Average pooling\n",
    "    return findings_embeddings\n",
    "\n",
    "# Step 2: Extract Image Features\n",
    "def get_image_features(df):\n",
    "    images = df[['image_1', 'image_2', 'image_3', 'image_4', 'image_5']].values.flatten()\n",
    "    image_features = extract_image_features(images)\n",
    "    return image_features\n",
    "\n",
    "# Step 3: Coarse Alignment (Cosine Similarity)\n",
    "def coarse_alignment(findings_embeddings, image_features):\n",
    "    # Compute cosine similarity between findings and image features\n",
    "    findings_embeddings_np = findings_embeddings.detach().numpy()\n",
    "    similarity_matrix = cosine_similarity(findings_embeddings_np, image_features)\n",
    "    return similarity_matrix\n",
    "\n",
    "# Step 4: Fine-Grained Alignment (Attention Mechanism)\n",
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention = torch.nn.Linear(embedding_dim, 1)\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        attn_weights = torch.nn.functional.softmax(self.attention(embeddings), dim=1)\n",
    "        weighted_embeddings = embeddings * attn_weights\n",
    "        return weighted_embeddings.sum(dim=1)\n",
    "\n",
    "def fine_grained_alignment(findings_embeddings, image_features):\n",
    "    attention_layer = Attention(findings_embeddings.size(1))\n",
    "    weighted_findings = attention_layer(findings_embeddings)  # Attention on findings embeddings\n",
    "    weighted_image_features = attention_layer(torch.tensor(image_features))  # Attention on image features\n",
    "    return weighted_findings, weighted_image_features\n",
    "\n",
    "# Final Code Integration\n",
    "def multilevel_alignment(df):\n",
    "    # Step 1: Findings Embeddings\n",
    "    findings_embeddings = get_findings_embeddings(df['findings'].tolist())\n",
    "\n",
    "    # Step 2: Image Features\n",
    "    image_features = get_image_features(df)\n",
    "\n",
    "    # Step 3: Coarse Alignment\n",
    "    similarity_matrix = coarse_alignment(findings_embeddings, image_features)\n",
    "    print(\"Coarse Alignment (Cosine Similarity):\", similarity_matrix)\n",
    "\n",
    "    # Step 4: Fine-Grained Alignment\n",
    "    weighted_findings, weighted_images = fine_grained_alignment(findings_embeddings, image_features)\n",
    "    print(\"Fine-Grained Alignment (Findings):\", weighted_findings)\n",
    "    print(\"Fine-Grained Alignment (Images):\", weighted_images)\n",
    "\n",
    "# Example usage\n",
    "# df is your DataFrame with the columns: findings, image_1, image_2, etc.\n",
    "# multilevel_alignment(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# Load the BLIP model and processor\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "'''\n",
    "# Define ITC and ITM losses\n",
    "def itc_loss(image_embeddings, text_embeddings, temperature=0.1):\n",
    "    # Normalize embeddings\n",
    "    image_embeddings = nn.functional.normalize(image_embeddings, dim=1)\n",
    "    text_embeddings = nn.functional.normalize(text_embeddings, dim=1)\n",
    "    \n",
    "    # Calculate similarity\n",
    "    similarity_matrix = torch.matmul(image_embeddings, text_embeddings.t())\n",
    "    labels = torch.arange(similarity_matrix.size(0)).to(similarity_matrix.device)\n",
    "    \n",
    "    # ITC loss\n",
    "    loss = nn.CrossEntropyLoss()(similarity_matrix / temperature, labels)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def itm_loss(image_embeddings, text_embeddings, match_labels):\n",
    "    logits = torch.matmul(image_embeddings, text_embeddings.t())\n",
    "    return nn.BCEWithLogitsLoss()(logits, match_labels.float())\n",
    "\n",
    "\n",
    "# Define the alignment module\n",
    "def align_with_dictionary(image_embedding, dictionary_knowledge):\n",
    "    # Simple alignment based on keywords\n",
    "    relevant_knowledge = {}\n",
    "    for key, value in dictionary_knowledge.items():\n",
    "        if key in image_embedding:  # Replace with actual keyword checking\n",
    "            relevant_knowledge[key] = value\n",
    "    return relevant_knowledge\n",
    "    \n",
    "\n",
    "# Extract and process embeddings\n",
    "def get_embeddings(image, text):\n",
    "    inputs = processor(images=image, text=text, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.get_image_features(**inputs)\n",
    "        image_embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        text_embeddings = model.get_text_features(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return image_embeddings, text_embeddings\n",
    "\n",
    "\n",
    "# Training step\n",
    "def train_step(image, text, dictionary_knowledge, optimizer):\n",
    "    model.train()\n",
    "    image_embeddings, text_embeddings = get_embeddings(image, text)\n",
    "    \n",
    "    # ITC and ITM tasks\n",
    "    itc_loss_value = itc_loss(image_embeddings, text_embeddings)\n",
    "    match_labels = (text_embeddings > 0).float()  # Example match labels\n",
    "    itm_loss_value = itm_loss(image_embeddings, text_embeddings, match_labels)\n",
    "    \n",
    "    total_loss = itc_loss_value + itm_loss_value\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return total_loss.item()\n",
    "\n",
    "\n",
    "# Example dictionary knowledge\n",
    "dictionary_knowledge = radiology_dictionary\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # Set your number of epochs\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "# Assuming you have a data loader defined that provides (image, text) pairs\n",
    "for epoch in range(num_epochs):\n",
    "    for image, text in data_loader:  # Replace with your actual data loader\n",
    "        image = image.to(device)  # Move image to the appropriate device\n",
    "        loss = train_step(image, text, dictionary_knowledge, optimizer)\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Multilevel Alignment based on BLIP Architecture - Coarse Grained Alignment (Image Text Contrastive)'''\n",
    "\n",
    "'''\n",
    "Image Feature Extraction (ResNet101):\n",
    "\n",
    "Extracts features from images using a pre-trained ResNet.\n",
    "Function: extract_image_features()\n",
    "Text Embedding Extraction (BERT):\n",
    "\n",
    "Encodes textual findings into embeddings using BERT.\n",
    "Function: get_findings_embeddings()\n",
    "Projection and Normalization:\n",
    "\n",
    "Projects both image features and text embeddings to a common 512-dimensional space and normalizes them.\n",
    "Code part:\n",
    "python\n",
    "Copy code\n",
    "image_proj = F.normalize(self.image_projection(image_features), p=2, dim=-1)\n",
    "text_proj = F.normalize(self.text_projection(text_embeddings), p=2, dim=-1)\n",
    "Cosine Similarity Calculation:\n",
    "\n",
    "Calculates the cosine similarity between projected text and image embeddings.\n",
    "Code part:\n",
    "python\n",
    "Copy code\n",
    "cosine_sim = torch.matmul(text_proj, image_proj.T)\n",
    "Coarse Alignment Function (ITC):\n",
    "\n",
    "Function: coarse_alignment()\n",
    "Outputs the cosine similarity between text and image pairs.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Multilevel Alignment based on BLIP Architecture - Fine Grained Alignment (Image Text Matching)'''\n",
    "\n",
    "\n",
    "'''\n",
    "Task List for ITM (Fine-Grained Alignment):\n",
    "Binary Classification Head (ITM):\n",
    "\n",
    "Determines whether an image and text pair match (1) or not (0).\n",
    "Code part:\n",
    "python\n",
    "Copy code\n",
    "itm_logits = self.itm_head(text_proj * image_proj)\n",
    "Fine-Grained Alignment Function (ITM):\n",
    "\n",
    "Function: fine_grained_alignment()\n",
    "Outputs logits indicating the match/mismatch of image-text pairs.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uz4pEhW2MuBF"
   },
   "source": [
    "### **Report Generator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_WeRBlDMwX2"
   },
   "source": [
    "### **Complete Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZjhDeJxMzgg"
   },
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Uk_G0K8M2H9"
   },
   "source": [
    "### **Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXhkaJVvM3Uu"
   },
   "source": [
    "## **Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzTZZUlQM401"
   },
   "source": [
    "### **Testing**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "MlOl6I0rMa68",
    "PsELnlXpMjGX",
    "D2kBZTiCMmsE",
    "gIYzXGtsMqmQ",
    "Uz4pEhW2MuBF",
    "Z_WeRBlDMwX2",
    "7Uk_G0K8M2H9",
    "OXhkaJVvM3Uu"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
