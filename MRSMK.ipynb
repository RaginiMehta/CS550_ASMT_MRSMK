{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["MlOl6I0rMa68","PsELnlXpMjGX","D2kBZTiCMmsE","gIYzXGtsMqmQ","Uz4pEhW2MuBF","Z_WeRBlDMwX2","7Uk_G0K8M2H9","OXhkaJVvM3Uu"],"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Medical Report Summarisation using Medical Knowledge**\n\n### **References**\n\n**Main Reference**\n- Radiology report generation with medical knowledge and multilevel image-report alignment: A new method and its verification\nhttps://www.sciencedirect.com/science/article/pii/S0933365723002282\n\n","metadata":{"id":"Bnpd7Zh0NPl2"}},{"cell_type":"markdown","source":"## **Data Collection**","metadata":{"id":"oKdcyk1sMEtD"}},{"cell_type":"markdown","source":"### **Collect Datasets**","metadata":{"id":"p81rfgckMR9a"}},{"cell_type":"code","source":"'''Libraries Installation and Import'''\n\n# installling necessary libraries\n!pip -q install --user requests numpy pandas matplotlib tqdm Pillow opencv-python nltk pyspellchecker torch torchvision torchaudio transformers scikit-learn sentence-transformers\n\n# importing required libraries\nimport os\nimport re\nimport csv\nimport requests\nimport tarfile\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport xml.etree.ElementTree as ET\nfrom tqdm import tqdm\nfrom PIL import Image\nimport cv2\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom spellchecker import SpellChecker\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\n\nimport transformers\nfrom transformers import BertTokenizer, BertModel\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import BlipProcessor, BlipForConditionalGeneration\nfrom transformers import AutoTokenizer\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AYR_B6u1ojJt","outputId":"faaac1ed-b54b-4cfd-b3e4-cca51372318e","execution":{"iopub.status.busy":"2024-10-20T18:11:38.836891Z","iopub.execute_input":"2024-10-20T18:11:38.837519Z","iopub.status.idle":"2024-10-20T18:11:50.429556Z","shell.execute_reply.started":"2024-10-20T18:11:38.837470Z","shell.execute_reply":"2024-10-20T18:11:50.428573Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}]},{"cell_type":"code","source":"'''Setting Paths'''\n\n# project directory\n# from google.colab import drive\n# drive.mount('/content/drive')\n# project_directory = '/content/drive/Othercomputers/My Laptop/CS550_ASMT_MRSMK/datasets'\n# project_directory = '/content/drive/MyDrive/Academics/CS550 Machine Learning/CS550 ASMT MRSMK/datasets'\n\nproject_directory = \"./datasets\"\ndataset = 'iu_xray/'\niu_xray_dataset = os.path.join(project_directory, dataset)\n\n\n# input directory\ninput_directory = os.path.join(iu_xray_dataset, \"input\")\n\nimages_dir = os.path.join(input_directory, \"images\")\nreports_dir = os.path.join(input_directory, \"reports\")\niu_xray_images = images_dir\niu_xray_reports = os.path.join(reports_dir, 'ecgen-radiology')\n\n\n# output directory \noutput_directory = os.path.join(iu_xray_dataset, \"output\")\nos.makedirs(output_directory, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T18:06:53.090407Z","iopub.execute_input":"2024-10-20T18:06:53.091026Z","iopub.status.idle":"2024-10-20T18:06:53.097948Z","shell.execute_reply.started":"2024-10-20T18:06:53.090990Z","shell.execute_reply":"2024-10-20T18:06:53.096976Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"'''Setup - Generalized'''\n\n# setup to download the IU X-Ray Dataset\nimages_url = \"https://openi.nlm.nih.gov/imgs/collections/NLMCXR_png.tgz\"\nreports_url = \"https://openi.nlm.nih.gov/imgs/collections/NLMCXR_reports.tgz\"\n\n\n# function to check the file size of a given URL\ndef get_file_size(url):\n    response = requests.head(url)\n    size_in_bytes = int(response.headers.get('Content-Length', 0))\n    size_in_mb = size_in_bytes / (1024 * 1024)\n    return size_in_mb\n\n\n# function to download and extract from a given url to a given directory\ndef download_and_extract(url, save_dir):\n    file_name = url.split('/')[-1]\n    file_path = os.path.join(save_dir, file_name)\n\n    response = requests.get(url, stream=True)\n    total_size = int(response.headers.get('Content-Length', 0))\n    downloaded_size = 0\n\n    with open(file_path, 'wb') as file:\n        for chunk in response.iter_content(chunk_size=1024):\n            if chunk:\n                file.write(chunk)\n                downloaded_size += len(chunk)\n                percent_complete = (downloaded_size / total_size) * 100\n                print(f\"Downloaded {downloaded_size / (1024*1024):.2f} MB out of {total_size / (1024*1024):.2f} MB: {percent_complete:.2f}% complete\")\n\n    print(\"\\nDownload complete!\")\n\n    with tarfile.open(file_path, 'r:gz') as tar:\n        members = tar.getmembers()\n        total_files = len(members)\n\n        for idx, member in enumerate(members, start=1):\n            tar.extract(member, path=save_dir)\n            print(f\"Extracting File {idx} out of {total_files}: {member.name}\")\n\n    os.remove(file_path)\n\n\n# downloading  IU X-Ray dataset\nif not os.path.exists(images_dir):\n    images_size = get_file_size(images_url)\n    print(f\"Downloading {images_url} to: {images_dir} ({images_size:.2f} MB)\")\n    os.makedirs(images_dir, exist_ok=True)\n    download_and_extract(images_url, images_dir)\n    print(f\"Downloaded {images_url} to: {images_dir}\")\nelse:\n    print(f\"{images_url} already exists at: {images_dir}\")\n\nif not os.path.exists(reports_dir):\n    reports_size = get_file_size(reports_url)\n    print(f\"Downloading {reports_url} to: {reports_dir} ({reports_size:.2f} MB)\")\n    os.makedirs(reports_dir, exist_ok=True)\n    download_and_extract(reports_url, reports_dir)\n    print(f\"Downloaded {reports_url} to: {reports_dir}\")\nelse:\n    print(f\"{reports_url} already exists at: {reports_dir}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"49-0xiXplwH8","outputId":"ea63eda3-908a-4f5f-eeec-a4019130e57f","execution":{"iopub.status.busy":"2024-10-20T18:06:53.099378Z","iopub.execute_input":"2024-10-20T18:06:53.099765Z","iopub.status.idle":"2024-10-20T18:06:53.138264Z","shell.execute_reply.started":"2024-10-20T18:06:53.099719Z","shell.execute_reply":"2024-10-20T18:06:53.137274Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"https://openi.nlm.nih.gov/imgs/collections/NLMCXR_png.tgz already exists at: ./datasets/iu_xray/input/images\nhttps://openi.nlm.nih.gov/imgs/collections/NLMCXR_reports.tgz already exists at: ./datasets/iu_xray/input/reports\n","output_type":"stream"}]},{"cell_type":"code","source":"'''Exploring the IU X-Ray Dataset Contents'''\n\n# displaying directory and subdirectory contents\nprint(\"\\nPath: \", iu_xray_images)\nprint(f\"Directory Contents: {len(os.listdir(iu_xray_images))} Images\")\n\nprint(\"\\nPath: \", iu_xray_reports)\nprint(f\"Directory Contents: {len(os.listdir(iu_xray_reports))} Reports\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ZSA8Jyowaoh","outputId":"dffa4899-00a7-4d49-a118-8dd85400ba06","execution":{"iopub.status.busy":"2024-10-20T18:06:53.142111Z","iopub.execute_input":"2024-10-20T18:06:53.142399Z","iopub.status.idle":"2024-10-20T18:06:53.155638Z","shell.execute_reply.started":"2024-10-20T18:06:53.142369Z","shell.execute_reply":"2024-10-20T18:06:53.154770Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\nPath:  ./datasets/iu_xray/input/images\nDirectory Contents: 7471 Images\n\nPath:  ./datasets/iu_xray/input/reports/ecgen-radiology\nDirectory Contents: 3955 Reports\n","output_type":"stream"}]},{"cell_type":"code","source":"'''Processing Textual Data from each .xml Report File and Storing it in a .csv File'''\n\n# function to iterate through all .xml report files and storing them in a dataframe\ndef save_images_df():\n    data = []\n    cnt = 0\n    for file in os.listdir(iu_xray_reports):\n        if file.endswith(\".xml\"):\n            cnt += 1\n            print(f\"Processing .xml File {cnt} out of {len(os.listdir(iu_xray_reports))}: {file}\")\n\n            file_path = os.path.join(iu_xray_reports, file)\n            try:\n                tree = ET.parse(file_path)\n                root = tree.getroot()\n\n                pmc_id = root.find('.//pmcId').attrib.get('id')\n\n                comparison = indication = findings = impression = None\n\n                for abstract in root.findall('.//AbstractText'):\n                    if abstract.attrib.get('Label') == 'COMPARISON':\n                        comparison = abstract.text\n                    elif abstract.attrib.get('Label') == 'INDICATION':\n                        indication = abstract.text\n                    elif abstract.attrib.get('Label') == 'FINDINGS':\n                        findings = abstract.text\n                    elif abstract.attrib.get('Label') == 'IMPRESSION':\n                        impression = abstract.text\n\n                for parent_image in root.findall('parentImage'):\n                    image_file = parent_image.attrib['id'] + \".png\"\n                    image_path = os.path.join(iu_xray_images, image_file)\n                    image = cv2.imread(image_path)\n\n                    if image is not None:\n                        height, width, channels = image.shape\n                        caption = parent_image.find('caption').text if parent_image.find('caption') is not None else None\n                        data.append([pmc_id, image_file, caption, comparison, indication, findings, impression, height, width])\n                    else:\n                        print(f\"Warning: Unable to read image {image_path}\")\n\n            except Exception as e:\n                print(f\"Error processing file {file}: {e}\")\n\n    return data\n\n\n# creating a dataframe and saving it as .csv\niu_xray_images_df_path = os.path.join(output_directory, 'iu_xray_images_df.csv')\nif not os.path.exists(iu_xray_images_df_path):\n    data = save_images_df()\n    columns = ['pmc_id', 'image_filename', 'caption', 'comparison', 'indication', 'findings', 'impression', 'height', 'width']\n    iu_xray_images_df = pd.DataFrame(data, columns=columns)\n    iu_xray_images_df.to_csv(iu_xray_images_df_path, index=False)\n    print(f\"Dataframe saved to {iu_xray_images_df_path}\")\nelse:\n    print(f\"Dataframe already exists at {iu_xray_images_df_path}\")\n    iu_xray_images_df = pd.read_csv(iu_xray_images_df_path)\n\n\n# displaying the stored dataframe\nprint(\"\\n\\nDataframe Shape:\", iu_xray_images_df.shape)\n\nprint(\"\\n\\nDataframe Information:\\n\")\ndisplay(iu_xray_images_df.info())\n\nprint(\"\\n\\nDisplaying Dataframe:\\n\")\ndisplay(iu_xray_images_df.head())","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":822},"id":"qGczexPLUaN5","outputId":"8c7528a1-7064-4802-c276-edef004f0d5b","execution":{"iopub.status.busy":"2024-10-20T18:07:44.320603Z","iopub.execute_input":"2024-10-20T18:07:44.320983Z","iopub.status.idle":"2024-10-20T18:07:44.414386Z","shell.execute_reply.started":"2024-10-20T18:07:44.320916Z","shell.execute_reply":"2024-10-20T18:07:44.413508Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Dataframe already exists at ./datasets/iu_xray/output/iu_xray_images_df.csv\n\n\nDataframe Shape: (7470, 9)\n\n\nDataframe Information:\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7470 entries, 0 to 7469\nData columns (total 9 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   pmc_id          7470 non-null   int64 \n 1   image_filename  7470 non-null   object\n 2   caption         7468 non-null   object\n 3   comparison      5210 non-null   object\n 4   indication      7311 non-null   object\n 5   findings        6473 non-null   object\n 6   impression      7418 non-null   object\n 7   height          7470 non-null   int64 \n 8   width           7470 non-null   int64 \ndtypes: int64(3), object(6)\nmemory usage: 525.4+ KB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}},{"name":"stdout","text":"\n\nDisplaying Dataframe:\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   pmc_id            image_filename  \\\n0    3967  CXR3967_IM-2028-1001.png   \n1    3967  CXR3967_IM-2028-2001.png   \n2    3332  CXR3332_IM-1596-1001.png   \n3    3332  CXR3332_IM-1596-2001.png   \n4    3332  CXR3332_IM-1596-3001.png   \n\n                                            caption  \\\n0  PA and lateral chest x-XXXX XXXX at XXXX hours.    \n1  PA and lateral chest x-XXXX XXXX at XXXX hours.    \n2      Radiograph Chest PA and Lateral XXXX, XXXX.    \n3      Radiograph Chest PA and Lateral XXXX, XXXX.    \n4      Radiograph Chest PA and Lateral XXXX, XXXX.    \n\n                                    comparison  indication  \\\n0                                          NaN  Chest pain   \n1                                          NaN  Chest pain   \n2  Radiograph Chest PA and Lateral XXXX, XXXX.   Weakness.   \n3  Radiograph Chest PA and Lateral XXXX, XXXX.   Weakness.   \n4  Radiograph Chest PA and Lateral XXXX, XXXX.   Weakness.   \n\n                                            findings  \\\n0  The cardiomediastinal silhouette is within nor...   \n1  The cardiomediastinal silhouette is within nor...   \n2  The heart is normal in size and contour. There...   \n3  The heart is normal in size and contour. There...   \n4  The heart is normal in size and contour. There...   \n\n                                          impression  height  width  \n0  1. No acute radiographic cardiopulmonary process.     420    512  \n1  1. No acute radiographic cardiopulmonary process.     624    512  \n2            No acute cardiopulmonary abnormalities.     420    512  \n3            No acute cardiopulmonary abnormalities.     624    512  \n4            No acute cardiopulmonary abnormalities.     624    512  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pmc_id</th>\n      <th>image_filename</th>\n      <th>caption</th>\n      <th>comparison</th>\n      <th>indication</th>\n      <th>findings</th>\n      <th>impression</th>\n      <th>height</th>\n      <th>width</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3967</td>\n      <td>CXR3967_IM-2028-1001.png</td>\n      <td>PA and lateral chest x-XXXX XXXX at XXXX hours.</td>\n      <td>NaN</td>\n      <td>Chest pain</td>\n      <td>The cardiomediastinal silhouette is within nor...</td>\n      <td>1. No acute radiographic cardiopulmonary process.</td>\n      <td>420</td>\n      <td>512</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3967</td>\n      <td>CXR3967_IM-2028-2001.png</td>\n      <td>PA and lateral chest x-XXXX XXXX at XXXX hours.</td>\n      <td>NaN</td>\n      <td>Chest pain</td>\n      <td>The cardiomediastinal silhouette is within nor...</td>\n      <td>1. No acute radiographic cardiopulmonary process.</td>\n      <td>624</td>\n      <td>512</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3332</td>\n      <td>CXR3332_IM-1596-1001.png</td>\n      <td>Radiograph Chest PA and Lateral XXXX, XXXX.</td>\n      <td>Radiograph Chest PA and Lateral XXXX, XXXX.</td>\n      <td>Weakness.</td>\n      <td>The heart is normal in size and contour. There...</td>\n      <td>No acute cardiopulmonary abnormalities.</td>\n      <td>420</td>\n      <td>512</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3332</td>\n      <td>CXR3332_IM-1596-2001.png</td>\n      <td>Radiograph Chest PA and Lateral XXXX, XXXX.</td>\n      <td>Radiograph Chest PA and Lateral XXXX, XXXX.</td>\n      <td>Weakness.</td>\n      <td>The heart is normal in size and contour. There...</td>\n      <td>No acute cardiopulmonary abnormalities.</td>\n      <td>624</td>\n      <td>512</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3332</td>\n      <td>CXR3332_IM-1596-3001.png</td>\n      <td>Radiograph Chest PA and Lateral XXXX, XXXX.</td>\n      <td>Radiograph Chest PA and Lateral XXXX, XXXX.</td>\n      <td>Weakness.</td>\n      <td>The heart is normal in size and contour. There...</td>\n      <td>No acute cardiopulmonary abnormalities.</td>\n      <td>624</td>\n      <td>512</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"'''Processing Textual Data from each .xml Report File and Storing it in a .csv File'''\n\n# function to iterate through all .xml report files and storing them in a dataframe\ndef save_reports_df():\n    data = []\n    cnt = 0\n    for file in os.listdir(iu_xray_reports):\n        if file.endswith(\".xml\"):\n            cnt += 1\n            print(f\"Processing .xml File {cnt} out of {len(os.listdir(iu_xray_reports))}: {file}\")\n\n            file_path = os.path.join(iu_xray_reports, file)\n            try:\n                tree = ET.parse(file_path)\n                root = tree.getroot()\n\n                pmc_id = root.find('.//pmcId').attrib.get('id')\n\n                comparison = indication = findings = impression = None\n\n                for abstract in root.findall('.//AbstractText'):\n                    if abstract.attrib.get('Label') == 'COMPARISON':\n                        comparison = abstract.text\n                    elif abstract.attrib.get('Label') == 'INDICATION':\n                        indication = abstract.text\n                    elif abstract.attrib.get('Label') == 'FINDINGS':\n                        findings = abstract.text\n                    elif abstract.attrib.get('Label') == 'IMPRESSION':\n                        impression = abstract.text\n\n                report_data = {\n                    'pmc_id': pmc_id,\n                    'findings': findings,\n                    'impression': impression,\n                    'comparison': comparison,\n                    'indication': indication,\n                }\n\n                parent_images = root.findall('parentImage')\n                report_data['image_count'] = len(parent_images)\n\n                for i, parent_image in enumerate(parent_images, start=1):\n                    image_file = parent_image.attrib['id'] + \".jpg\"\n                    caption = parent_image.find('caption').text if parent_image.find('caption') is not None else None\n                    report_data[f'image_{i}'] = f\"{image_file}: {caption}\" if caption else image_file\n\n                data.append(report_data)\n\n            except Exception as e:\n                print(f\"Error processing file {file}: {e}\")\n\n    return data\n\n\n# creating a dataframe and saving it as .csv\niu_xray_reports_df_path = os.path.join(output_directory, 'iu_xray_reports_df.csv')\nif not os.path.exists(iu_xray_reports_df_path):\n    data = save_reports_df()\n    iu_xray_reports_df = pd.DataFrame(data)\n    iu_xray_reports_df.to_csv(iu_xray_reports_df_path, index=False)\n    print(f\"Dataframe saved to {iu_xray_reports_df_path}\")\nelse:\n    print(f\"Dataframe already exists at {iu_xray_reports_df_path}\")\n    iu_xray_reports_df = pd.read_csv(iu_xray_reports_df_path)\n\n\n# displaying the stored dataframe\nprint(\"\\n\\nDataframe Shape:\", iu_xray_reports_df.shape)\n\nprint(\"\\n\\nDataframe Information:\\n\")\ndisplay(iu_xray_reports_df.info())\n\nprint(\"\\n\\nDisplaying Dataframe:\\n\")\ndisplay(iu_xray_reports_df.head())","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":893},"id":"vYnfzXXT0O6w","outputId":"d2692046-ebe0-45ac-8291-37641f6d5958","execution":{"iopub.status.busy":"2024-10-20T18:07:47.846271Z","iopub.execute_input":"2024-10-20T18:07:47.846637Z","iopub.status.idle":"2024-10-20T18:07:47.908470Z","shell.execute_reply.started":"2024-10-20T18:07:47.846600Z","shell.execute_reply":"2024-10-20T18:07:47.907465Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Dataframe already exists at ./datasets/iu_xray/output/iu_xray_reports_df.csv\n\n\nDataframe Shape: (3955, 11)\n\n\nDataframe Information:\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3955 entries, 0 to 3954\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   pmc_id       3955 non-null   int64 \n 1   findings     3425 non-null   object\n 2   impression   3921 non-null   object\n 3   comparison   2757 non-null   object\n 4   indication   3865 non-null   object\n 5   image_count  3955 non-null   int64 \n 6   image_1      3851 non-null   object\n 7   image_2      3405 non-null   object\n 8   image_3      197 non-null    object\n 9   image_4      16 non-null     object\n 10  image_5      1 non-null      object\ndtypes: int64(2), object(9)\nmemory usage: 340.0+ KB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}},{"name":"stdout","text":"\n\nDisplaying Dataframe:\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   pmc_id                                           findings  \\\n0    3967  The cardiomediastinal silhouette is within nor...   \n1    3332  The heart is normal in size and contour. There...   \n2      30  Lungs are clear without focal consolidation, e...   \n3    2593  Mild cardiomegaly is unchanged. Stable superio...   \n4    1165  Frontal and lateral views of the chest show no...   \n\n                                          impression  \\\n0  1. No acute radiographic cardiopulmonary process.   \n1            No acute cardiopulmonary abnormalities.   \n2        Negative acute cardiopulmonary abnormality.   \n3  Mild cardiomegaly with interstitial prominence...   \n4  No acute or active cardiac, pulmonary or pleur...   \n\n                                    comparison  \\\n0                                          NaN   \n1  Radiograph Chest PA and Lateral XXXX, XXXX.   \n2                                          NaN   \n3                                          NaN   \n4                                        None.   \n\n                                          indication  image_count  \\\n0                                         Chest pain            2   \n1                                          Weakness.            3   \n2                XXXX-year-old male with chest pain.            2   \n3                                          Back pain            2   \n4  Chest pain. Shortness of breath. The patient's...            1   \n\n                                             image_1  \\\n0  CXR3967_IM-2028-1001.jpg: PA and lateral chest...   \n1  CXR3332_IM-1596-1001.jpg: Radiograph Chest PA ...   \n2  CXR30_IM-1385-1001.jpg: Chest x-XXXX XXXX and ...   \n3  CXR2593_IM-1084-1001.jpg: Chest, 2 views, XXXX...   \n4  CXR1165_IM-0110-1001.jpg: Xray Chest PA and La...   \n\n                                             image_2  \\\n0  CXR3967_IM-2028-2001.jpg: PA and lateral chest...   \n1  CXR3332_IM-1596-2001.jpg: Radiograph Chest PA ...   \n2  CXR30_IM-1385-2001.jpg: Chest x-XXXX XXXX and ...   \n3  CXR2593_IM-1084-2001.jpg: Chest, 2 views, XXXX...   \n4                                                NaN   \n\n                                             image_3 image_4 image_5  \n0                                                NaN     NaN     NaN  \n1  CXR3332_IM-1596-3001.jpg: Radiograph Chest PA ...     NaN     NaN  \n2                                                NaN     NaN     NaN  \n3                                                NaN     NaN     NaN  \n4                                                NaN     NaN     NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pmc_id</th>\n      <th>findings</th>\n      <th>impression</th>\n      <th>comparison</th>\n      <th>indication</th>\n      <th>image_count</th>\n      <th>image_1</th>\n      <th>image_2</th>\n      <th>image_3</th>\n      <th>image_4</th>\n      <th>image_5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3967</td>\n      <td>The cardiomediastinal silhouette is within nor...</td>\n      <td>1. No acute radiographic cardiopulmonary process.</td>\n      <td>NaN</td>\n      <td>Chest pain</td>\n      <td>2</td>\n      <td>CXR3967_IM-2028-1001.jpg: PA and lateral chest...</td>\n      <td>CXR3967_IM-2028-2001.jpg: PA and lateral chest...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3332</td>\n      <td>The heart is normal in size and contour. There...</td>\n      <td>No acute cardiopulmonary abnormalities.</td>\n      <td>Radiograph Chest PA and Lateral XXXX, XXXX.</td>\n      <td>Weakness.</td>\n      <td>3</td>\n      <td>CXR3332_IM-1596-1001.jpg: Radiograph Chest PA ...</td>\n      <td>CXR3332_IM-1596-2001.jpg: Radiograph Chest PA ...</td>\n      <td>CXR3332_IM-1596-3001.jpg: Radiograph Chest PA ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30</td>\n      <td>Lungs are clear without focal consolidation, e...</td>\n      <td>Negative acute cardiopulmonary abnormality.</td>\n      <td>NaN</td>\n      <td>XXXX-year-old male with chest pain.</td>\n      <td>2</td>\n      <td>CXR30_IM-1385-1001.jpg: Chest x-XXXX XXXX and ...</td>\n      <td>CXR30_IM-1385-2001.jpg: Chest x-XXXX XXXX and ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2593</td>\n      <td>Mild cardiomegaly is unchanged. Stable superio...</td>\n      <td>Mild cardiomegaly with interstitial prominence...</td>\n      <td>NaN</td>\n      <td>Back pain</td>\n      <td>2</td>\n      <td>CXR2593_IM-1084-1001.jpg: Chest, 2 views, XXXX...</td>\n      <td>CXR2593_IM-1084-2001.jpg: Chest, 2 views, XXXX...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1165</td>\n      <td>Frontal and lateral views of the chest show no...</td>\n      <td>No acute or active cardiac, pulmonary or pleur...</td>\n      <td>None.</td>\n      <td>Chest pain. Shortness of breath. The patient's...</td>\n      <td>1</td>\n      <td>CXR1165_IM-0110-1001.jpg: Xray Chest PA and La...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"'''Displaying the Number of Images per Report'''\n\n# displaying the distribution of number of images per report\nreports_count = iu_xray_reports_df['image_count'].value_counts().rename_axis('images_qty').reset_index(name='reports_count')\nprint(\"\\n\\nNumber of Images per Report:\\n\")\ndisplay(reports_count)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":310},"id":"bw4Ylfa94M1o","outputId":"5ef503a0-265c-423b-8cae-1d36b136134d","execution":{"iopub.status.busy":"2024-10-20T18:07:52.905423Z","iopub.execute_input":"2024-10-20T18:07:52.905789Z","iopub.status.idle":"2024-10-20T18:07:52.919447Z","shell.execute_reply.started":"2024-10-20T18:07:52.905751Z","shell.execute_reply":"2024-10-20T18:07:52.918427Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\n\nNumber of Images per Report:\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   images_qty  reports_count\n0           2           3208\n1           1            446\n2           3            181\n3           0            104\n4           4             15\n5           5              1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>images_qty</th>\n      <th>reports_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>3208</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>446</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>181</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>104</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## **Data Preprocessing**","metadata":{"id":"6UouFxQwMNeo"}},{"cell_type":"markdown","source":"### **Preprocess Images**","metadata":{"id":"-cGf99_CMV47"}},{"cell_type":"code","source":"'''Preprocessing Images - Resizing, Tensor Conversion and Normalization'''\n\n# function to preprocess and save images\ndef preprocess_images(input_dir, output_dir):\n    preprocess = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n\n    os.makedirs(output_dir, exist_ok=True)\n\n    cnt = 0\n    for filename in os.listdir(input_dir):\n        if filename.endswith('.png'):\n            cnt += 1\n            print(f\"Preprocessing File {cnt} out of {len(os.listdir(input_dir))}: {filename}\")\n\n            image_path = os.path.join(input_dir, filename)\n            image = Image.open(image_path).convert('RGB')\n            processed_image = preprocess(image)\n\n            processed_image_path = os.path.join(output_dir, filename)\n\n            processed_image_pil = transforms.ToPILImage()(processed_image)\n            processed_image_pil.save(processed_image_path)\n\n\n# preprocessing images\niu_xray_images_preprocessed = os.path.join(output_directory, 'images_preprocessed')\nif not os.path.exists(iu_xray_images_preprocessed):\n    print(f\"Preprocessing Images to: {iu_xray_images_preprocessed}\")\n    preprocess_images(iu_xray_images, iu_xray_images_preprocessed)\n    print(f\"Preprocessed Images saved to: {iu_xray_images_preprocessed}\")\nelse:\n    print(f\"Preprocessed Images already exist at: {iu_xray_images_preprocessed}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JTClOSxeSCOM","outputId":"811cbc93-70e7-4d60-f213-26238488c44d","execution":{"iopub.status.busy":"2024-10-20T18:07:56.442806Z","iopub.execute_input":"2024-10-20T18:07:56.443189Z","iopub.status.idle":"2024-10-20T18:07:56.452908Z","shell.execute_reply.started":"2024-10-20T18:07:56.443153Z","shell.execute_reply":"2024-10-20T18:07:56.451957Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Preprocessed Images already exist at: ./datasets/iu_xray/output/images_preprocessed\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **Preprocess Text**","metadata":{"id":"lvdRoNqXMZlN"}},{"cell_type":"code","source":"'''Preprocessing Text - Lowercasing, Decontracting, Punctuation Removal, Number Removal, Two-Letter Word Removal, Stop Word Removal, Spell Checking, Extra Space Removal'''\n\n# download nltk resources and initialize spell checker\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('stopwords')\nspell = SpellChecker()\n\n\n# function to convert text to lowercase\ndef lowercase(text):\n    return text.lower() if isinstance(text, str) else text\n\n\n# function to decontract words\ndef decontracted(text):\n    if not isinstance(text, str):\n        return text\n    contractions = {\n        \"won't\": \"will not\", \"can't\": \"can not\", \"couldn't\": \"could not\",\n        \"shouldn't\": \"should not\", \"wouldn't\": \"would not\", \"n't\": \" not\",\n        \"'re\": \" are\", \"'s\": \" is\", \"'d\": \" would\", \"'ll\": \" will\",\n        \"'t\": \" not\", \"'ve\": \" have\", \"'m\": \" am\"\n    }\n    for contraction, full_form in contractions.items():\n        text = text.replace(contraction, full_form)\n    return text\n\n\n# function to remove punctuations\ndef rem_punctuations(text):\n    return re.sub(r'[^\\w\\s]', ' ', text) if isinstance(text, str) else text\n\n\n# function to remove numbers\ndef rem_numbers(text):\n    return re.sub(r'\\d+', ' ', text) if isinstance(text, str) else text\n\n\n# function to remove two-letter words except \"no\" and \"ct\"\ndef rem_two_letter_words(text):\n    if not isinstance(text, str):\n        return text\n    return ' '.join(word for word in text.split() if len(word) > 2 or word in [\"no\", \"ct\"])\n\n\n# function to remove stop words\ndef rem_stop_words(text):\n    if not isinstance(text, str):\n        return text\n    stop_words = set(stopwords.words('english'))\n    return ' '.join(word for word in text.split() if word not in stop_words)\n\n\n# function to correct spelling\ndef correct_spelling(text):\n    if not isinstance(text, str):\n        return text\n    corrected = []\n    for word in text.split():\n        corrected_word = list(spell.candidates(word))[0] if spell.candidates(word) else word\n        corrected.append(corrected_word)\n    return ' '.join(corrected)\n\n\n# function to remove extra spaces\ndef rem_extra_spaces(text):\n    return ' '.join(text.split()) if isinstance(text, str) else text\n\n\n# function to preprocess text\ndef preprocess_text(data):\n    preprocessed = []\n    for sentence in tqdm(data.values):\n        sentence = str(sentence)\n        sentence = lowercase(sentence)\n        sentence = decontracted(sentence)\n        sentence = rem_punctuations(sentence)\n        sentence = rem_numbers(sentence)\n        sentence = rem_two_letter_words(sentence)\n        sentence = rem_stop_words(sentence)\n        sentence = correct_spelling(sentence)\n        sentence = rem_extra_spaces(sentence)\n        \n        preprocessed.append(sentence)\n\n    return preprocessed\n\n\n# path to the preprocessed dataframe\niu_xray_reports_preprocessed_df_path = os.path.join(output_directory, 'iu_xray_reports_preprocessed_df.csv')\niu_xray_reports_preprocessed_df = iu_xray_reports_df.copy()\n\n\n# preprocessing text columns in the dataframe\nif not os.path.exists(iu_xray_reports_preprocessed_df_path):\n    print(f\"Preprocessing Text of DataFrame {iu_xray_reports_df_path} to: {iu_xray_reports_preprocessed_df_path}\")\n    \n    preprocess_caption = True\n    preprocess_comparison = True\n    preprocess_indication = True\n    preprocess_findings = True\n    preprocess_impression = True\n    \n    if preprocess_caption and 'caption' in iu_xray_reports_preprocessed_df.columns:\n        print(\"Preprocessing Column: caption\")\n        iu_xray_reports_preprocessed_df['caption'] = iu_xray_reports_preprocessed_df['caption'].fillna('unknown').astype(str)\n        iu_xray_reports_preprocessed_df['caption'] = preprocess_text(iu_xray_reports_preprocessed_df['caption'])\n        iu_xray_reports_preprocessed_df.to_csv(iu_xray_reports_preprocessed_df_path, index=False)\n        print(f\"Saved preprocessed 'caption' column to: {iu_xray_reports_preprocessed_df_path}\")\n    \n    if preprocess_comparison and 'comparison' in iu_xray_reports_preprocessed_df.columns:\n        print(\"Preprocessing Column: comparison\")\n        iu_xray_reports_preprocessed_df['comparison'] = iu_xray_reports_preprocessed_df['comparison'].fillna('none').astype(str)\n        iu_xray_reports_preprocessed_df['comparison'] = preprocess_text(iu_xray_reports_preprocessed_df['comparison'])\n        iu_xray_reports_preprocessed_df.to_csv(iu_xray_reports_preprocessed_df_path, index=False)\n        print(f\"Saved preprocessed 'comparison' column to: {iu_xray_reports_preprocessed_df_path}\")\n    \n    if preprocess_indication and 'indication' in iu_xray_reports_preprocessed_df.columns:\n        print(\"Preprocessing Column: indication\")\n        iu_xray_reports_preprocessed_df['indication'] = iu_xray_reports_preprocessed_df['indication'].fillna('none').astype(str)\n        iu_xray_reports_preprocessed_df['indication'] = preprocess_text(iu_xray_reports_preprocessed_df['indication'])\n        iu_xray_reports_preprocessed_df.to_csv(iu_xray_reports_preprocessed_df_path, index=False)\n        print(f\"Saved preprocessed 'indication' column to: {iu_xray_reports_preprocessed_df_path}\")\n    \n    if preprocess_findings and 'findings' in iu_xray_reports_preprocessed_df.columns:\n        print(\"Preprocessing Column: findings\")\n        iu_xray_reports_preprocessed_df['findings'] = iu_xray_reports_preprocessed_df['findings'].fillna('none').astype(str)\n        iu_xray_reports_preprocessed_df['findings'] = preprocess_text(iu_xray_reports_preprocessed_df['findings'])\n        iu_xray_reports_preprocessed_df.to_csv(iu_xray_reports_preprocessed_df_path, index=False)\n        print(f\"Saved preprocessed 'findings' column to: {iu_xray_reports_preprocessed_df_path}\")\n    \n    if preprocess_impression and 'impression' in iu_xray_reports_preprocessed_df.columns:\n        print(\"Preprocessing Column: impression\")\n        iu_xray_reports_preprocessed_df['impression'] = iu_xray_reports_preprocessed_df['impression'].fillna('none').astype(str)\n        iu_xray_reports_preprocessed_df['impression'] = preprocess_text(iu_xray_reports_preprocessed_df['impression'])\n        iu_xray_reports_preprocessed_df.to_csv(iu_xray_reports_preprocessed_df_path, index=False)\n        print(f\"Saved preprocessed 'impression' column to: {iu_xray_reports_preprocessed_df_path}\")\nelse:\n    print(f\"Preprocessed Text of DataFrame {iu_xray_reports_df_path} already exists at: {iu_xray_reports_preprocessed_df_path}\")\n    \n\n# displaying the preprocessed dataframe\niu_xray_reports_preprocessed_df = pd.read_csv(iu_xray_reports_preprocessed_df_path)\ndisplay(iu_xray_reports_preprocessed_df.head())","metadata":{"id":"M8sW8uz8-plE","execution":{"iopub.status.busy":"2024-10-20T18:07:58.325472Z","iopub.execute_input":"2024-10-20T18:07:58.325820Z","iopub.status.idle":"2024-10-20T18:07:58.764309Z","shell.execute_reply.started":"2024-10-20T18:07:58.325785Z","shell.execute_reply":"2024-10-20T18:07:58.759661Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\nPreprocessed Text of DataFrame ./datasets/iu_xray/output/iu_xray_reports_df.csv already exists at: ./datasets/iu_xray/output/iu_xray_reports_preprocessed_df.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   pmc_id                                           findings  \\\n0    3967  cardiomediastinal silhouette within normal lim...   \n1    3332  heart normal size contour mediastinal widening...   \n2      30  lungs clear without focal consolidation effusi...   \n3    2593  mild cardiomegaly unchanged stable superior me...   \n4    1165  frontal lateral views chest show normal size c...   \n\n                                          impression  \\\n0         acute radiographic cardiopulmonary process   \n1                acute cardiopulmonary abnormalities   \n2         negative acute cardiopulmonary abnormality   \n3  mild cardiomegaly interstitial prominence coul...   \n4     acute active cardiac pulmonary pleural disease   \n\n                           comparison  \\\n0                                none   \n1  radiograph chest lateral xxxx xxxx   \n2                                none   \n3                                none   \n4                                none   \n\n                                          indication  image_count  \\\n0                                         chest pain            2   \n1                                           weakness            3   \n2                      xxxx year old male chest pain            2   \n3                                          back pain            2   \n4  chest pain shortness breath patient lower abdo...            1   \n\n                                             image_1  \\\n0  CXR3967_IM-2028-1001.jpg: PA and lateral chest...   \n1  CXR3332_IM-1596-1001.jpg: Radiograph Chest PA ...   \n2  CXR30_IM-1385-1001.jpg: Chest x-XXXX XXXX and ...   \n3  CXR2593_IM-1084-1001.jpg: Chest, 2 views, XXXX...   \n4  CXR1165_IM-0110-1001.jpg: Xray Chest PA and La...   \n\n                                             image_2  \\\n0  CXR3967_IM-2028-2001.jpg: PA and lateral chest...   \n1  CXR3332_IM-1596-2001.jpg: Radiograph Chest PA ...   \n2  CXR30_IM-1385-2001.jpg: Chest x-XXXX XXXX and ...   \n3  CXR2593_IM-1084-2001.jpg: Chest, 2 views, XXXX...   \n4                                                NaN   \n\n                                             image_3 image_4 image_5  \n0                                                NaN     NaN     NaN  \n1  CXR3332_IM-1596-3001.jpg: Radiograph Chest PA ...     NaN     NaN  \n2                                                NaN     NaN     NaN  \n3                                                NaN     NaN     NaN  \n4                                                NaN     NaN     NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pmc_id</th>\n      <th>findings</th>\n      <th>impression</th>\n      <th>comparison</th>\n      <th>indication</th>\n      <th>image_count</th>\n      <th>image_1</th>\n      <th>image_2</th>\n      <th>image_3</th>\n      <th>image_4</th>\n      <th>image_5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3967</td>\n      <td>cardiomediastinal silhouette within normal lim...</td>\n      <td>acute radiographic cardiopulmonary process</td>\n      <td>none</td>\n      <td>chest pain</td>\n      <td>2</td>\n      <td>CXR3967_IM-2028-1001.jpg: PA and lateral chest...</td>\n      <td>CXR3967_IM-2028-2001.jpg: PA and lateral chest...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3332</td>\n      <td>heart normal size contour mediastinal widening...</td>\n      <td>acute cardiopulmonary abnormalities</td>\n      <td>radiograph chest lateral xxxx xxxx</td>\n      <td>weakness</td>\n      <td>3</td>\n      <td>CXR3332_IM-1596-1001.jpg: Radiograph Chest PA ...</td>\n      <td>CXR3332_IM-1596-2001.jpg: Radiograph Chest PA ...</td>\n      <td>CXR3332_IM-1596-3001.jpg: Radiograph Chest PA ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30</td>\n      <td>lungs clear without focal consolidation effusi...</td>\n      <td>negative acute cardiopulmonary abnormality</td>\n      <td>none</td>\n      <td>xxxx year old male chest pain</td>\n      <td>2</td>\n      <td>CXR30_IM-1385-1001.jpg: Chest x-XXXX XXXX and ...</td>\n      <td>CXR30_IM-1385-2001.jpg: Chest x-XXXX XXXX and ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2593</td>\n      <td>mild cardiomegaly unchanged stable superior me...</td>\n      <td>mild cardiomegaly interstitial prominence coul...</td>\n      <td>none</td>\n      <td>back pain</td>\n      <td>2</td>\n      <td>CXR2593_IM-1084-1001.jpg: Chest, 2 views, XXXX...</td>\n      <td>CXR2593_IM-1084-2001.jpg: Chest, 2 views, XXXX...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1165</td>\n      <td>frontal lateral views chest show normal size c...</td>\n      <td>acute active cardiac pulmonary pleural disease</td>\n      <td>none</td>\n      <td>chest pain shortness breath patient lower abdo...</td>\n      <td>1</td>\n      <td>CXR1165_IM-0110-1001.jpg: Xray Chest PA and La...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### **Create Data Loaders**","metadata":{"id":"MlOl6I0rMa68"}},{"cell_type":"code","source":"'''Image Data Loaders to Supply Dataset to Model in Batches'''\n\n# classes in dataset\nclass CustomImageDataset(Dataset):\n    def __init__(self, image_dir, transform=None):\n        self.image_dir = image_dir\n        self.transform = transform\n        self.image_files = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.image_dir, self.image_files[idx])\n        image = Image.open(img_path).convert('RGB')\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image\n\n\n# function to load image data with transformation and batching\ndef load_preprocessed_images(image_dir, batch_size=32):\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),  \n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n\n    dataset = CustomImageDataset(image_dir, transform=transform)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2024-10-20T18:08:04.398695Z","iopub.execute_input":"2024-10-20T18:08:04.399508Z","iopub.status.idle":"2024-10-20T18:08:04.408203Z","shell.execute_reply.started":"2024-10-20T18:08:04.399467Z","shell.execute_reply":"2024-10-20T18:08:04.407356Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"'''Text Data Loaders to Supply Dataset to Model in Batches'''\n\n# classes in dataset\nclass CustomTextDataset(Dataset):\n    def __init__(self, text_list, tokenizer, max_length=512):\n        self.text_list = text_list\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.text_list)\n\n    def __getitem__(self, idx):\n        text = self.text_list[idx]\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n        return {key: tensor.squeeze(0) for key, tensor in encoding.items()}\n\n\n# function to load text data with batching\ndef load_preprocessed_texts(text_list, tokenizer, batch_size=32, max_length=512):\n    dataset = CustomTextDataset(text_list, tokenizer, max_length)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2024-10-20T18:08:07.329040Z","iopub.execute_input":"2024-10-20T18:08:07.329766Z","iopub.status.idle":"2024-10-20T18:08:07.337358Z","shell.execute_reply.started":"2024-10-20T18:08:07.329728Z","shell.execute_reply":"2024-10-20T18:08:07.336416Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## **Model Implementation**","metadata":{"id":"wQ0H-X3HMgS1"}},{"cell_type":"markdown","source":"### **Visual Extractor**","metadata":{"id":"PsELnlXpMjGX"}},{"cell_type":"code","source":"'''Visual Extractor to Extract Data from Image and Encode it Accordingly'''\n\n# defining device for gpu support\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# defining the visual extractor model using ResNet101 \nclass VisualExtractor(nn.Module):\n    def __init__(self, args):\n        super(VisualExtractor, self).__init__()\n        self.visual_extractor = args.visual_extractor\n        weights = models.ResNet101_Weights.DEFAULT if args.visual_extractor_pretrained else None  \n        model = getattr(models, self.visual_extractor)(weights=weights)\n        modules = list(model.children())[:-2]  \n        self.model = nn.Sequential(*modules)\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc_layer = nn.Linear(model.fc.in_features, 2048) \n        \n    def forward(self, images):\n        patch_feats = self.model(images)\n        avg_feats = self.avg_pool(patch_feats).squeeze() \n        avg_feats = self.fc_layer(avg_feats)\n\n        batch_size, feat_size, _, _ = patch_feats.shape\n        patch_feats = patch_feats.view(batch_size, feat_size, -1).permute(0, 2, 1)\n        \n        final_embedding = torch.cat((avg_feats.unsqueeze(1), patch_feats), dim=1) \n        \n        return patch_feats, avg_feats, final_embedding\n\n\n# arguments for the visual extractor\nclass Args:\n    visual_extractor = 'resnet101' \n    visual_extractor_pretrained = True\n\n\n# initializing the model\nargs = Args()\nvisual_extractor = VisualExtractor(args).to(device)\n\n\n# function to extract features from images\ndef extract_features(images_dataloader):\n    all_patch_feats = []\n    all_avg_feats = []\n    all_final_embeddings = []\n\n    visual_extractor.eval() \n    with torch.no_grad():\n        for images in tqdm(images_dataloader):\n            images = images.to(device)\n            patch_feats, avg_feats, final_embedding = visual_extractor(images)\n            all_patch_feats.append(patch_feats.cpu()) \n            all_avg_feats.append(avg_feats.cpu())\n            all_final_embeddings.append(final_embedding.cpu())\n\n    all_patch_feats = torch.cat(all_patch_feats, dim=0)\n    all_avg_feats = torch.cat(all_avg_feats, dim=0)\n    all_final_embeddings = torch.cat(all_final_embeddings, dim=0)\n\n    return all_patch_feats, all_avg_feats, all_final_embeddings\n\n\n# function to save extracted features\ndef save_features(file_path, features):\n    print(f\"Saving features to {file_path}\")\n    torch.save(features, file_path)\n\n\n# function to lead the extracted features\ndef load_features(file_path):\n    if os.path.exists(file_path):\n        print(f\"Loading features from {file_path}\")\n        return torch.load(file_path, weights_only=True)\n    return None\n\n\n# initializing paths\nfeature_dir = output_directory\npatch_feats_file = os.path.join(output_directory, 'patch_feats.pt')\navg_feats_file = os.path.join(output_directory, 'avg_feats.pt')\nimage_embeddings_file = os.path.join(output_directory, 'image_embeddings.pt')\nimages_dataloader = load_preprocessed_images(iu_xray_images_preprocessed)\n\n\n# extracting and saving the extracted features\nif os.path.exists(patch_feats_file) and os.path.exists(avg_feats_file) and os.path.exists(image_embeddings_file):\n    print(\"All features are already precomputed and will be loaded.\")\n    patch_feats = load_features(patch_feats_file)\n    avg_feats = load_features(avg_feats_file)\n    image_embeddings = load_features(image_embeddings_file)\nelse:\n    print(\"Extracting features since they are not precomputed...\")\n    patch_feats, avg_feats, image_embeddings = extract_features(images_dataloader) \n        \n    os.makedirs(feature_dir, exist_ok=True)\n    save_features(patch_feats_file, patch_feats)\n    save_features(avg_feats_file, avg_feats)\n    save_features(image_embeddings_file, image_embeddings)\n\n\n# displaying sizes of the feature dataframes\nprint(\"Patch Features Shape:\", patch_feats.shape)\nprint(\"Average Features Shape:\", avg_feats.shape)\nprint(\"Final Embedding Shape:\", image_embeddings.shape)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-20T18:08:13.654286Z","iopub.execute_input":"2024-10-20T18:08:13.654646Z","iopub.status.idle":"2024-10-20T18:08:19.339016Z","shell.execute_reply.started":"2024-10-20T18:08:13.654610Z","shell.execute_reply":"2024-10-20T18:08:19.338043Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet101-cd907fc2.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-cd907fc2.pth\n100%|| 171M/171M [00:00<00:00, 209MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"All features are already precomputed and will be loaded.\nLoading features from ./datasets/iu_xray/output/patch_feats.pt\nLoading features from ./datasets/iu_xray/output/avg_feats.pt\nLoading features from ./datasets/iu_xray/output/image_embeddings.pt\nPatch Features Shape: torch.Size([7470, 49, 2048])\nAverage Features Shape: torch.Size([7470, 2048])\nFinal Embedding Shape: torch.Size([7470, 50, 2048])\n","output_type":"stream"}]},{"cell_type":"code","source":"'''Visualizing Extracted Features using Plots'''\n\n# function to visualize features using PCA and t-SNE, including K-Means clustering\ndef visualize_features(features, title):\n    print(f\"Original feature shape: {features.shape}\")\n    \n    features = features.reshape(features.shape[0], -1) \n    \n    pca = PCA(n_components=2)\n    pca_result = pca.fit_transform(features)\n\n    tsne = TSNE(n_components=2)\n    tsne_result = tsne.fit_transform(features)\n\n    plt.figure(figsize=(12, 6))\n    plt.subplot(1, 2, 1)\n    plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.5)\n    plt.title(f\"PCA - {title}\")\n    plt.xlabel(\"PCA Component 1\")\n    plt.ylabel(\"PCA Component 2\")\n\n    plt.subplot(1, 2, 2)\n    plt.scatter(tsne_result[:, 0], tsne_result[:, 1], alpha=0.5)\n    plt.title(f\"t-SNE - {title}\")\n    plt.xlabel(\"t-SNE Component 1\")\n    plt.ylabel(\"t-SNE Component 2\")\n\n    plt.show()\n\n    num_clusters = 3\n    kmeans = KMeans(n_clusters=num_clusters)\n    labels = kmeans.fit_predict(features)\n    \n    plt.figure(figsize=(8, 8))\n    plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=labels, cmap='viridis', alpha=0.5)\n    plt.title('t-SNE Result with K-Means Clusters')\n    plt.colorbar()\n    plt.show()\n    plt.figure(figsize=(8, 8))\n    plt.scatter(pca_result[:, 0], pca_result[:, 1], c=labels, cmap='viridis', alpha=0.5)\n    plt.title('PCA Result with K-Means Clusters')\n    plt.colorbar()\n    plt.show()\n\n\n# function to visualize features using PCA and t-SNE, without clustering\ndef visualize_features_2(features, title):\n    print(f\"Original feature shape: {features.shape}\")\n    \n    flattened_features = features.reshape(features.shape[0], -1) \n    \n    pca = PCA(n_components=2)\n    pca_result = pca.fit_transform(flattened_features)\n\n    tsne = TSNE(n_components=2)\n    tsne_result = tsne.fit_transform(flattened_features)\n\n    plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.7)\n    plt.title(f'PCA: {title}')\n    plt.show()\n    \n    plt.scatter(tsne_result[:, 0], tsne_result[:, 1], alpha=0.7)\n    plt.title(f't-SNE: {title}')\n    plt.show()\n\n\n# visualizing average features\n# visualize_features(avg_feats.numpy(), \"Average Features\")\n# visualize_features(patch_feats.numpy(), \"Patch Features\")\n# visualize_features(image_embeddings.numpy(), \"Image Embeddings\")\n\n# visualize_features_2(avg_feats.numpy(), \"Average Features\")\n# visualize_features_2(patch_feats.numpy(), \"Patch Features\")\n# visualize_features_2(image_embeddings.numpy(), \"Image Embeddings\")","metadata":{"execution":{"iopub.status.busy":"2024-10-20T18:08:22.008359Z","iopub.execute_input":"2024-10-20T18:08:22.009202Z","iopub.status.idle":"2024-10-20T18:08:22.023380Z","shell.execute_reply.started":"2024-10-20T18:08:22.009163Z","shell.execute_reply":"2024-10-20T18:08:22.022287Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### **Text Encoder**","metadata":{"id":"D2kBZTiCMmsE"}},{"cell_type":"code","source":"'''Text Encoder'''\n\n# function to embed text\ndef embed_text(text_dataloader, model):\n    all_embeddings = []\n    \n    try:\n        for batch in text_dataloader:\n            if isinstance(batch, str):\n                inputs = tokenizer([batch], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n            elif isinstance(batch, list):\n                inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n            else:\n                raise ValueError(\"Batch must be of type str or List[str]\")\n\n            outputs = model(**inputs)\n            embeddings = outputs.last_hidden_state.mean(dim=1)\n            all_embeddings.append(embeddings)\n\n        if all_embeddings: \n            return torch.cat(all_embeddings, dim=0)\n        else:\n            if isinstance(model, SentenceTransformer):\n                return torch.empty(0, model.get_sentence_embedding_dimension()).to(device)\n            else:\n                return torch.empty(0, model.config.hidden_size).to(device)\n\n    except Exception as e:\n        print(f\"Error in embedding: {e}\")\n        if isinstance(model, SentenceTransformer):\n            return torch.empty(0, model.get_sentence_embedding_dimension()).to(device)\n        else:\n            return torch.empty(0, model.config.hidden_size).to(device)\n\n\n# function to compute cosine similarity\ndef compute_cosine_similarity(embeddings1, embeddings2):\n    embeddings1 = F.normalize(embeddings1, p=2, dim=1)\n    embeddings2 = F.normalize(embeddings2, p=2, dim=1)\n    cosine = torch.mm(embeddings1, embeddings2.t())\n    return cosine\n\n\n# defining device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n# loading tokenizer, bert model and sentence-bert model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nbert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\nsentence_model = SentenceTransformer('all-MiniLM-L6-v2').to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-20T18:08:28.481040Z","iopub.execute_input":"2024-10-20T18:08:28.481410Z","iopub.status.idle":"2024-10-20T18:08:39.363790Z","shell.execute_reply.started":"2024-10-20T18:08:28.481374Z","shell.execute_reply":"2024-10-20T18:08:39.363050Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b87028cc066649089330d14a648f950d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9ea4a053f254fd082fc3495d4a375ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f5f75b01cf149ffb87f1a8f9d282f3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32dda27e83184256a039bcfa484bd50a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f779c69d3de44969430f783544d5f56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f21840528bef4de0aad74ae5de8dfc66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25d5982f417b4a039dfde980021342a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5139e9721e14f63911b0f1d0402df26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"407f9e8d48a240bd950ce3b0c9eb8af8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b70139e3124c47d08f21d19e54c195f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46950fe9b3894016b24eba5460416eec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cd6835e6c394805b4229c5a95eff15f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2353daac091943199f6fd6a532e3bc46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f97bff5b78934350bcf25d221f36bd39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"471cc0f693ae47d3a6a3542649469c13"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f85c00fc9d334efc905cc118fdb491d6"}},"metadata":{}}]},{"cell_type":"code","source":"'''Text Encoder - Medical Knowledge encoder using TextEncoder -> note shape'''\n\n# defining radiology dictionary\nradiology_dictionary = {\n    \"pleural\": ['hemithorax', 'effusion', 'pneumothorax', 'parenchymal'],\n    \"lung\": ['lungs', 'pulmonary', 'hilar', 'lobe', 'consolidation', 'atelectasis', 'edema', 'opacity', 'pneumonia'],\n    \"mediastinal\": ['mediastinum', 'diaphragm', 'hemidiaphragm'],\n    \"cardiac\": ['heart', 'cardiomegaly', 'cardiomediastinal', 'atrium', 'ventricle', 'retrocardiac'],\n    \"vascular\": ['aorta', 'venous', 'jugular', 'aortic', 'vasculature', 'cabg'],\n    \"osseous\": ['rib', 'sternal', 'subclavian', 'thoracic'],\n    \"trachea\": ['endotrachea'],\n    \"stomach\": [],\n    \"abdomen\": [],\n    \"tube\": ['clips'],\n    \"spine\": ['vertebral', 'degenerative'],\n    \"nodule\": ['mass'],\n    \"chest\": ['small', 'enlarged', 'unchanged', 'stable', 'silhouette', 'contours', 'size', 'focal', 'mild', 'acute']\n}\n\n\n# Ensure the output directory exists\nos.makedirs(output_directory, exist_ok=True)\n\n\n# define the filename and full path\nfilename = 'radiology_terms.csv'\ndictionary_csv = os.path.join(output_directory, filename) \n\n\n# Open the CSV file in write mode using the full path\nif not os.path.exists(dictionary_csv):    \n    with open(dictionary_csv, 'w', newline='') as file:  \n        writer = csv.writer(file)  \n        writer.writerow(['Category', 'Term']) \n    \n        for category, terms in radiology_dictionary.items():\n            for term in terms:\n                if term: \n                    writer.writerow([category, term]) \n                    \n    print(f\"Dictionary saved to {dictionary_csv}\")  \nelse:     \n    print(f\"File already exists at {dictionary_csv}. No changes made.\")\n\ntext_list = []\nwith open(dictionary_csv, 'r') as file:\n    reader = csv.reader(file)\n    next(reader) \n    for row in reader:\n        text_list.append(row[1]) \n\n        \n# load the SentenceTransformer model\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\n# Generate embeddings\nembeddings = model.encode(text_list)\n\n# Display the shape of the embeddings\nprint(f\"Embeddings Shape: {embeddings.shape}\")\n\ndictionary_pt = os.path.join(output_directory, 'dictionary_embeddings.pt')\nif not os.path.exists(dictionary_pt):    \n    torch.save(embeddings, dictionary_pt)\n    print(f\"Saved at : {dictionary_pt}\")\nelse : print(f\"Already saved at path : {dictionary_pt}\")\n\n    \n# # embedding dictionary and reports using bert, and historical medical reports using sentence transformer\n# dictionary_dataloader = load_preprocessed_texts(radiology_dictionary, tokenizer)\n# dictionary_embeddings = embed_text(dictionary_dataloader, bert_model)\n\n\n# # saving embeddings\n# embeddings_file_path = os.path.join(output_directory, 'dictionary_embeddings.pt')\n# if not os.path.exists(embeddings_file_path):\n#     torch.save(dictionary_embeddings.cpu(), embeddings_file_path)\n#     print(f\"Dictionary embeddings saved to {embeddings_file_path}\")\n\n\n# # displaying shape of embeddings\n# print(f\"Dictionary Embeddings Shape: {dictionary_embeddings.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-20T18:11:50.431647Z","iopub.execute_input":"2024-10-20T18:11:50.432032Z","iopub.status.idle":"2024-10-20T18:11:50.519562Z","shell.execute_reply.started":"2024-10-20T18:11:50.431994Z","shell.execute_reply":"2024-10-20T18:11:50.518317Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"File already exists at ./datasets/iu_xray/output/radiology_terms.csv. No changes made.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dictionary_csv, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     47\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(file)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreader\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n\u001b[1;32m     50\u001b[0m         text_list\u001b[38;5;241m.\u001b[39mappend(row[\u001b[38;5;241m1\u001b[39m]) \n","\u001b[0;31mStopIteration\u001b[0m: "],"ename":"StopIteration","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"'''Text Encoder - Medical History encoding using sentence encoder'''\n\n# reading and preprocessing medical history reports\niu_xray_reports_preprocessed_df_path = os.path.join(output_directory, 'iu_xray_reports_preprocessed_df.csv')\nmedical_history = pd.read_csv(iu_xray_reports_preprocessed_df_path)[\"findings\"].dropna().tolist()\nmedical_history = [str(report) for report in medical_history if isinstance(report, str) or pd.notna(report)]\n\nbatch_size = 32  # Set your desired batch size\ntokenizer = AutoTokenizer.from_pretrained('all-MiniLM-L6-v2')  # Ensure you have your tokenizer defined\n\n# Load the data into a DataLoader\nmedical_reports_dataloader = load_preprocessed_texts(medical_history, tokenizer, batch_size)\n\n# Step 3: Print the shapes of the batches\nfor batch in medical_reports_dataloader:\n    # Printing shapes of input tensors\n    print({key: tensor.shape for key, tensor in batch.items()})\n    break  # Remove this break to see all batches","metadata":{},"execution_count":86,"outputs":[{"ename":"OSError","evalue":"all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n","\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)","File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    404\u001b[0m         path_or_repo_id,\n\u001b[1;32m    405\u001b[0m         filename,\n\u001b[1;32m    406\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[1;32m    407\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    408\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    409\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    410\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    411\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    412\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    413\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    414\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    415\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    416\u001b[0m     )\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1232\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[1;32m   1233\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m   1234\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   1235\u001b[0m         \u001b[38;5;66;03m# File info\u001b[39;00m\n\u001b[1;32m   1236\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m   1237\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   1238\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m   1239\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   1240\u001b[0m         \u001b[38;5;66;03m# HTTP info\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[1;32m   1242\u001b[0m         etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[1;32m   1243\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1244\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1245\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   1246\u001b[0m         \u001b[38;5;66;03m# Additional options\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1248\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   1249\u001b[0m     )\n","File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1339\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m-> 1339\u001b[0m     _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1854\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1853\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1854\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1856\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1746\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1746\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m get_hf_file_metadata(\n\u001b[1;32m   1747\u001b[0m         url\u001b[38;5;241m=\u001b[39murl, proxies\u001b[38;5;241m=\u001b[39mproxies, timeout\u001b[38;5;241m=\u001b[39metag_timeout, headers\u001b[38;5;241m=\u001b[39mheaders, token\u001b[38;5;241m=\u001b[39mtoken\n\u001b[1;32m   1748\u001b[0m     )\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n","File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1666\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1666\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1667\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1668\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   1669\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1670\u001b[0m     allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1671\u001b[0m     follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1672\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1673\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   1674\u001b[0m )\n\u001b[1;32m   1675\u001b[0m hf_raise_for_status(r)\n","File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:364\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 364\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m    365\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    366\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    367\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    369\u001b[0m     )\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:388\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    387\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 388\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n","File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:454\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    446\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m     )\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-6714246e-33c72aac4912074a77e010f5;fe53025f-24dc-42bd-b0e0-ffeb58db44ba)\n\nRepository Not Found for url: https://huggingface.co/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[86], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m medical_history \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(report) \u001b[38;5;28;01mfor\u001b[39;00m report \u001b[38;5;129;01min\u001b[39;00m medical_history \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(report, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(report)]\n\u001b[1;32m      8\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m  \u001b[38;5;66;03m# Set your desired batch size\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Ensure you have your tokenizer defined\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Load the data into a DataLoader\u001b[39;00m\n\u001b[1;32m     12\u001b[0m medical_reports_dataloader \u001b[38;5;241m=\u001b[39m load_preprocessed_texts(medical_history, tokenizer, batch_size)\n","File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:844\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    843\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[0;32m--> 844\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m get_tokenizer_config(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[1;32m    846\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:676\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m     token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[1;32m    675\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 676\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m    677\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m    678\u001b[0m     TOKENIZER_CONFIG_FILE,\n\u001b[1;32m    679\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    680\u001b[0m     force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    681\u001b[0m     resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    682\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    683\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    684\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    685\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    686\u001b[0m     subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m    687\u001b[0m     _raise_exceptions_for_gated_repo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    688\u001b[0m     _raise_exceptions_for_missing_entries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    689\u001b[0m     _raise_exceptions_for_connection_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    690\u001b[0m     _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[1;32m    691\u001b[0m )\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    693\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:426\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    431\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","\u001b[0;31mOSError\u001b[0m: all-MiniLM-L6-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"]}]},{"cell_type":"code","source":"'''Text Encoder -  Sentence-Bert Encoder using Medical History'''\n\n# reading and preprocessing medical history reports\niu_xray_reports_preprocessed_df_path = os.path.join(output_directory, 'iu_xray_reports_preprocessed_df.csv')\nmedical_history = pd.read_csv(iu_xray_reports_preprocessed_df_path)[\"findings\"].dropna().tolist()\nmedical_history = [str(report) for report in medical_history if isinstance(report, str) or pd.notna(report)]\n\ninvalid_entries = [report for report in medical_history if not isinstance(report, (str, list))]\n\n# Print if there are any invalid entries\nif invalid_entries:\n    print(f\"Found {len(invalid_entries)} invalid entries: {invalid_entries}\")\nelse:\n    print(\"No invalid entries found.\")\n\n# encoding medical history using Sentence-BERT\nbert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nhistorical_dataloader_b = load_preprocessed_texts(medical_history, tokenizer)\nhistorical_embeddings_b = embed_text(historical_dataloader, bert_model)\n\n# # Check for invalid entries after batching\n# invalid_entries_after_batches = [\n#     report for batch in historical_dataloader_b for report in batch.values() if not isinstance(report, (str, list))\n# ]\n\n# for batch in historical_dataloader:\n#     print(type(batch))  # Check the type\n#     print(batch)  # Print the batch content\n#     break\n\n\n\n# saving embeddings\nhistorical_pt_b = os.path.join(output_directory, 'historical_embeddings_b.pt')\nif not os.path.exists(historical_pt_b):\n    torch.save(historical_embeddings_b.cpu(), historical_pt_b)\n    print(f\"Historical embeddings saved to {historical_pt_b}\")\nelse : print(f\"Already at {historical_pt_b}\")\n\n\n# displaying shape of embeddings\nprint(f\"Historical Embeddings Shape: {historical_embeddings_b.shape}\")","metadata":{},"execution_count":120,"outputs":[{"name":"stdout","output_type":"stream","text":"No invalid entries found.\n\nError in embedding: Batch must be of type str or List[str]\n\nAlready at ./datasets/iu_xray/output/historical_embeddings_b.pt\n\nHistorical Embeddings Shape: torch.Size([0, 768])\n"}]},{"cell_type":"code","source":"'''Text Encoder - Finding Reports Similar to Current Report'''\n\n# current report embedding\ncurrent_report = 'Heart size pulmonary vascularity appear within normal limits mild tortuosity descending thoracic aorta lungs free focal airspace disease pleural effusion pneumothorax seen discrete nodules adenopathy noted degenerative changes present spine'\ncurrent_embeddings = embed_text(current_report, sentence_model)\n\n\n# computing cosine similarity\nhistorical_embeddings_normalized = historical_embeddings / historical_embeddings.norm(dim=1, keepdim=True)\ncurrent_embeddings_normalized = current_embeddings / current_embeddings.norm(dim=1, keepdim=True)\n\nsimilarity_matrix = compute_cosine_similarity(dictionary_embeddings, historical_embeddings)\nprint(f\"Similarity Matrix Shape: {similarity_matrix.shape}\")\n\n\n# finding top-k relevant entries\nk = 5\ntop_k_indices = similarity_matrix.topk(k=k, dim=1).indices\n\n\n# preparing relevant entries based on indices\nrelevant_entries = []\nfor row in top_k_indices:\n    relevant_entries.append(medical_history[row.item()])\n\n\n# printing relevant entries for each report\nprint(f\"Relevant Entries for the Current Report: {relevant_entries}\")\n\n\n# update the historical embeddingx\nhistorical_embeddings.append(current_embeddings)","metadata":{"execution":{"iopub.execute_input":"2024-10-19T19:11:16.520892Z","iopub.status.busy":"2024-10-19T19:11:16.520038Z","iopub.status.idle":"2024-10-19T19:11:16.658663Z","shell.execute_reply":"2024-10-19T19:11:16.657206Z","shell.execute_reply.started":"2024-10-19T19:11:16.520840Z"}},"execution_count":25,"outputs":[{"name":"stdout","output_type":"stream","text":"Error in embedding: SentenceTransformer.forward() missing 1 required positional argument: 'input'\n"},{"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (0x768 and 384x0)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m historical_embeddings_normalized \u001b[38;5;241m=\u001b[39m historical_embeddings \u001b[38;5;241m/\u001b[39m historical_embeddings\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m current_embeddings_normalized \u001b[38;5;241m=\u001b[39m current_embeddings \u001b[38;5;241m/\u001b[39m current_embeddings\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 12\u001b[0m similarity_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_cosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictionary_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistorical_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimilarity Matrix Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimilarity_matrix\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# finding top-k relevant entries\u001b[39;00m\n","Cell \u001b[0;32mIn[14], line 40\u001b[0m, in \u001b[0;36mcompute_cosine_similarity\u001b[0;34m(embeddings1, embeddings2)\u001b[0m\n\u001b[1;32m     38\u001b[0m embeddings1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(embeddings1, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     39\u001b[0m embeddings2 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(embeddings2, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m cosine \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cosine\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (0x768 and 384x0)"]}]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer, BertModel\nimport pickle\n\n# Check if GPU is available and set the device accordingly\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Function to convert findings to list of lists\ndef get_findings_list(df):\n    findings_list = df['findings'].fillna(\"\").tolist()  # Replace NaN with empty string\n    return [[finding] for finding in findings_list]  # Convert each finding into a list of strings\n\n# Dataset class to load the findings from the reports\nclass FindingsDataset(Dataset):\n    def __init__(self, findings_list):\n        self.findings_list = findings_list\n\n    def __len__(self):\n        return len(self.findings_list)\n\n    def __getitem__(self, idx):\n        return self.findings_list[idx]\n\n# Define the Sentence Encoder (trainable)\nclass SentenceEncoder(nn.Module):\n    def __init__(self, hidden_size=768):\n        super(SentenceEncoder, self).__init__()\n        self.encoder = nn.Linear(hidden_size, hidden_size)\n    \n    def forward(self, x):\n        return self.encoder(x)\n\n# Cosine similarity loss based on the image equation\ndef cosine_similarity_loss(H, H_b):\n    cos_sim_H = F.cosine_similarity(H, H.unsqueeze(1))\n    cos_sim_H_b = F.cosine_similarity(H_b, H_b.unsqueeze(1))\n    loss = torch.mean((cos_sim_H_b - cos_sim_H) ** 2)\n    return loss\n\n# Load pre-trained BERT model and tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nbert_model = BertModel.from_pretrained('bert-base-uncased')\n\n# Move the model to the appropriate device\nbert_model.to(device)\n\n# Load your dataframe\n# iu_xray_reports_preprocessed_df_path = '/kaggle/input/preprocessed-text/iu_xray_reports_df_preprocessed.csv'\niu_xray_reports_preprocessed_df_path = os.path.join(output_directory, 'iu_xray_reports_preprocessed_df.csv')\nmedical_history = pd.read_csv(iu_xray_reports_preprocessed_df_path)\nfindings_list = get_findings_list(medical_history)\n\n# Custom collate function to tokenize the findings in batches\ndef collate_fn(batch):\n    batch = [item[0] for item in batch]  # Flatten the batch list\n    return tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(device)  # Move to GPU\n\n# Create dataset and dataloader\nfindings_dataset = FindingsDataset(findings_list)\ndataloader = DataLoader(findings_dataset, batch_size=16, collate_fn=collate_fn)\n\n# Initialize Sentence Encoder and move to device\nsentence_encoder = SentenceEncoder().to(device)\n\n# Historical Knowledge Storage\n#historical_knowledge_file = 'historical_knowledge.pkl'  # File to save the historical encodings\nhistorical_knowledge = []  # List to store historical encodings\n\nhistorical_knowledge_file = os.path.join(output_directory, 'historical_knowledge.pkl')\n# if not os.path.exists(historical_pt_b):\n#     torch.save(historical_embeddings_b.cpu(), historical_pt_b)\n#     print(f\"Historical embeddings saved to {historical_pt_b}\")\n\n# Load historical knowledge if it exists\nif os.path.exists(historical_knowledge_file):\n    with open(historical_knowledge_file, 'rb') as f:\n        historical_knowledge = pickle.load(f)\n\n# Optimizer\noptimizer = torch.optim.Adam(sentence_encoder.parameters(), lr=1e-4)\nnum_epochs = 10  # Set the number of epochs\n\n# Training loop\nfor epoch in range(num_epochs):\n    for batch in dataloader:\n        input_ids = batch['input_ids'].to(device)  # Move input_ids to GPU\n        attention_mask = batch['attention_mask'].to(device)  # Move attention_mask to GPU\n\n        # Get historical encodings from BERT\n        with torch.no_grad():\n            bert_output = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n            H_b = bert_output.last_hidden_state.mean(dim=1).to(device)  # Average pooling of BERT embeddings and move to GPU\n\n        # Get encodings from the trainable Sentence Encoder\n        H = sentence_encoder(H_b)  # Feeding the pre-trained embeddings to the trainable encoder\n\n        # final_H = H.detach().cpu()\n        # Store the current encodings in historical knowledge\n        historical_knowledge.append(H.detach().cpu())  # Detach tensor and move to CPU\n\n        # Calculate cosine similarity loss\n        loss = cosine_similarity_loss(H, H_b)\n\n        # Backpropagation and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n\n# final_H_file = 'final_H.pkl'\n# with open(final_H_file, 'wb') as f:\n#     pickle.dump(final_H.numpy(), f)\n\n\n# Now you can utilize historical_knowledge for further inference or report generation.\nwith open(historical_knowledge_file, 'wb') as f:\n    # Convert tensors to NumPy arrays before saving\n    historical_knowledge_np = [h.numpy() for h in historical_knowledge]\n    pickle.dump(historical_knowledge_np, f)\n","metadata":{},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 1, Loss: 0.2381143867969513\n"}]},{"cell_type":"markdown","source":"### **Multilevel Alignment**","metadata":{"id":"gIYzXGtsMqmQ"}},{"cell_type":"code","source":"'''Multilevel Alignment based on BLIP Architecture'''\n\n# function to extract image embeddings of a given file name\ndef extract_image_embeddings(image_name):\n    image_embeddings = torch.load(output_directory + \"image_embeddings.pt\")\n    if image_name in image_embeddings:\n        return image_embeddings[image_name]\n    else:\n        return None\n    \n\n# function to extract text embeddings of a given text\ndef extract_historical_text_embeddings(text):\n    historical_text_embeddings = torch.load(output_directory + \"historical_embeddings.pt\")\n    if text in historical_text_embeddings:\n        return historical_text_embeddings[text]\n    else :\n        return None\n\ndef extract_dictionary_text_embeddings(text):\n    dictionary_text_embeddings = torch.load(output_directory + \"dictionary_embeddings.pt\")\n    if text in dictionary_text_embeddings:\n        return dictionary_text_embeddings[text]\n    else :\n        return None\n    \n\n# function to find cosine similarity between a text and an image \ndef cosine_similarity(embedding1, embedding2):\n    embedding1 = np.array(embedding1)\n    embedding2 = np.array(embedding2)\n\n    dot_product = np.dot(embedding1, embedding2)\n    norm_embedding1 = np.linalg.norm(embedding1)\n    norm_embedding2 = np.linalg.norm(embedding2)\n    \n    if norm_embedding1 == 0 or norm_embedding2 == 0:\n        return None \n    \n    return dot_product / (norm_embedding1 * norm_embedding2)\n    \n\n# function to compute Image-Text-Contrastive Loss\ndef batch_itc_loss(image_embeddings, text_embeddings, temperature=0.1):\n    image_embeddings = F.normalize(image_embeddings, dim=1)\n    text_embeddings = F.normalize(text_embeddings, dim=1)\n\n    similarity_matrix = torch.matmul(image_embeddings, text_embeddings.T) / temperature\n\n    labels = torch.arange(len(image_embeddings), device=image_embeddings.device)\n\n    loss = F.cross_entropy(similarity_matrix, labels)\n    return labels, loss\n\n\n# function to compute Image-Text-Matching loss\ndef batch_itm_loss(image_embeddings, text_embeddings, match_labels):\n    logits = torch.matmul(image_embeddings, text_embeddings.t())\n    probabilities = torch.sigmoid(logits) \n    positive_probs = probabilities[torch.arange(len(match_labels)), match_labels]\n\n    loss = -torch.log(positive_probs + 1e-12).mean()\n    return loss\n\n\n# function to get embeddings()\ndef get_embeddings(file_path):\n    df = pd.read_csv(file_path)\n    report_embeddings = []\n    image_embeddings = []\n\n    for _, row in df.iterrows():\n        report_embedding = extract_historical_text_embeddings(row['findings'])\n\n        for i in range(1, 6):\n            image_col = f'image_{i}'\n            if image_col in row and pd.notnull(row[image_col]):\n                image_embedding = extract_image_embeddings(row[image_col])\n                report_embeddings.append(report_embedding)\n                image_embeddings.append(image_embedding)\n\n    return report_embeddings, image_embeddings\n\n\n# function to do training step\ndef train_step(file, optimizer):\n    blip_model.train()\n    text_embeddings, image_embeddings = get_embeddings(file_path)\n    \n    match_labels, itc_loss_value = batch_itc_loss(image_embeddings, text_embeddings)\n    itm_loss_value = batch_itm_loss(image_embeddings, text_embeddings, match_labels)\n    \n    total_loss = itc_loss_value + itm_loss_value\n    \n    optimizer.zero_grad()\n    total_loss.backward()\n    optimizer.step()\n    \n    return total_loss.item()","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:15:08.221577Z","iopub.execute_input":"2024-10-20T20:15:08.222467Z","iopub.status.idle":"2024-10-20T20:15:08.239307Z","shell.execute_reply.started":"2024-10-20T20:15:08.222425Z","shell.execute_reply":"2024-10-20T20:15:08.238412Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"'''Multilevel Alignment based on BLIP Architecture - Coarse Grained Alignment (Image Text Contrastive and Image Text Matching)'''\n\n# BLIP architecture\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-base\")\nblip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-base\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nblip_model.to(device)\nblip_model.eval()\n\n\n# training loop\nnum_epochs = 10  \noptimizer = torch.optim.Adam(blip_model.parameters(), lr=1e-5)\n\n\n# using a data loader defined that provides (image, text) pairs\nfor epoch in range(num_epochs):\n    loss = train_step(file_path, optimizer)\n    print(f\"Epoch {epoch}, Loss: {loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-20T20:15:20.976387Z","iopub.execute_input":"2024-10-20T20:15:20.977193Z","iopub.status.idle":"2024-10-20T20:15:21.484897Z","shell.execute_reply.started":"2024-10-20T20:15:20.977153Z","shell.execute_reply":"2024-10-20T20:15:21.483412Z"},"trusted":true},"execution_count":22,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n","\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/Salesforce/blip-base/resolve/main/preprocessor_config.json","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1232\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1339\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m-> 1339\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1854\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1853\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1854\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1856\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1746\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1746\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1666\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1666\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1675\u001b[0m hf_raise_for_status(r)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:364\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 364\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:388\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    387\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 388\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:454\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    446\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m     )\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-671564d9-14412cd30925fffd6db21c63;981de6ca-cf8f-4c2a-b502-d11d6fe81bbe)\n\nRepository Not Found for url: https://huggingface.co/Salesforce/blip-base/resolve/main/preprocessor_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m'''Multilevel Alignment based on BLIP Architecture - Coarse Grained Alignment (Image Text Contrastive and Image Text Matching)'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# BLIP architecture\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m processor \u001b[38;5;241m=\u001b[39m \u001b[43mBlipProcessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSalesforce/blip-base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m blip_model \u001b[38;5;241m=\u001b[39m BlipForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSalesforce/blip-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/processing_utils.py:915\u001b[0m, in \u001b[0;36mProcessorMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    913\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m token\n\u001b[0;32m--> 915\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_arguments_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m processor_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_processor_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_args_and_dict(args, processor_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/processing_utils.py:961\u001b[0m, in \u001b[0;36mProcessorMixin._get_arguments_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    959\u001b[0m         attribute_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(transformers_module, class_name)\n\u001b[0;32m--> 961\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(\u001b[43mattribute_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/image_processing_base.py:206\u001b[0m, in \u001b[0;36mImageProcessingMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m token\n\u001b[0;32m--> 206\u001b[0m image_processor_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_processor_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_dict(image_processor_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/image_processing_base.py:335\u001b[0m, in \u001b[0;36mImageProcessingMixin.get_image_processor_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m image_processor_file \u001b[38;5;241m=\u001b[39m IMAGE_PROCESSOR_NAME\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m     resolved_image_processor_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_processor_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:426\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    431\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","\u001b[0;31mOSError\u001b[0m: Salesforce/blip-base is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"],"ename":"OSError","evalue":"Salesforce/blip-base is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`","output_type":"error"}]},{"cell_type":"code","source":"'''Multilevel Alignment based on BLIP Architecture - Fine Grained Alignment'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Report Generator**","metadata":{"id":"Uz4pEhW2MuBF"}},{"cell_type":"markdown","source":"### **Complete Model**","metadata":{"id":"Z_WeRBlDMwX2"}},{"cell_type":"markdown","source":"## **Training**","metadata":{"id":"NZjhDeJxMzgg"}},{"cell_type":"markdown","source":"### **Training**","metadata":{"id":"7Uk_G0K8M2H9"}},{"cell_type":"markdown","source":"## **Testing**","metadata":{"id":"OXhkaJVvM3Uu"}},{"cell_type":"markdown","source":"### **Testing**","metadata":{"id":"bzTZZUlQM401"}}]}